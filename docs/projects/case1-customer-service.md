# æ¡ˆä¾‹1ï¼šæ™ºèƒ½å®¢æœRAGç³»ç»Ÿ

> **éš¾åº¦**: â­ å…¥é—¨ | **æŠ€æœ¯æ ˆ**: LangChain, OpenAI, ChromaDB, Streamlit

ä½¿ç”¨RAGæŠ€æœ¯æ„å»ºä¸€ä¸ªèƒ½å¤Ÿå›ç­”å®¢æˆ·é—®é¢˜çš„æ™ºèƒ½å®¢æœç³»ç»Ÿ

---

## ğŸ¯ æ¡ˆä¾‹æ¦‚è¿°

æœ¬æ¡ˆä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨RAGæŠ€æœ¯æ„å»ºä¸€ä¸ªåŸºç¡€çš„æ™ºèƒ½å®¢æœç³»ç»Ÿï¼Œèƒ½å¤Ÿï¼š
- å›ç­”å¸¸è§é—®é¢˜ï¼ˆFAQï¼‰
- æ”¯æŒå¤šè½®å¯¹è¯
- æä¾›å‹å¥½çš„Webç•Œé¢

### æŠ€æœ¯äº®ç‚¹

- âœ… åŸºäºRAGçš„é—®ç­”ç³»ç»Ÿ
- âœ… OpenAI Embeddingsè¯­ä¹‰æ£€ç´¢
- âœ… ChromaDBå‘é‡æ•°æ®åº“
- âœ… å¤šè½®å¯¹è¯ï¼ˆå¯¹è¯å†å²ç®¡ç†ï¼‰
- âœ… Streamlit Webç•Œé¢

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
cd projects/case1-customer-service
pip install -r requirements.txt
```

### 2. é…ç½®ç¯å¢ƒ

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
OPENAI_API_KEY=your-actual-api-key
MODEL_NAME=gpt-3.5-turbo
EMBEDDING_MODEL=text-embedding-ada-002
TOP_K=3
```

### 3. è¿è¡Œç³»ç»Ÿ

```bash
streamlit run main.py
```

è®¿é—®ï¼šhttp://localhost:8501

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
case1-customer-service/
â”œâ”€â”€ main.py              # Streamlitä¸»ç¨‹åº
â”œâ”€â”€ rag_system.py        # RAGç³»ç»Ÿæ ¸å¿ƒå®ç°
â”œâ”€â”€ knowledge_base.py    # çŸ¥è¯†åº“ç®¡ç†
â”œâ”€â”€ requirements.txt     # ä¾èµ–åŒ…
â””â”€â”€ README.md           # è¯¦ç»†æ–‡æ¡£
```

---

## ğŸ’¬ æ ¸å¿ƒåŠŸèƒ½

### 1. FAQé—®ç­”
- äº§å“ä½¿ç”¨é—®é¢˜
- é…é€æ”¿ç­–
- é€€æ¢è´§æµç¨‹
- æ”¯ä»˜æ–¹å¼

### 2. è®¢å•æŸ¥è¯¢
- è®¢å•çŠ¶æ€æŸ¥è¯¢
- ç‰©æµè·Ÿè¸ª
- é…é€æ—¶é—´

### 3. äº§å“æ¨è
- åŸºäºéœ€æ±‚æ¨è
- äº§å“å¯¹æ¯”
- ä»·æ ¼å’¨è¯¢

### 4. å¤šè½®å¯¹è¯
- ä¸Šä¸‹æ–‡è®°å¿†
- æ¾„æ¸…é—®é¢˜
- å¼•å¯¼å¼æŸ¥è¯¢

---

## ğŸ”‘ æ ¸å¿ƒä»£ç è§£æ

### RAGç³»ç»Ÿåˆå§‹åŒ–

```python
# rag_system.py
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chains import ConversationalRetrievalChain

class RAGSystem:
    def __init__(self):
        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        self.embeddings = OpenAIEmbeddings()

        # åŠ è½½çŸ¥è¯†åº“
        documents = self.load_knowledge_base()

        # åˆ›å»ºå‘é‡å­˜å‚¨
        self.vectorstore = Chroma.from_documents(
            documents=documents,
            embedding=self.embeddings
        )

        # åˆ›å»ºå¯¹è¯é“¾
        self.qa_chain = ConversationalRetrievalChain.from_llm(
            llm=ChatOpenAI(model_name="gpt-3.5-turbo"),
            retriever=self.vectorstore.as_retriever(search_kwargs={"k": 3}),
            return_source_documents=True
        )
```

### å¤šè½®å¯¹è¯å¤„ç†

```python
def chat(message, history):
    """å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
    # è°ƒç”¨RAGç³»ç»Ÿ
    response = qa_chain({
        "question": message,
        "chat_history": history
    })

    # è¿”å›ç­”æ¡ˆå’Œæ¥æº
    return response["answer"], response["source_documents"]
```

---

## ğŸ“Š ç¤ºä¾‹å¯¹è¯

**ç”¨æˆ·**: é€€æ¢è´§æ”¿ç­–æ˜¯ä»€ä¹ˆï¼Ÿ

**å®¢æœ**: æ ¹æ®çŸ¥è¯†åº“ï¼Œé€€æ¢è´§æ”¿ç­–ï¼šæ”¯æŒ7å¤©æ— ç†ç”±é€€æ¢è´§ï¼Œå•†å“éœ€ä¿æŒå®Œå¥½ï¼Œä¸å½±å“äºŒæ¬¡é”€å”®ã€‚

**ç”¨æˆ·**: è¿è´¹è°æ‰¿æ‹…ï¼Ÿ

**å®¢æœ**: é€€æ¢è´§è¿è´¹ï¼šå› è´¨é‡é—®é¢˜äº§ç”Ÿçš„é€€æ¢è´§ï¼Œè¿è´¹ç”±å•†å®¶æ‰¿æ‹…ï¼›å› ä¸ªäººåŸå› ï¼Œè¿è´¹ç”±ä¹°å®¶æ‰¿æ‹…ã€‚

---

## ğŸ“ å­¦ä¹ è¦ç‚¹

é€šè¿‡æœ¬æ¡ˆä¾‹ï¼Œä½ å°†å­¦ä¹ ï¼š

1. **RAGåŸºç¡€æ¶æ„**
   - æ–‡æ¡£åŠ è½½å’Œåˆ†å—
   - å‘é‡åµŒå…¥å’Œå­˜å‚¨
   - è¯­ä¹‰æ£€ç´¢

2. **å¤šè½®å¯¹è¯å®ç°**
   - å¯¹è¯å†å²ç®¡ç†
   - ä¸Šä¸‹æ–‡ç»´æŠ¤
   - æç¤ºè¯å·¥ç¨‹

3. **Webç•Œé¢å¼€å‘**
   - StreamlitåŸºç¡€
   - ä¼šè¯çŠ¶æ€ç®¡ç†
   - ç”¨æˆ·ç•Œé¢è®¾è®¡

---

## ğŸ“ˆ æ‰©å±•æ–¹å‘

### çŸ­æœŸä¼˜åŒ–
- [ ] æ¥å…¥çœŸå®è®¢å•æ•°æ®
- [ ] é›†æˆæ›´å¤šçŸ¥è¯†æº
- [ ] æ·»åŠ ç”¨æˆ·åé¦ˆ
- [ ] ä¼˜åŒ–å¯¹è¯ç®¡ç†

### é•¿æœŸè§„åˆ’
- [ ] æ¥å…¥çœŸå®å®¢æœç³»ç»Ÿ
- [ ] æ”¯æŒè¯­éŸ³å¯¹è¯
- [ ] å¤šè¯­è¨€æ”¯æŒ
- [ ] ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

---

## ğŸ› ï¸ ä¾èµ–ç‰ˆæœ¬

```txt
streamlit==1.29.0
langchain==0.1.0
chromadb==0.4.22
openai==1.7.2
python-dotenv==1.0.0
```

---

**[æŸ¥çœ‹å®Œæ•´æºç  â†’](https://github.com/vivy-yi/rag-tutorial/tree/main/projects/case1-customer-service)**

**[â† è¿”å›æ¡ˆä¾‹åˆ—è¡¨](index.md)**

---

**ä¸‹ä¸€æ­¥**: å°è¯•[æ¡ˆä¾‹2ï¼šæŠ€æœ¯æ–‡æ¡£é—®ç­”ç³»ç»Ÿ](case2-doc-qa.md)ï¼Œå­¦ä¹ æ··åˆæ£€ç´¢ï¼ğŸš€
