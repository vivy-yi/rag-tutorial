# ç¬¬11ç« ï¼šæ€§èƒ½ä¼˜åŒ–

> RAGç³»ç»Ÿå“åº”å¤ªæ…¢ï¼Ÿé€šè¿‡ç¼“å­˜ã€æ‰¹å¤„ç†ã€å¹¶å‘å’Œå†…å­˜ä¼˜åŒ–ï¼Œå°†ç³»ç»Ÿååé‡æå‡2-3å€ï¼Œå“åº”æ—¶é—´é™ä½50%ï¼

---

## ğŸ“š å­¦ä¹ ç›®æ ‡

å­¦å®Œæœ¬ç« åï¼Œä½ å°†èƒ½å¤Ÿï¼š

- [ ] è¯†åˆ«RAGç³»ç»Ÿçš„æ€§èƒ½ç“¶é¢ˆ
- [ ] å®ç°å¤šå±‚ç¼“å­˜ç­–ç•¥
- [ ] åº”ç”¨æ‰¹å¤„ç†ä¼˜åŒ–
- [ ] ä½¿ç”¨å¹¶å‘æå‡ååé‡
- [ ] ä¼˜åŒ–å†…å­˜ä½¿ç”¨
- [ ] å°†ç³»ç»Ÿæ€§èƒ½æå‡2-3å€

**é¢„è®¡å­¦ä¹ æ—¶é—´**ï¼š3å°æ—¶
**éš¾åº¦ç­‰çº§**ï¼šâ­â­â­â˜†â˜†

---

## å‰ç½®çŸ¥è¯†

åœ¨å¼€å§‹æœ¬ç« å­¦ä¹ å‰ï¼Œä½ éœ€è¦å…·å¤‡ï¼š

- [ ] å®Œæˆæ¨¡å—1çš„åŸºç¡€RAGå®ç°
- [ ] ç†è§£é«˜çº§RAGæ¨¡å¼ï¼ˆç¬¬10ç« ï¼‰
- [ ] ç†Ÿæ‚‰Pythonå¼‚æ­¥ç¼–ç¨‹

**ç¯å¢ƒè¦æ±‚**ï¼š
- Python >= 3.9
- redisï¼ˆç”¨äºç¼“å­˜ï¼‰
- profilingå·¥å…·ï¼ˆpy-spy, memory_profilerï¼‰

---

## 11.1 æ€§èƒ½ç“¶é¢ˆåˆ†æ

### 11.1.1 RAGç³»ç»Ÿæ€§èƒ½å‰–æ

**å…¸å‹RAGæµç¨‹çš„æ—¶é—´åˆ†è§£**ï¼š

```
ç”¨æˆ·æŸ¥è¯¢ â†’ RAGç³»ç»Ÿ â†’ ç­”æ¡ˆ
  â”‚         â”‚
  â”‚         â”œâ”€ [1] æŸ¥è¯¢å¤„ç†: ~50ms
  â”‚         â”œâ”€ [2] åµŒå…¥æŸ¥è¯¢: ~100ms
  â”‚         â”œâ”€ [3] å‘é‡æ£€ç´¢: ~200ms
  â”‚         â”œâ”€ [4] æ–‡æ¡£åŠ è½½: ~100ms
  â”‚         â”œâ”€ [5] LLMç”Ÿæˆ: ~2000ms âš ï¸ ç“¶é¢ˆ
  â”‚         â””â”€ [6] åå¤„ç†: ~50ms
  â”‚
  æ€»è®¡: ~2500ms

å„éƒ¨åˆ†å æ¯”ï¼š
  LLMç”Ÿæˆ: 80% âš ï¸
  å‘é‡æ£€ç´¢: 8%
  æŸ¥è¯¢åµŒå…¥: 4%
  æ–‡æ¡£åŠ è½½: 4%
  å…¶ä»–: 4%
```

### 11.1.2 æ€§èƒ½åˆ†æå·¥å…·

**å·¥å…·1ï¼šcProfileï¼ˆCPUåˆ†æï¼‰**

```python
# æ–‡ä»¶åï¼šprofiling_example.py
"""
æ€§èƒ½åˆ†æç¤ºä¾‹
"""

import cProfile
import pstats
import io
from pstats import SortKey


def rag_pipeline(query: str) -> str:
    """
    æ¨¡æ‹ŸRAGæµç¨‹
    """
    # æ­¥éª¤1ï¼šæŸ¥è¯¢å¤„ç†
    import time
    time.sleep(0.05)

    # æ­¥éª¤2ï¼šåµŒå…¥æŸ¥è¯¢
    time.sleep(0.1)

    # æ­¥éª¤3ï¼šå‘é‡æ£€ç´¢
    time.sleep(0.2)

    # æ­¥éª¤4ï¼šæ–‡æ¡£åŠ è½½
    time.sleep(0.1)

    # æ­¥éª¤5ï¼šLLMç”Ÿæˆ
    time.sleep(2.0)

    # æ­¥éª¤6ï¼šåå¤„ç†
    time.sleep(0.05)

    return "ç­”æ¡ˆ"


# æ€§èƒ½åˆ†æ
if __name__ == "__main__":
    # åˆ›å»ºåˆ†æå™¨
    profiler = cProfile.Profile()

    # è¿è¡Œåˆ†æ
    print("è¿è¡Œæ€§èƒ½åˆ†æ...")
    profiler.enable()

    # æ‰§è¡Œå‡½æ•°
    result = rag_pipeline("Pythonæ€§èƒ½ä¼˜åŒ–")

    profiler.disable()

    # è¾“å‡ºç»“æœ
    s = io.StringIO()
    ps = pstats.Stats(profiler, stream=s).sort_stats(SortKey.CUMULATIVE)

    # æ‰“å°Top-10å‡½æ•°
    ps.print_stats(10)
    print(s.getvalue())
```

**è¾“å‡ºç¤ºä¾‹**ï¼š

```
è¿è¡Œæ€§èƒ½åˆ†æ...

         100 function calls in 2.501 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    2.501    2.501 profiling_example.py:11(rag_pipeline)
        1    2.000    2.000    2.000    2.000 {built-in method time.sleep}
        1    0.200    0.200    0.200    0.200 {built-in method time.sleep}
        1    0.100    0.100    0.100    0.100 {built-in method time.sleep}
        ...
```

**å·¥å…·2ï¼šmemory_profilerï¼ˆå†…å­˜åˆ†æï¼‰**

```python
# å®‰è£…
# pip install memory_profiler

from memory_profiler import profile


@profile
def rag_pipeline_memory(query: str) -> str:
    """
    åˆ†æå†…å­˜ä½¿ç”¨
    """
    # æ¨¡æ‹Ÿæ•°æ®åŠ è½½
    large_data = [i for i in range(1000000)]  # ~8MB

    # æ¨¡æ‹ŸåµŒå…¥
    embeddings = [[0.1] * 768 for _ in range(100)]  # ~300KB

    # æ¨¡æ‹Ÿæ–‡æ¡£
    documents = ["æ–‡æ¡£å†…å®¹" * 1000 for _ in range(100)]  # ~1MB

    return "ç­”æ¡ˆ"


if __name__ == "__main__":
    result = rag_pipeline_memory("æµ‹è¯•æŸ¥è¯¢")
```

**è¾“å‡ºç¤ºä¾‹**ï¼š

```
Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     1     50.0 MiB     50.0 MiB           1   @profile
     2                                         def rag_pipeline_memory(query):
     3     58.0 MiB      8.0 MiB           1       large_data = [i for i in range(1000000)]
     4     58.3 MiB      0.3 MiB           1       embeddings = [[0.1] * 768 for _ in range(100)]
     5     59.3 MiB      1.0 MiB           1       documents = ["æ–‡æ¡£å†…å®¹" * 1000 for _ in range(100)]
     6     59.3 MiB      0.0 MiB           1       return "ç­”æ¡ˆ"
```

---

## 11.2 ç¼“å­˜ç­–ç•¥

### 11.2.1 ä¸ºä»€ä¹ˆéœ€è¦ç¼“å­˜ï¼Ÿ

**é—®é¢˜ï¼šé‡å¤è®¡ç®—æµªè´¹èµ„æº**

```
åœºæ™¯ï¼šFAQé—®ç­”ç³»ç»Ÿ

é—®é¢˜åˆ—è¡¨ï¼š
- "å¦‚ä½•é‡ç½®å¯†ç ï¼Ÿ"  (æ¯å¤©100æ¬¡)
- "å¦‚ä½•é€€æ¬¾ï¼Ÿ"      (æ¯å¤©50æ¬¡)
- "å¦‚ä½•è”ç³»å®¢æœï¼Ÿ"  (æ¯å¤©30æ¬¡)

æ— ç¼“å­˜ï¼š
  æ¯æ¬¡æŸ¥è¯¢éƒ½éœ€è¦ï¼š
  - åµŒå…¥æŸ¥è¯¢: 100ms
  - å‘é‡æ£€ç´¢: 200ms
  - LLMç”Ÿæˆ: 2000ms
  æ€»è®¡: 2300ms

æœ‰ç¼“å­˜ï¼š
  é¦–æ¬¡æŸ¥è¯¢: 2300ms
  åç»­æŸ¥è¯¢: 10ms (ç›´æ¥è¿”å›ç¼“å­˜)

èŠ‚çœ: 99.6%çš„æ—¶é—´ï¼
```

### 11.2.2 å¤šå±‚ç¼“å­˜æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               å¤šå±‚ç¼“å­˜æ¶æ„                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  L1: å†…å­˜ç¼“å­˜ (LRU)                                 â”‚
â”‚  â”œâ”€ å®¹é‡: 1000æ¡                                    â”‚
â”‚  â”œâ”€ TTL: 1å°æ—¶                                      â”‚
â”‚  â”œâ”€ å‘½ä¸­ç‡: ~60%                                    â”‚
â”‚  â””â”€ å“åº”æ—¶é—´: <1ms                                  â”‚
â”‚     â†“ (æœªå‘½ä¸­)                                      â”‚
â”‚  L2: Redisç¼“å­˜                                      â”‚
â”‚  â”œâ”€ å®¹é‡: 10000æ¡                                   â”‚
â”‚  â”œâ”€ TTL: 24å°æ—¶                                     â”‚
â”‚  â”œâ”€ å‘½ä¸­ç‡: ~30%                                    â”‚
â”‚  â””â”€ å“åº”æ—¶é—´: <10ms                                 â”‚
â”‚     â†“ (æœªå‘½ä¸­)                                      â”‚
â”‚  L3: å‘é‡æ•°æ®åº“ + LLM                                â”‚
â”‚  â”œâ”€ å®Œæ•´RAGæµç¨‹                                     â”‚
â”‚  â”œâ”€ å“åº”æ—¶é—´: ~2000ms                               â”‚
â”‚  â””â”€ ç»“æœå›å¡«åˆ°L1å’ŒL2                                â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ•´ä½“å‘½ä¸­ç‡: 90% (60% + 30%)
å¹³å‡å“åº”æ—¶é—´: 0.6*1ms + 0.3*10ms + 0.1*2000ms = 210ms
æå‡: 10.7å€
```

### 11.2.3 ç¼“å­˜å®ç°

**L1: å†…å­˜ç¼“å­˜**

```python
# æ–‡ä»¶åï¼šcache_strategies.py
"""
ç¼“å­˜ç­–ç•¥å®ç°
"""

from typing import Any, Optional, Dict
from functools import lru_cache
import hashlib
import json
import time


class MemoryCache:
    """
    å†…å­˜ç¼“å­˜ï¼ˆLRUï¼‰

    Args:
        max_size: æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
        ttl: ç”Ÿå­˜æ—¶é—´ï¼ˆç§’ï¼‰

    Example:
        >>> cache = MemoryCache(max_size=1000, ttl=3600)
        >>> cache.set("key", {"answer": "..."})
        >>> result = cache.get("key")
    """

    def __init__(self, max_size: int = 1000, ttl: int = 3600):
        self.max_size = max_size
        self.ttl = ttl
        self.cache: Dict[str, Dict] = {}

    def _generate_key(self, query: str, **kwargs) -> str:
        """
        ç”Ÿæˆç¼“å­˜é”®
        """
        # åŒ…å«æŸ¥è¯¢å’Œå‚æ•°
        data = {'query': query, **kwargs}
        data_str = json.dumps(data, sort_keys=True)
        return hashlib.md5(data_str.encode()).hexdigest()

    def get(self, query: str, **kwargs) -> Optional[Any]:
        """
        è·å–ç¼“å­˜
        """
        key = self._generate_key(query, **kwargs)

        if key in self.cache:
            entry = self.cache[key]

            # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if time.time() - entry['timestamp'] < self.ttl:
                entry['hits'] += 1
                return entry['value']
            else:
                # è¿‡æœŸï¼Œåˆ é™¤
                del self.cache[key]

        return None

    def set(self, query: str, value: Any, **kwargs):
        """
        è®¾ç½®ç¼“å­˜
        """
        key = self._generate_key(query, **kwargs)

        # æ£€æŸ¥å®¹é‡
        if len(self.cache) >= self.max_size:
            # LRUåˆ é™¤ï¼ˆç®€åŒ–ç‰ˆï¼šåˆ é™¤ç¬¬ä¸€ä¸ªï¼‰
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]

        # å­˜å‚¨ç¼“å­˜
        self.cache[key] = {
            'value': value,
            'timestamp': time.time(),
            'hits': 0
        }

    def clear(self):
        """
        æ¸…ç©ºç¼“å­˜
        """
        self.cache.clear()

    def get_stats(self) -> Dict:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯
        """
        total_hits = sum(entry['hits'] for entry in self.cache.values())

        return {
            'size': len(self.cache),
            'max_size': self.max_size,
            'total_hits': total_hits,
            'hit_rate': total_hits / max(total_hits, 1)
        }


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    cache = MemoryCache(max_size=100, ttl=60)

    # è®¾ç½®ç¼“å­˜
    cache.set("å¦‚ä½•é‡ç½®å¯†ç ï¼Ÿ", {
        'answer': 'è¯·åœ¨è®¾ç½®é¡µé¢ç‚¹å‡»"é‡ç½®å¯†ç "...',
        'sources': ['doc1', 'doc2']
    })

    # è·å–ç¼“å­˜
    result = cache.get("å¦‚ä½•é‡ç½®å¯†ç ï¼Ÿ")
    print(f"ç¼“å­˜å‘½ä¸­: {result}")

    # å†æ¬¡è·å–ï¼ˆå‘½ä¸­æ¬¡æ•°+1ï¼‰
    result = cache.get("å¦‚ä½•é‡ç½®å¯†ç ï¼Ÿ")
    print(f"å†æ¬¡å‘½ä¸­: {result}")

    # ç»Ÿè®¡ä¿¡æ¯
    stats = cache.get_stats()
    print(f"\nç¼“å­˜ç»Ÿè®¡: {stats}")
```

**L2: Redisç¼“å­˜**

```python
# å®‰è£…
# pip install redis

import redis
import json
import time


class RedisCache:
    """
    Redisç¼“å­˜

    Args:
        host: Redisä¸»æœº
        port: Redisç«¯å£
        db: Redisæ•°æ®åº“ç¼–å·
        ttl: ç”Ÿå­˜æ—¶é—´ï¼ˆç§’ï¼‰

    Example:
        >>> cache = RedisCache(host='localhost', port=6379, ttl=86400)
        >>> cache.set("key", {"answer": "..."})
        >>> result = cache.get("key")
    """

    def __init__(self,
                 host: str = 'localhost',
                 port: int = 6379,
                 db: int = 0,
                 ttl: int = 86400):

        self.ttl = ttl
        self.redis_client = redis.Redis(
            host=host,
            port=port,
            db=db,
            decode_responses=True
        )

    def _generate_key(self, query: str, **kwargs) -> str:
        """
        ç”Ÿæˆç¼“å­˜é”®
        """
        data = {'query': query, **kwargs}
        data_str = json.dumps(data, sort_keys=True)
        return f"rag:cache:{hashlib.md5(data_str.encode()).hexdigest()}"

    def get(self, query: str, **kwargs) -> Optional[Any]:
        """
        è·å–ç¼“å­˜
        """
        key = self._generate_key(query, **kwargs)

        try:
            value = self.redis_client.get(key)
            if value:
                return json.loads(value)
        except Exception as e:
            print(f"Redisè·å–å¤±è´¥: {e}")

        return None

    def set(self, query: str, value: Any, **kwargs):
        """
        è®¾ç½®ç¼“å­˜
        """
        key = self._generate_key(query, **kwargs)

        try:
            value_json = json.dumps(value, ensure_ascii=False)
            self.redis_client.setex(key, self.ttl, value_json)
        except Exception as e:
            print(f"Redisè®¾ç½®å¤±è´¥: {e}")

    def clear(self):
        """
        æ¸…ç©ºæ‰€æœ‰RAGç¼“å­˜
        """
        try:
            # åˆ é™¤æ‰€æœ‰rag:cache:*é”®
            for key in self.redis_client.scan_iter("rag:cache:*"):
                self.redis_client.delete(key)
        except Exception as e:
            print(f"Redisæ¸…ç©ºå¤±è´¥: {e}")

    def get_stats(self) -> Dict:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            # ç»Ÿè®¡é”®æ•°é‡
            keys = list(self.redis_client.scan_iter("rag:cache:*"))
            return {
                'size': len(keys),
                'ttl': self.ttl
            }
        except Exception as e:
            print(f"Redisç»Ÿè®¡å¤±è´¥: {e}")
            return {'size': 0, 'ttl': self.ttl}


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æ³¨æ„ï¼šéœ€è¦å…ˆå¯åŠ¨RedisæœåŠ¡
    # redis-server

    try:
        cache = RedisCache(host='localhost', port=6379, ttl=3600)

        # è®¾ç½®ç¼“å­˜
        cache.set("å¦‚ä½•é€€æ¬¾ï¼Ÿ", {
            'answer': 'æ‚¨å¯ä»¥åœ¨è®¢å•é¡µé¢ç”³è¯·é€€æ¬¾...',
            'sources': ['doc3']
        })

        # è·å–ç¼“å­˜
        result = cache.get("å¦‚ä½•é€€æ¬¾ï¼Ÿ")
        print(f"Redisç¼“å­˜: {result}")

        # ç»Ÿè®¡ä¿¡æ¯
        stats = cache.get_stats()
        print(f"\nRedisç»Ÿè®¡: {stats}")

    except Exception as e:
        print(f"Redisæœªè¿è¡Œï¼Œè·³è¿‡ç¤ºä¾‹: {e}")
```

**å®Œæ•´çš„ç¼“å­˜è£…é¥°å™¨**

```python
# æ–‡ä»¶åï¼šcached_rag.py
"""
å¸¦ç¼“å­˜çš„RAGç³»ç»Ÿ
"""

from typing import Optional, Callable, Any
import functools


class CachedRAGSystem:
    """
    å¸¦ç¼“å­˜çš„RAGç³»ç»Ÿ

    Args:
        rag_pipeline: RAGå¤„ç†å‡½æ•°
        l1_cache: L1ç¼“å­˜ï¼ˆå†…å­˜ï¼‰
        l2_cache: L2ç¼“å­˜ï¼ˆRedisï¼‰ï¼Œå¯é€‰

    Example:
        >>> rag = CachedRAGSystem(rag_pipeline, l1_cache, l2_cache)
        >>> result = rag.query("å¦‚ä½•é‡ç½®å¯†ç ï¼Ÿ")
        >>> # é¦–æ¬¡æŸ¥è¯¢ï¼šå®Œæ•´æµç¨‹
        >>> result = rag.query("å¦‚ä½•é‡ç½®å¯†ç ï¼Ÿ")
        >>> # ç¬¬äºŒæ¬¡ï¼šä»L1ç¼“å­˜è¿”å›
    """

    def __init__(self,
                 rag_pipeline: Callable,
                 l1_cache: MemoryCache,
                 l2_cache: Optional[RedisCache] = None):

        self.rag_pipeline = rag_pipeline
        self.l1_cache = l1_cache
        self.l2_cache = l2_cache

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_queries': 0,
            'l1_hits': 0,
            'l2_hits': 0,
            'misses': 0
        }

    def query(self, query: str, **kwargs) -> Dict:
        """
        æŸ¥è¯¢ï¼ˆå¸¦ç¼“å­˜ï¼‰
        """
        self.stats['total_queries'] += 1

        # L1ç¼“å­˜æŸ¥æ‰¾
        result = self.l1_cache.get(query, **kwargs)
        if result is not None:
            self.stats['l1_hits'] += 1
            return {
                'answer': result['answer'],
                'sources': result['sources'],
                'cache': 'L1'
            }

        # L2ç¼“å­˜æŸ¥æ‰¾
        if self.l2_cache:
            result = self.l2_cache.get(query, **kwargs)
            if result is not None:
                self.stats['l2_hits'] += 1

                # å›å¡«L1ç¼“å­˜
                self.l1_cache.set(query, result, **kwargs)

                return {
                    'answer': result['answer'],
                    'sources': result['sources'],
                    'cache': 'L2'
                }

        # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡ŒRAGæµç¨‹
        self.stats['misses'] += 1

        print("ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡ŒRAGæµç¨‹...")
        result = self.rag_pipeline(query, **kwargs)

        # å­˜å‚¨åˆ°ç¼“å­˜
        cache_data = {
            'answer': result['answer'],
            'sources': result.get('sources', [])
        }

        self.l1_cache.set(query, cache_data, **kwargs)

        if self.l2_cache:
            self.l2_cache.set(query, cache_data, **kwargs)

        return {
            'answer': result['answer'],
            'sources': result.get('sources', []),
            'cache': 'None'
        }

    def get_stats(self) -> Dict:
        """
        è·å–ç¼“å­˜ç»Ÿè®¡
        """
        total = self.stats['total_queries']
        l1_rate = self.stats['l1_hits'] / total if total > 0 else 0
        l2_rate = self.stats['l2_hits'] / total if total > 0 else 0
        miss_rate = self.stats['misses'] / total if total > 0 else 0

        return {
            'total_queries': total,
            'l1_hits': self.stats['l1_hits'],
            'l2_hits': self.stats['l2_hits'],
            'misses': self.stats['misses'],
            'l1_hit_rate': l1_rate,
            'l2_hit_rate': l2_rate,
            'overall_hit_rate': l1_rate + l2_rate,
            'miss_rate': miss_rate
        }


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æ¨¡æ‹ŸRAGæµç¨‹
    def mock_rag_pipeline(query: str, **kwargs) -> Dict:
        print(f"  [RAG] å¤„ç†æŸ¥è¯¢: {query}")
        import time
        time.sleep(0.5)  # æ¨¡æ‹Ÿè€—æ—¶
        return {
            'answer': f'å…³äº"{query}"çš„ç­”æ¡ˆ...',
            'sources': ['doc1', 'doc2']
        }

    # åˆ›å»ºç¼“å­˜
    l1_cache = MemoryCache(max_size=100, ttl=60)
    l2_cache = None  # RedisCache()  # å¦‚æœæœ‰Redis

    # åˆ›å»ºå¸¦ç¼“å­˜çš„RAGç³»ç»Ÿ
    rag = CachedRAGSystem(mock_rag_pipeline, l1_cache, l2_cache)

    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "å¦‚ä½•é‡ç½®å¯†ç ï¼Ÿ",
        "å¦‚ä½•é‡ç½®å¯†ç ï¼Ÿ",  # é‡å¤æŸ¥è¯¢
        "å¦‚ä½•é€€æ¬¾ï¼Ÿ",
        "å¦‚ä½•é‡ç½®å¯†ç ï¼Ÿ",  # å†æ¬¡é‡å¤
        "å¦‚ä½•è”ç³»å®¢æœï¼Ÿ",
        "å¦‚ä½•é€€æ¬¾ï¼Ÿ",  # é‡å¤æŸ¥è¯¢
    ]

    print("\n" + "="*80)
    print("å¸¦ç¼“å­˜çš„RAGç³»ç»Ÿæµ‹è¯•")
    print("="*80 + "\n")

    for query in test_queries:
        print(f"æŸ¥è¯¢: {query}")
        result = rag.query(query)
        print(f"  ç¼“å­˜: {result['cache']}")
        print(f"  ç­”æ¡ˆ: {result['answer'][:50]}...")
        print()

    # ç»Ÿè®¡ä¿¡æ¯
    stats = rag.get_stats()

    print("="*80)
    print("ç¼“å­˜ç»Ÿè®¡")
    print("="*80)
    print(f"æ€»æŸ¥è¯¢æ•°: {stats['total_queries']}")
    print(f"L1å‘½ä¸­: {stats['l1_hits']} ({stats['l1_hit_rate']*100:.1f}%)")
    print(f"L2å‘½ä¸­: {stats['l2_hits']} ({stats['l2_hit_rate']*100:.1f}%)")
    print(f"æœªå‘½ä¸­: {stats['misses']} ({stats['miss_rate']*100:.1f}%)")
    print(f"æ•´ä½“å‘½ä¸­ç‡: {stats['overall_hit_rate']*100:.1f}%")
    print("\næ€§èƒ½æå‡:")
    print(f"  èŠ‚çœæ—¶é—´: {stats['l1_hits'] + stats['l2_hits']} * 500ms = {(stats['l1_hits'] + stats['l2_hits']) * 0.5:.1f}ç§’")
```

---

## 11.3 æ‰¹å¤„ç†ä¼˜åŒ–

### 11.3.1 ä¸ºä»€ä¹ˆéœ€è¦æ‰¹å¤„ç†ï¼Ÿ

**é—®é¢˜ï¼šé€ä¸ªå¤„ç†æ•ˆç‡ä½**

```
åœºæ™¯ï¼šæ‰¹é‡å¤„ç†100ä¸ªæŸ¥è¯¢

æ— æ‰¹å¤„ç†ï¼š
  for query in queries:
      result = process(query)  # æ¯ä¸ªæŸ¥è¯¢ç‹¬ç«‹å¤„ç†
  æ€»æ—¶é—´: 100 * 500ms = 50ç§’

æ‰¹å¤„ç†ï¼š
  batch_process(queries)  # æ‰¹é‡å¤„ç†
  æ€»æ—¶é—´: 10ç§’

æå‡: 5å€
```

### 11.3.2 æ‰¹å¤„ç†å®ç°

```python
# æ–‡ä»¶åï¼šbatch_processing.py
"""
æ‰¹å¤„ç†ä¼˜åŒ–å®ç°
"""

from typing import List, Dict, Any
import time
from concurrent.futures import ThreadPoolExecutor, as_completed


class BatchProcessor:
    """
    æ‰¹å¤„ç†å™¨

    Args:
        batch_size: æ‰¹å¤§å°
        process_function: å¤„ç†å‡½æ•°
        max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°

    Example:
        >>> processor = BatchProcessor(
        ...     batch_size=10,
        ...     process_function=rag_query,
        ...     max_workers=5
        ... )
        >>> results = processor.process(queries)
    """

    def __init__(self,
                 batch_size: int = 10,
                 process_function: Callable = None,
                 max_workers: int = 4):

        self.batch_size = batch_size
        self.process_function = process_function
        self.max_workers = max_workers

    def process(self, items: List[Any]) -> List[Any]:
        """
        æ‰¹é‡å¤„ç†

        Args:
            items: å¾…å¤„ç†çš„é¡¹ç›®åˆ—è¡¨

        Returns:
            å¤„ç†ç»“æœåˆ—è¡¨
        """
        results = []

        # åˆ†æ‰¹
        batches = [
            items[i:i + self.batch_size]
            for i in range(0, len(items), self.batch_size)
        ]

        print(f"æ€»å…± {len(items)} ä¸ªé¡¹ç›®ï¼Œåˆ†ä¸º {len(batches)} æ‰¹")

        # å¹¶å‘å¤„ç†æ‰¹æ¬¡
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰¹æ¬¡ä»»åŠ¡
            future_to_batch = {
                executor.submit(self._process_batch, batch): i
                for i, batch in enumerate(batches)
            }

            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_batch):
                batch_idx = future_to_batch[future]
                try:
                    batch_results = future.result()
                    results.extend(batch_results)
                    print(f"æ‰¹æ¬¡ {batch_idx + 1}/{len(batches)} å®Œæˆ")
                except Exception as e:
                    print(f"æ‰¹æ¬¡ {batch_idx + 1} å¤±è´¥: {e}")

        # æ¢å¤åŸå§‹é¡ºåº
        return results

    def _process_batch(self, batch: List[Any]) -> List[Any]:
        """
        å¤„ç†å•ä¸ªæ‰¹æ¬¡
        """
        if self.process_function:
            return [self.process_function(item) for item in batch]
        return batch


# RAGæ‰¹å¤„ç†ç¤ºä¾‹
class BatchRAGSystem:
    """
    æ‰¹é‡RAGç³»ç»Ÿ

    æ”¯æŒæ‰¹é‡æŸ¥è¯¢ã€æ‰¹é‡åµŒå…¥ç­‰
    """

    def __init__(self, retriever, llm_client):
        self.retriever = retriever
        self.llm_client = llm_client

    def batch_query(self, queries: List[str],
                   batch_size: int = 10) -> List[Dict]:
        """
        æ‰¹é‡æŸ¥è¯¢

        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨
            batch_size: æ‰¹å¤§å°

        Returns:
            ç­”æ¡ˆåˆ—è¡¨
        """
        results = []

        # æ‰¹é‡åµŒå…¥ï¼ˆå¦‚æœæ”¯æŒï¼‰
        all_embeddings = self._batch_embed(queries, batch_size)

        # æ‰¹é‡æ£€ç´¢
        for i in range(0, len(queries), batch_size):
            batch_queries = queries[i:i + batch_size]
            batch_embeddings = all_embeddings[i:i + batch_size]

            # æ£€ç´¢
            batch_results = self._batch_retrieve(batch_queries, batch_embeddings)

            # ç”Ÿæˆç­”æ¡ˆ
            for query, retrieved_docs in zip(batch_queries, batch_results):
                answer = self._generate_answer(query, retrieved_docs)
                results.append(answer)

        return results

    def _batch_embed(self, queries: List[str],
                    batch_size: int) -> List[List[float]]:
        """
        æ‰¹é‡åµŒå…¥æŸ¥è¯¢

        ä¼˜åŒ–ï¼šæ‰¹é‡è°ƒç”¨åµŒå…¥æ¨¡å‹
        """
        all_embeddings = []

        for i in range(0, len(queries), batch_size):
            batch = queries[i:i + batch_size]
            # æ‰¹é‡åµŒå…¥ï¼ˆå‡è®¾retrieveræ”¯æŒï¼‰
            embeddings = self.retriever.embed_batch(batch)
            all_embeddings.extend(embeddings)

        return all_embeddings

    def _batch_retrieve(self,
                       queries: List[str],
                       embeddings: List[List[float]]) -> List[List[Dict]]:
        """
        æ‰¹é‡æ£€ç´¢
        """
        results = []
        for query, embedding in zip(queries, embeddings):
            docs = self.retriever.retrieve_by_embedding(embedding)
            results.append(docs)
        return results

    def _generate_answer(self, query: str, docs: List[Dict]) -> Dict:
        """
        ç”Ÿæˆç­”æ¡ˆ
        """
        context = "\n".join([doc['text'] for doc in docs[:3]])

        # è°ƒç”¨LLM
        prompt = f"åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜ï¼š\n\n{context}\n\né—®é¢˜ï¼š{query}\nç­”æ¡ˆï¼š"

        # æ¨¡æ‹ŸLLMè°ƒç”¨
        return {
            'answer': f'åŸºäº{len(docs)}ä¸ªæ–‡æ¡£ç”Ÿæˆçš„ç­”æ¡ˆ...',
            'sources': [doc['id'] for doc in docs]
        }


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æ¨¡æ‹ŸRAGç³»ç»Ÿ
    class MockRAGSystem:
        def query(self, query: str) -> Dict:
            time.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            return {'query': query, 'answer': f'ç­”æ¡ˆ: {query}'}

    rag = MockRAGSystem()

    # æµ‹è¯•æŸ¥è¯¢
    queries = [f"æŸ¥è¯¢{i+1}" for i in range(20)]

    print("\n" + "="*80)
    print("æ‰¹å¤„ç†æ€§èƒ½æµ‹è¯•")
    print("="*80 + "\n")

    # æ— æ‰¹å¤„ç†
    print("æ–¹å¼1: é€ä¸ªå¤„ç†")
    start = time.time()
    results_single = [rag.query(q) for q in queries]
    time_single = time.time() - start
    print(f"  æ—¶é—´: {time_single:.2f}ç§’\n")

    # æ‰¹å¤„ç†
    print("æ–¹å¼2: æ‰¹å¤„ç†")
    processor = BatchProcessor(
        batch_size=5,
        process_function=rag.query,
        max_workers=4
    )

    start = time.time()
    results_batch = processor.process(queries)
    time_batch = time.time() - start
    print(f"  æ—¶é—´: {time_batch:.2f}ç§’\n")

    # å¯¹æ¯”
    print("="*80)
    print("æ€§èƒ½å¯¹æ¯”")
    print("="*80)
    print(f"é€ä¸ªå¤„ç†: {time_single:.2f}ç§’")
    print(f"æ‰¹å¤„ç†:   {time_batch:.2f}ç§’")
    print(f"æå‡:     {time_single/time_batch:.2f}x")
    print(f"èŠ‚çœ:     {((time_single - time_batch)/time_single * 100):.1f}%")
```

---

## 11.4 å¹¶å‘ä¼˜åŒ–

### 11.4.1 Pythonå¹¶å‘æ¨¡å‹

```
å¹¶å‘æ¨¡å‹å¯¹æ¯”ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ¨¡å‹          é€‚ç”¨åœºæ™¯              GILå½±å“        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å¤šçº¿ç¨‹          I/Oå¯†é›†å‹             å—é™åˆ¶        â”‚
â”‚  (threading)    - ç½‘ç»œè¯·æ±‚                          â”‚
â”‚                  - æ–‡ä»¶è¯»å†™                         â”‚
â”‚                  - æ•°æ®åº“æŸ¥è¯¢                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å¤šè¿›ç¨‹          CPUå¯†é›†å‹             ä¸å—é™åˆ¶      â”‚
â”‚  (multiprocessing) - è®¡ç®—å¯†é›†                       â”‚
â”‚                  - æ•°æ®å¤„ç†                         â”‚
â”‚                  - æ¨¡å‹æ¨ç†                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å¼‚æ­¥I/O         é«˜å¹¶å‘I/O            ä¸å—é™åˆ¶      â”‚
â”‚  (asyncio)      - å¤§é‡ç½‘ç»œè¯·æ±‚                     â”‚
â”‚                  - WebSocket                       â”‚
â”‚                  - å®æ—¶æ•°æ®æµ                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 11.4.2 å¹¶å‘å®ç°

**å¤šçº¿ç¨‹ï¼ˆé€‚åˆI/Oå¯†é›†ï¼‰**

```python
# æ–‡ä»¶åï¼šconcurrent_rag.py
"""
å¹¶å‘RAGå®ç°
"""

from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import asyncio
import time
from typing import List, Dict, Callable


class ConcurrentRAGSystem:
    """
    å¹¶å‘RAGç³»ç»Ÿ

    æ”¯æŒå¤šçº¿ç¨‹å¤„ç†å¤šä¸ªæŸ¥è¯¢
    """

    def __init__(self, rag_pipeline: Callable, max_workers: int = 10):
        self.rag_pipeline = rag_pipeline
        self.max_workers = max_workers

    def query_concurrent(self, queries: List[str]) -> List[Dict]:
        """
        å¹¶å‘æŸ¥è¯¢ï¼ˆå¤šçº¿ç¨‹ï¼‰

        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨

        Returns:
            ç­”æ¡ˆåˆ—è¡¨ï¼ˆä¿æŒåŸå§‹é¡ºåºï¼‰
        """
        results = [None] * len(queries)

        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_index = {
                executor.submit(self.rag_pipeline, query): idx
                for idx, query in enumerate(queries)
            }

            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_index):
                idx = future_to_index[future]
                try:
                    results[idx] = future.result()
                    print(f"æŸ¥è¯¢ {idx + 1}/{len(queries)} å®Œæˆ")
                except Exception as e:
                    print(f"æŸ¥è¯¢ {idx + 1} å¤±è´¥: {e}")
                    results[idx] = {'error': str(e)}

        return results

    def query_sequential(self, queries: List[str]) -> List[Dict]:
        """
        é¡ºåºæŸ¥è¯¢ï¼ˆå¯¹æ¯”ï¼‰
        """
        results = []
        for query in queries:
            result = self.rag_pipeline(query)
            results.append(result)
        return results


# å¼‚æ­¥RAGç³»ç»Ÿ
class AsyncRAGSystem:
    """
    å¼‚æ­¥RAGç³»ç»Ÿ

    ä½¿ç”¨asyncioå®ç°é«˜å¹¶å‘
    """

    def __init__(self):
        pass

    async def query_async(self, query: str) -> Dict:
        """
        å¼‚æ­¥æŸ¥è¯¢
        """
        # å¼‚æ­¥åµŒå…¥
        embedding = await self._embed_async(query)

        # å¼‚æ­¥æ£€ç´¢
        docs = await self._retrieve_async(embedding)

        # å¼‚æ­¥ç”Ÿæˆç­”æ¡ˆ
        answer = await self._generate_async(query, docs)

        return answer

    async def _embed_async(self, query: str) -> List[float]:
        """
        å¼‚æ­¥åµŒå…¥ï¼ˆæ¨¡æ‹Ÿï¼‰
        """
        await asyncio.sleep(0.1)  # æ¨¡æ‹ŸI/O
        return [0.1] * 768

    async def _retrieve_async(self, embedding: List[float]) -> List[Dict]:
        """
        å¼‚æ­¥æ£€ç´¢ï¼ˆæ¨¡æ‹Ÿï¼‰
        """
        await asyncio.sleep(0.2)  # æ¨¡æ‹ŸI/O
        return [{'id': 'doc1', 'text': 'ç›¸å…³æ–‡æ¡£'}]

    async def _generate_async(self, query: str, docs: List[Dict]) -> Dict:
        """
        å¼‚æ­¥ç”Ÿæˆç­”æ¡ˆï¼ˆæ¨¡æ‹Ÿï¼‰
        """
        await asyncio.sleep(1.0)  # æ¨¡æ‹ŸLLMè°ƒç”¨
        return {'answer': f'å¼‚æ­¥ç­”æ¡ˆ: {query}'}

    async def batch_query_async(self, queries: List[str]) -> List[Dict]:
        """
        æ‰¹é‡å¼‚æ­¥æŸ¥è¯¢
        """
        tasks = [self.query_async(q) for q in queries]
        return await asyncio.gather(*tasks)


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æ¨¡æ‹ŸRAGæµç¨‹
    def mock_rag_pipeline(query: str) -> Dict:
        """æ¨¡æ‹ŸRAGæµç¨‹ï¼ˆI/Oå¯†é›†ï¼‰"""
        time.sleep(0.5)  # æ¨¡æ‹ŸI/Oç­‰å¾…
        return {'query': query, 'answer': f'ç­”æ¡ˆ: {query}'}

    # æµ‹è¯•æŸ¥è¯¢
    queries = [f"æŸ¥è¯¢{i+1}" for i in range(10)]

    print("\n" + "="*80)
    print("å¹¶å‘æ€§èƒ½æµ‹è¯•")
    print("="*80 + "\n")

    # æ–¹å¼1ï¼šé¡ºåºå¤„ç†
    print("æ–¹å¼1: é¡ºåºå¤„ç†")
    rag = ConcurrentRAGSystem(mock_rag_pipeline, max_workers=1)

    start = time.time()
    results_sequential = rag.query_sequential(queries)
    time_sequential = time.time() - start

    print(f"  æ—¶é—´: {time_sequential:.2f}ç§’")
    print(f"  å¹³å‡æ¯ä¸ªæŸ¥è¯¢: {time_sequential/len(queries):.2f}ç§’\n")

    # æ–¹å¼2ï¼šå¹¶å‘å¤„ç†ï¼ˆå¤šçº¿ç¨‹ï¼‰
    print("æ–¹å¼2: å¹¶å‘å¤„ç†ï¼ˆå¤šçº¿ç¨‹ï¼‰")
    rag = ConcurrentRAGSystem(mock_rag_pipeline, max_workers=10)

    start = time.time()
    results_concurrent = rag.query_concurrent(queries)
    time_concurrent = time.time() - start

    print(f"  æ—¶é—´: {time_concurrent:.2f}ç§’")
    print(f"  å¹³å‡æ¯ä¸ªæŸ¥è¯¢: {time_concurrent/len(queries):.2f}ç§’\n")

    # æ–¹å¼3ï¼šå¼‚æ­¥å¤„ç†
    print("æ–¹å¼3: å¼‚æ­¥å¤„ç†ï¼ˆasyncioï¼‰")
    async_rag = AsyncRAGSystem()

    start = time.time()
    results_async = asyncio.run(async_rag.batch_query_async(queries))
    time_async = time.time() - start

    print(f"  æ—¶é—´: {time_async:.2f}ç§’")
    print(f"  å¹³å‡æ¯ä¸ªæŸ¥è¯¢: {time_async/len(queries):.2f}ç§’\n")

    # å¯¹æ¯”
    print("="*80)
    print("æ€§èƒ½å¯¹æ¯”")
    print("="*80)
    print(f"é¡ºåºå¤„ç†:  {time_sequential:.2f}ç§’ (åŸºå‡†)")
    print(f"å¤šçº¿ç¨‹:    {time_concurrent:.2f}ç§’ ({time_sequential/time_concurrent:.2f}x)")
    print(f"å¼‚æ­¥:      {time_async:.2f}ç§’ ({time_sequential/time_async:.2f}x)")
```

---

## 11.5 å†…å­˜ä¼˜åŒ–

### 11.5.1 å†…å­˜é—®é¢˜è¯†åˆ«

**å¸¸è§å†…å­˜é—®é¢˜**ï¼š

```
é—®é¢˜1ï¼šæ–‡æ¡£å…¨éƒ¨åŠ è½½åˆ°å†…å­˜
  ç°è±¡ï¼šå†…å­˜å ç”¨é«˜
  è§£å†³ï¼šæµå¼å¤„ç†ï¼ŒæŒ‰éœ€åŠ è½½

é—®é¢˜2ï¼šåµŒå…¥å‘é‡å ç”¨å¤§
  ç°è±¡ï¼š100ä¸‡æ–‡æ¡£ * 768ç»´ * 4å­—èŠ‚ = 2.9GB
  è§£å†³ï¼šä½¿ç”¨é‡åŒ–ï¼ˆfloat16 -> 2å­—èŠ‚ï¼‰

é—®é¢˜3ï¼šç¼“å­˜æ— é™å¢é•¿
  ç°è±¡ï¼šå†…å­˜æŒç»­å¢é•¿
  è§£å†³ï¼šLRUæ·˜æ±°ï¼Œè®¾ç½®å¤§å°ä¸Šé™

é—®é¢˜4ï¼šLLMä¸Šä¸‹æ–‡ç´¯ç§¯
  ç°è±¡ï¼šé•¿å¯¹è¯å¯¼è‡´å†…å­˜å¢é•¿
  è§£å†³ï¼šé™åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œå®šæœŸæ¸…ç†
```

### 11.5.2 ä¼˜åŒ–ç­–ç•¥

**ç­–ç•¥1ï¼šç”Ÿæˆå™¨**

```python
# æ–‡ä»¶åï¼šmemory_optimization.py
"""
å†…å­˜ä¼˜åŒ–å®ç°
"""

def load_documents_lazy(file_path: str):
    """
    æƒ°æ€§åŠ è½½æ–‡æ¡£ï¼ˆç”Ÿæˆå™¨ï¼‰

    ä¼˜ç‚¹ï¼šä¸ä¼šä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ–‡æ¡£åˆ°å†…å­˜

    Yield:
        æ–‡æ¡£æ–‡æœ¬
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            yield line.strip()


# å¯¹æ¯”ï¼šä¸€æ¬¡æ€§åŠ è½½ vs æƒ°æ€§åŠ è½½

def load_documents_all(file_path: str) -> List[str]:
    """
    ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ–‡æ¡£

    é—®é¢˜ï¼šå¤§æ–‡ä»¶ä¼šå¯¼è‡´å†…å­˜æº¢å‡º
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        return [line.strip() for line in f]


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æ¨¡æ‹Ÿå¤§æ–‡ä»¶
    import tempfile
    import os

    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
    temp_file = tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt')
    for i in range(100000):
        temp_file.write(f"æ–‡æ¡£{i}çš„å†…å®¹...\n")
    temp_file_path = temp_file.name
    temp_file.close()

    print("\n" + "="*80)
    print("å†…å­˜ä¼˜åŒ–å¯¹æ¯”")
    print("="*80 + "\n")

    # æ–¹å¼1ï¼šä¸€æ¬¡æ€§åŠ è½½
    print("æ–¹å¼1: ä¸€æ¬¡æ€§åŠ è½½")
    import tracemalloc
    tracemalloc.start()

    docs_all = load_documents_all(temp_file_path)
    current, peak = tracemalloc.get_traced_memory()
    print(f"  å½“å‰å†…å­˜: {current / 1024 / 1024:.2f} MB")
    print(f"  å³°å€¼å†…å­˜: {peak / 1024 / 1024:.2f} MB")
    print(f"  æ–‡æ¡£æ•°é‡: {len(docs_all)}\n")

    tracemalloc.stop()

    # æ–¹å¼2ï¼šæƒ°æ€§åŠ è½½
    print("æ–¹å¼2: æƒ°æ€§åŠ è½½ï¼ˆç”Ÿæˆå™¨ï¼‰")
    tracemalloc.start()

    docs_lazy = load_documents_lazy(temp_file_path)
    count = 0
    for doc in docs_lazy:
        count += 1
        if count >= 10:  # åªå¤„ç†å‰10ä¸ª
            break

    current, peak = tracemalloc.get_traced_memory()
    print(f"  å½“å‰å†…å­˜: {current / 1024 / 1024:.2f} MB")
    print(f"  å³°å€¼å†…å­˜: {peak / 1024 / 1024:.2f} MB")
    print(f"  å¤„ç†æ–‡æ¡£: {count} ä¸ª\n")

    tracemalloc.stop()

    # æ¸…ç†
    os.unlink(temp_file_path)
```

**ç­–ç•¥2ï¼šå‘é‡é‡åŒ–**

```python
import numpy as np


class QuantizedVectorStore:
    """
    é‡åŒ–çš„å‘é‡å­˜å‚¨

    ä½¿ç”¨float16ä»£æ›¿float32ï¼ŒèŠ‚çœ50%å†…å­˜
    """

    def __init__(self):
        self.vectors = None
        self.dtype = np.float16  # ä½¿ç”¨åŠç²¾åº¦æµ®ç‚¹æ•°

    def add_vectors(self, vectors: np.ndarray):
        """
        æ·»åŠ å‘é‡ï¼ˆè‡ªåŠ¨é‡åŒ–ï¼‰
        """
        if vectors.dtype != self.dtype:
            vectors = vectors.astype(self.dtype)
        self.vectors = vectors

    def get_memory_usage(self) -> Dict:
        """
        è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ
        """
        if self.vectors is None:
            return {'memory_mb': 0}

        memory_mb = self.vectors.nbytes / 1024 / 1024
        return {
            'memory_mb': memory_mb,
            'num_vectors': len(self.vectors),
            'dimension': self.vectors.shape[1],
            'dtype': str(self.vectors.dtype)
        }


# å¯¹æ¯”ï¼šfloat32 vs float16
if __name__ == "__main__":
    print("\n" + "="*80)
    print("å‘é‡é‡åŒ–å¯¹æ¯”")
    print("="*80 + "\n")

    # ç”Ÿæˆç¤ºä¾‹å‘é‡
    num_vectors = 100000
    dimension = 768

    print(f"å‘é‡æ•°é‡: {num_vectors}")
    print(f"å‘é‡ç»´åº¦: {dimension}\n")

    # float32
    vectors_f32 = np.random.randn(num_vectors, dimension).astype(np.float32)
    memory_f32 = vectors_f32.nbytes / 1024 / 1024

    print(f"Float32:")
    print(f"  å†…å­˜: {memory_f32:.2f} MB")
    print(f"  æ¯ä¸ª: {vectors_f32[0].nbytes / 1024:.2f} KB\n")

    # float16
    vectors_f16 = vectors_f32.astype(np.float16)
    memory_f16 = vectors_f16.nbytes / 1024 / 1024

    print(f"Float16:")
    print(f"  å†…å­˜: {memory_f16:.2f} MB")
    print(f"  æ¯ä¸ª: {vectors_f16[0].nbytes / 1024:.2f} KB\n")

    print(f"èŠ‚çœ: {(memory_f32 - memory_f16) / memory_f32 * 100:.1f}%")
```

**ç­–ç•¥3ï¼šä¸Šä¸‹æ–‡ç®¡ç†**

```python
class ContextManagedRAG:
    """
    å¸¦ä¸Šä¸‹æ–‡ç®¡ç†çš„RAGç³»ç»Ÿ

    è‡ªåŠ¨æ¸…ç†ä¸å†ä½¿ç”¨çš„èµ„æº
    """

    def __init__(self, max_context_length: int = 10):
        self.max_context_length = max_context_length
        self.conversation_history = []

    def query(self, query: str) -> Dict:
        """
        æŸ¥è¯¢ï¼ˆè‡ªåŠ¨ç®¡ç†ä¸Šä¸‹æ–‡ï¼‰
        """
        # æ·»åŠ åˆ°å†å²
        self.conversation_history.append({
            'query': query,
            'timestamp': time.time()
        })

        # é™åˆ¶å†å²é•¿åº¦
        if len(self.conversation_history) > self.max_context_length:
            # ç§»é™¤æœ€æ—§çš„è®°å½•
            removed = self.conversation_history.pop(0)
            print(f"æ¸…ç†æ—§ä¸Šä¸‹æ–‡: {removed['query'][:30]}...")

        # è·å–æœ€è¿‘çš„å†å²
        recent_history = self.conversation_history[-5:]

        # å¤„ç†æŸ¥è¯¢
        return {'answer': f'åŸºäº{len(recent_history)}è½®ä¸Šä¸‹æ–‡çš„ç­”æ¡ˆ'}

    def clear_history(self):
        """
        æ¸…ç©ºå†å²
        """
        self.conversation_history.clear()
        print("ä¸Šä¸‹æ–‡å·²æ¸…ç©º")
```

---

## 11.6 ç»¼åˆä¼˜åŒ–æ¡ˆä¾‹

### 11.6.1 å®Œæ•´çš„ä¼˜åŒ–æ–¹æ¡ˆ

```python
# æ–‡ä»¶åï¼šoptimized_rag_system.py
"""
ç»¼åˆä¼˜åŒ–çš„RAGç³»ç»Ÿ

é›†æˆï¼šç¼“å­˜ + æ‰¹å¤„ç† + å¹¶å‘ + å†…å­˜ä¼˜åŒ–
"""

from typing import List, Dict, Optional
import time
from concurrent.futures import ThreadPoolExecutor


class OptimizedRAGSystem:
    """
    ä¼˜åŒ–çš„RAGç³»ç»Ÿ

    ç‰¹æ€§ï¼š
    1. å¤šå±‚ç¼“å­˜ï¼ˆL1å†…å­˜ + L2Redisï¼‰
    2. æ‰¹å¤„ç†
    3. å¹¶å‘å¤„ç†
    4. å†…å­˜ä¼˜åŒ–

    æ€§èƒ½ç›®æ ‡ï¼š
    - ç¼“å­˜å‘½ä¸­ç‡ > 80%
    - ååé‡ > 100 queries/s
    - å¹³å‡å“åº”æ—¶é—´ < 100msï¼ˆå‘½ä¸­ç¼“å­˜ï¼‰
    """

    def __init__(self,
                 rag_pipeline,
                 l1_cache_size: int = 1000,
                 max_workers: int = 10):

        # RAGæµç¨‹
        self.rag_pipeline = rag_pipeline

        # ç¼“å­˜
        self.l1_cache = MemoryCache(max_size=l1_cache_size, ttl=3600)
        self.l2_cache = None  # å¯é€‰ï¼šRedisCache()

        # å¹¶å‘
        self.max_workers = max_workers

        # ç»Ÿè®¡
        self.stats = {
            'total_queries': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'total_time': 0.0
        }

    def query(self, query: str) -> Dict:
        """
        æŸ¥è¯¢ï¼ˆå¸¦ç¼“å­˜ï¼‰
        """
        start_time = time.time()
        self.stats['total_queries'] += 1

        # L1ç¼“å­˜æŸ¥æ‰¾
        result = self.l1_cache.get(query)
        if result is not None:
            self.stats['cache_hits'] += 1
            self.stats['total_time'] += time.time() - start_time
            return {**result, 'cache': 'L1'}

        # L2ç¼“å­˜æŸ¥æ‰¾ï¼ˆå¦‚æœé…ç½®ï¼‰
        if self.l2_cache:
            result = self.l2_cache.get(query)
            if result is not None:
                self.stats['cache_hits'] += 1
                # å›å¡«L1
                self.l1_cache.set(query, result)
                self.stats['total_time'] += time.time() - start_time
                return {**result, 'cache': 'L2'}

        # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡ŒRAG
        self.stats['cache_misses'] += 1
        result = self.rag_pipeline(query)

        # å­˜å‚¨åˆ°ç¼“å­˜
        cache_data = {
            'answer': result['answer'],
            'sources': result.get('sources', [])
        }
        self.l1_cache.set(query, cache_data)

        if self.l2_cache:
            self.l2_cache.set(query, cache_data)

        self.stats['total_time'] += time.time() - start_time
        return {**result, 'cache': 'None'}

    def batch_query(self, queries: List[str],
                   batch_size: int = 10) -> List[Dict]:
        """
        æ‰¹é‡æŸ¥è¯¢ï¼ˆå¹¶å‘ï¼‰
        """
        results = [None] * len(queries)

        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_index = {
                executor.submit(self.query, query): idx
                for idx, query in enumerate(queries)
            }

            for future in future_to_index:
                idx = future_to_index[future]
                results[idx] = future.result()

        return results

    def get_stats(self) -> Dict:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯
        """
        total = self.stats['total_queries']
        hits = self.stats['cache_hits']
        misses = self.stats['cache_misses']

        avg_time = self.stats['total_time'] / total if total > 0 else 0
        hit_rate = hits / total if total > 0 else 0

        return {
            'total_queries': total,
            'cache_hits': hits,
            'cache_misses': misses,
            'hit_rate': hit_rate,
            'avg_response_time_ms': avg_time * 1000,
            'throughput_qps': total / max(self.stats['total_time'], 0.001)
        }


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æ¨¡æ‹ŸRAGæµç¨‹
    def mock_rag(query: str) -> Dict:
        time.sleep(0.2)  # æ¨¡æ‹Ÿå¤„ç†
        return {
            'answer': f'ç­”æ¡ˆ: {query}',
            'sources': ['doc1']
        }

    # åˆ›å»ºä¼˜åŒ–çš„RAGç³»ç»Ÿ
    rag = OptimizedRAGSystem(
        rag_pipeline=mock_rag,
        l1_cache_size=1000,
        max_workers=10
    )

    # æµ‹è¯•ï¼šåŒ…å«é‡å¤æŸ¥è¯¢
    test_queries = [
        "æŸ¥è¯¢1", "æŸ¥è¯¢2", "æŸ¥è¯¢1",  # é‡å¤
        "æŸ¥è¯¢3", "æŸ¥è¯¢2",          # é‡å¤
        "æŸ¥è¯¢4", "æŸ¥è¯¢5", "æŸ¥è¯¢1",  # é‡å¤
        "æŸ¥è¯¢6"
    ]

    print("\n" + "="*80)
    print("ä¼˜åŒ–RAGç³»ç»Ÿæµ‹è¯•")
    print("="*80 + "\n")

    # å•ä¸ªæŸ¥è¯¢
    for query in test_queries:
        result = rag.query(query)
        print(f"{query} â†’ ç¼“å­˜: {result['cache']}")

    # ç»Ÿè®¡
    stats = rag.get_stats()

    print("\n" + "="*80)
    print("æ€§èƒ½ç»Ÿè®¡")
    print("="*80)
    print(f"æ€»æŸ¥è¯¢æ•°: {stats['total_queries']}")
    print(f"ç¼“å­˜å‘½ä¸­: {stats['cache_hits']}")
    print(f"ç¼“å­˜æœªå‘½ä¸­: {stats['cache_misses']}")
    print(f"å‘½ä¸­ç‡: {stats['hit_rate']*100:.1f}%")
    print(f"å¹³å‡å“åº”æ—¶é—´: {stats['avg_response_time_ms']:.2f} ms")
    print(f"ååé‡: {stats['throughput_qps']:.2f} QPS")
```

---

## ç»ƒä¹ é¢˜

### ç»ƒä¹ 1ï¼šåŸºç¡€ç»ƒä¹  - å®ç°å†…å­˜ç¼“å­˜

**é¢˜ç›®**ï¼šå®ç°ä¸€ä¸ªLRUç¼“å­˜

**è¦æ±‚**ï¼š
1. æ”¯æŒgetå’Œsetæ“ä½œ
2. å®¹é‡æ»¡æ—¶è‡ªåŠ¨æ·˜æ±°æœ€ä¹…æœªä½¿ç”¨çš„é¡¹
3. æ”¯æŒTTLï¼ˆè¿‡æœŸæ—¶é—´ï¼‰
4. æä¾›ç»Ÿè®¡ä¿¡æ¯

**æç¤º**ï¼š
- ä½¿ç”¨`collections.OrderedDict`ç»´æŠ¤è®¿é—®é¡ºåº
- è®°å½•æ¯ä¸ªkeyçš„è®¿é—®æ—¶é—´æˆ³

---

### ç»ƒä¹ 2ï¼šè¿›é˜¶ç»ƒä¹  - æ‰¹å¤„ç†ä¼˜åŒ–

**é¢˜ç›®**ï¼šä¼˜åŒ–æ‰¹é‡æŸ¥è¯¢æ€§èƒ½

**è¦æ±‚**ï¼š
1. å®ç°æ‰¹é‡æŸ¥è¯¢æ¥å£
2. æ”¯æŒå¹¶å‘å¤„ç†
3. å¯¹æ¯”é¡ºåºå’Œæ‰¹å¤„ç†çš„æ€§èƒ½
4. è¾¾åˆ°3xä»¥ä¸ŠåŠ é€Ÿ

---

### ç»ƒä¹ 3ï¼šæŒ‘æˆ˜é¡¹ç›® - å®Œæ•´çš„ä¼˜åŒ–ç³»ç»Ÿ

**é¡¹ç›®æè¿°**ï¼šæ„å»ºä¸€ä¸ªç”Ÿäº§çº§çš„é«˜æ€§èƒ½RAGç³»ç»Ÿ

**åŠŸèƒ½éœ€æ±‚**ï¼š
1. âœ… å¤šå±‚ç¼“å­˜
2. âœ… æ‰¹å¤„ç†
3. âœ… å¹¶å‘å¤„ç†
4. âœ… å†…å­˜ä¼˜åŒ–
5. âœ… æ€§èƒ½ç›‘æ§

**æ€§èƒ½ç›®æ ‡**ï¼š
- ç¼“å­˜å‘½ä¸­ç‡ > 80%
- ååé‡ > 50 QPS
- P95å»¶è¿Ÿ < 500ms
- å†…å­˜å ç”¨ < 4GBï¼ˆç™¾ä¸‡çº§æ–‡æ¡£ï¼‰

---

## æ€»ç»“

### æœ¬ç« è¦ç‚¹å›é¡¾

1. **æ€§èƒ½ç“¶é¢ˆè¯†åˆ«**
   - LLMç”Ÿæˆæ˜¯æœ€å¤§ç“¶é¢ˆï¼ˆ~80%æ—¶é—´ï¼‰
   - ä½¿ç”¨profilingå·¥å…·å®šä½é—®é¢˜
   - é‡ç‚¹å…³æ³¨çƒ­ç‚¹å‡½æ•°

2. **ç¼“å­˜ç­–ç•¥**
   - L1å†…å­˜ç¼“å­˜ï¼šå¿«é€Ÿï¼Œå®¹é‡å°
   - L2 Redisç¼“å­˜ï¼šç¨æ…¢ï¼Œå®¹é‡å¤§
   - å¤šå±‚ç¼“å­˜ï¼š90%+å‘½ä¸­ç‡

3. **æ‰¹å¤„ç†ä¼˜åŒ–**
   - æ‰¹é‡åµŒå…¥ï¼šå‡å°‘APIè°ƒç”¨
   - æ‰¹é‡æ£€ç´¢ï¼šæå‡ååé‡
   - æ‰¹é‡ç”Ÿæˆï¼šåˆ©ç”¨å¹¶è¡Œèƒ½åŠ›

4. **å¹¶å‘ä¼˜åŒ–**
   - å¤šçº¿ç¨‹ï¼šé€‚åˆI/Oå¯†é›†
   - å¤šè¿›ç¨‹ï¼šé€‚åˆCPUå¯†é›†
   - å¼‚æ­¥ï¼šé€‚åˆé«˜å¹¶å‘

5. **å†…å­˜ä¼˜åŒ–**
   - ç”Ÿæˆå™¨ï¼šæƒ°æ€§åŠ è½½
   - å‘é‡é‡åŒ–ï¼šèŠ‚çœ50%å†…å­˜
   - ä¸Šä¸‹æ–‡ç®¡ç†ï¼šé™åˆ¶å†å²é•¿åº¦

### å­¦ä¹ æ£€æŸ¥æ¸…å•

- [ ] èƒ½å¤Ÿä½¿ç”¨profilingå·¥å…·åˆ†ææ€§èƒ½
- [ ] ç†è§£å¤šå±‚ç¼“å­˜æ¶æ„
- [ ] æŒæ¡æ‰¹å¤„ç†ä¼˜åŒ–æ–¹æ³•
- [ ] èƒ½å¤Ÿåº”ç”¨å¹¶å‘å¤„ç†
- [ ] ç†è§£å†…å­˜ä¼˜åŒ–ç­–ç•¥
- [ ] èƒ½å¤Ÿæ„å»ºé«˜æ€§èƒ½RAGç³»ç»Ÿ

### ä¸‹ä¸€æ­¥å­¦ä¹ 

- **ä¸‹ä¸€ç« **ï¼š[ç¬¬12ç« ï¼šç»¼åˆé¡¹ç›®ä¼˜åŒ–](./12-ç»¼åˆé¡¹ç›®ä¼˜åŒ–.md)
- **ç›¸å…³ç« èŠ‚**ï¼š
  - [ç¬¬9ç« ï¼šæ··åˆæ£€ç´¢ä¸é‡æ’åº](./09-æ··åˆæ£€ç´¢ä¸é‡æ’åº.md)
  - [ç¬¬10ç« ï¼šé«˜çº§RAGæ¨¡å¼](./10-é«˜çº§RAGæ¨¡å¼.md)
- **æ‰©å±•é˜…è¯»**ï¼š
  - Pythonæ€§èƒ½ä¼˜åŒ–: https://docs.python.org/3/library/profile.html
  - Redisç¼“å­˜: https://redis.io/docs/manual/patterns/caching/

---

**è¿”å›ç›®å½•** | **ä¸Šä¸€ç« ** | **ä¸‹ä¸€ç« **

---

**æœ¬ç« ç»“æŸ**

> æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Ÿæ¬¢è¿æäº¤Issueæˆ–PRåˆ°æ•™ç¨‹ä»“åº“ï¼
