# ç¬¬9ç« ï¼šæ··åˆæ£€ç´¢ä¸é‡æ’åº

> å•ä¸€æ£€ç´¢æ–¹æ³•æ€»æœ‰å±€é™ã€‚æ··åˆæ£€ç´¢ç»“åˆå‘é‡æœç´¢å’Œå…³é”®è¯åŒ¹é…ï¼Œå†é€šè¿‡é‡æ’åºç²¾ç‚¼ç»“æœï¼Œå¯å°†æ£€ç´¢è´¨é‡æå‡20-30%ï¼

---

## ğŸ“š å­¦ä¹ ç›®æ ‡

å­¦å®Œæœ¬ç« åï¼Œä½ å°†èƒ½å¤Ÿï¼š

- [ ] ç†è§£æ··åˆæ£€ç´¢çš„åŸç†å’Œä¼˜åŠ¿
- [ ] å®ç°å‘é‡æ£€ç´¢ä¸BM25çš„èåˆ
- [ ] æŒæ¡RRFï¼ˆReciprocal Rank Fusionï¼‰ç®—æ³•
- [ ] åº”ç”¨é‡æ’åºæŠ€æœ¯ç²¾ç‚¼ç»“æœ
- [ ] å°†æ£€ç´¢è´¨é‡æå‡20-30%

**é¢„è®¡å­¦ä¹ æ—¶é—´**ï¼š3å°æ—¶
**éš¾åº¦ç­‰çº§**ï¼šâ­â­â­â­â˜†

---

## å‰ç½®çŸ¥è¯†

åœ¨å¼€å§‹æœ¬ç« å­¦ä¹ å‰ï¼Œä½ éœ€è¦å…·å¤‡ï¼š

- [ ] å®Œæˆæ¨¡å—1çš„åŸºç¡€RAGå®ç°
- [ ] ç†è§£å‘é‡æ£€ç´¢åŸç†ï¼ˆç¬¬6ç« ï¼‰
- [ ] äº†è§£æŸ¥è¯¢å¢å¼ºæŠ€æœ¯ï¼ˆç¬¬8ç« ï¼‰

**ç¯å¢ƒè¦æ±‚**ï¼š
- Python >= 3.9
- rank-bm25ï¼ˆBM25æ£€ç´¢ï¼‰
- sentence-transformersï¼ˆé‡æ’åºæ¨¡å‹ï¼‰
- å‘é‡æ•°æ®åº“ï¼ˆChroma/Qdrantï¼‰

---

## 9.1 ä¸ºä»€ä¹ˆéœ€è¦æ··åˆæ£€ç´¢ï¼Ÿ

### 9.1.1 å•ä¸€æ£€ç´¢æ–¹æ³•çš„å±€é™

**å‘é‡æ£€ç´¢çš„å¼±ç‚¹**

```
åœºæ™¯1ï¼šç²¾ç¡®åŒ¹é…å¤±è´¥

ç”¨æˆ·æŸ¥è¯¢ï¼š"iPhone 15 Pro Maxçš„A17èŠ¯ç‰‡ä¸»é¢‘æ˜¯å¤šå°‘ï¼Ÿ"

å‘é‡æ£€ç´¢ç»“æœï¼š
âŒ å¯èƒ½è¿”å›"iPhone 15çš„è§„æ ¼ä»‹ç»"ï¼ˆè¯­ä¹‰ç›¸ä¼¼ï¼Œä½†æ— å…·ä½“æ•°æ®ï¼‰
âŒ å¯èƒ½è¿”å›"A17èŠ¯ç‰‡çš„æ¶æ„åˆ†æ"ï¼ˆç›¸å…³ä½†æ— ä¸»é¢‘ä¿¡æ¯ï¼‰
âœ… ç†æƒ³ç»“æœï¼šåŒ…å«"3.78 GHz"ç²¾ç¡®æ•°æ®çš„æ–‡æ¡£

é—®é¢˜ï¼šå‘é‡æœç´¢ä¾§é‡è¯­ä¹‰ç›¸ä¼¼ï¼Œå¿½ç•¥å…³é”®è¯ç²¾ç¡®åŒ¹é…
```

```
åœºæ™¯2ï¼šä¸“æœ‰åè¯æ£€ç´¢

ç”¨æˆ·æŸ¥è¯¢ï¼š"å¦‚ä½•ä½¿ç”¨LangChainçš„SQLDatabaseChainï¼Ÿ"

å‘é‡æ£€ç´¢ç»“æœï¼š
âŒ "LangChainåŸºç¡€æ•™ç¨‹"
âŒ "SQLæ•°æ®åº“è¿æ¥æ–¹æ³•"
âœ… ç†æƒ³ç»“æœï¼šä¸“é—¨è®²è§£SQLDatabaseChainçš„æ–‡æ¡£

é—®é¢˜ï¼šä¸“æœ‰åè¯çš„åµŒå…¥å¯èƒ½ä¸å‡†ç¡®
```

**BM25æ£€ç´¢çš„å¼±ç‚¹**

```
åœºæ™¯3ï¼šè¯­ä¹‰ç†è§£ä¸è¶³

ç”¨æˆ·æŸ¥è¯¢ï¼š"æ€ä¹ˆè®©æˆ‘çš„ä»£ç è·‘å¾—æ›´å¿«ï¼Ÿ"

BM25æ£€ç´¢ç»“æœï¼š
âŒ åŒ¹é…"ä»£ç "ã€"è·‘"ã€"å¿«"çš„æ–‡æ¡£ï¼ˆå­—é¢åŒ¹é…ï¼‰
âŒ å¯èƒ½è¿”å›"è·‘æ­¥è¿åŠ¨ä»£ç "
âœ… ç†æƒ³ç»“æœï¼š"Pythonæ€§èƒ½ä¼˜åŒ–"ã€"ä»£ç åŠ é€ŸæŠ€å·§"

é—®é¢˜ï¼šå…³é”®è¯åŒ¹é…æ— æ³•ç†è§£è¯­ä¹‰å’Œæ„å›¾
```

```
åœºæ™¯4ï¼šåŒä¹‰è¯ç¼ºå¤±

ç”¨æˆ·æŸ¥è¯¢ï¼š"Pythonæ€§èƒ½è°ƒä¼˜"

BM25æ£€ç´¢ç»“æœï¼š
âŒ åªèƒ½åŒ¹é…"æ€§èƒ½"ã€"è°ƒä¼˜"å…³é”®è¯
âŒ é”™è¿‡åŒ…å«"ä¼˜åŒ–"ã€"åŠ é€Ÿ"ã€"æå‡"çš„æ–‡æ¡£

é—®é¢˜ï¼šæ— æ³•è¯†åˆ«åŒä¹‰è¯å’Œç›¸å…³æ¦‚å¿µ
```

### 9.1.2 æ··åˆæ£€ç´¢çš„ä¼˜åŠ¿

**ä¼˜åŠ¿1ï¼šäº’è¡¥æ€§å¼º**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            æ£€ç´¢æ–¹æ³•å¯¹æ¯”çŸ©é˜µ                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚  å‘é‡æ£€ç´¢                            â”‚
â”‚  âœ“ è¯­ä¹‰ç†è§£å¼º                                   â”‚
â”‚  âœ“ å¤„ç†åŒä¹‰è¯                                   â”‚
â”‚  âœ— ç²¾ç¡®åŒ¹é…å¼±                                   â”‚
â”‚  âœ— å…³é”®è¯æƒé‡ä½                                 â”‚
â”‚                                                 â”‚
â”‚  BM25æ£€ç´¢                           â”‚
â”‚  âœ“ ç²¾ç¡®åŒ¹é…å¼º                                   â”‚
â”‚  âœ“ å…³é”®è¯æƒé‡é«˜                                 â”‚
â”‚  âœ— è¯­ä¹‰ç†è§£å¼±                                   â”‚
â”‚  âœ— åŒä¹‰è¯å¤„ç†å·®                                 â”‚
â”‚                                                 â”‚
â”‚  æ··åˆæ£€ç´¢                     â”‚
â”‚  âœ“ ç»“åˆä¸¤è€…ä¼˜åŠ¿                                 â”‚
â”‚  âœ“ è¯­ä¹‰ + å…³é”®è¯                                â”‚
â”‚  âœ“ é€‚ç”¨åœºæ™¯å¹¿                                   â”‚
â”‚  âœ— å®ç°å¤æ‚åº¦å¢åŠ                                â”‚
â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ä¼˜åŠ¿2ï¼šæ€§èƒ½æå‡æ˜¾è‘—**

æ ¹æ®LlamaIndexçš„å®éªŒæ•°æ®ï¼š

```python
# æ··åˆæ£€ç´¢æ€§èƒ½æå‡ï¼ˆç›¸æ¯”å•ä¸€å‘é‡æ£€ç´¢ï¼‰

æ£€ç´¢æ–¹æ³•          Hit Rate    MRR    å“åº”æ—¶é—´
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ä»…å‘é‡æ£€ç´¢         0.62       0.51    120ms
ä»…BM25æ£€ç´¢         0.58       0.47    80ms
æ··åˆæ£€ç´¢ï¼ˆRRFï¼‰    0.78       0.68    200ms
æ··åˆæ£€ç´¢+é‡æ’åº    0.85       0.76    350ms

æå‡å¹…åº¦ï¼š
  Hit Rate: +37% (å‘é‡) â†’ +47% (å‘é‡+é‡æ’åº)
  MRR: +33% (å‘é‡) â†’ +49% (å‘é‡+é‡æ’åº)
```

**ä¼˜åŠ¿3ï¼šé€‚ç”¨åœºæ™¯å¹¿æ³›**

| åœºæ™¯ | å‘é‡æ£€ç´¢ | BM25 | æ··åˆæ£€ç´¢ |
|------|---------|------|---------|
| **äº‹å®æ€§é—®ç­”** | â­â­ | â­â­â­â­ | â­â­â­â­â­ |
| **æ¦‚å¿µè§£é‡Š** | â­â­â­â­â­ | â­â­ | â­â­â­â­â­ |
| **ä»£ç æœç´¢** | â­â­â­ | â­â­â­â­ | â­â­â­â­â­ |
| **ä¸“æœ‰åè¯** | â­â­ | â­â­â­â­â­ | â­â­â­â­â­ |
| **æ¨¡ç³ŠæŸ¥è¯¢** | â­â­â­â­â­ | â­â­ | â­â­â­â­â­ |

---

## 9.2 æ··åˆæ£€ç´¢å®ç°æ–¹æ³•

### 9.2.1 æ–¹æ³•æ¦‚è§ˆ

```
æ··åˆæ£€ç´¢çš„å®ç°è·¯å¾„ï¼š

è·¯å¾„1ï¼šç®€å•èåˆ
  â”œâ”€ åˆ†åˆ«æ£€ç´¢ï¼šå‘é‡æ£€ç´¢ + BM25æ£€ç´¢
  â”œâ”€ ç»“æœåˆå¹¶ï¼šæ‹¼æ¥ä¸¤ä¸ªç»“æœåˆ—è¡¨
  â””â”€ å»é‡æ’åºï¼šåŸºäºåˆ†æ•°é‡æ–°æ’åº
  ä¼˜ç‚¹ï¼šå®ç°ç®€å•
  ç¼ºç‚¹ï¼šæ•ˆæœä¸€èˆ¬

è·¯å¾„2ï¼šåŠ æƒèåˆ
  â”œâ”€ åˆ†åˆ«æ£€ç´¢ï¼šå‘é‡æ£€ç´¢ + BM25æ£€ç´¢
  â”œâ”€ åˆ†æ•°å½’ä¸€åŒ–ï¼šå°†ä¸åŒåˆ†æ•°å½’ä¸€åŒ–åˆ°[0,1]
  â”œâ”€ åŠ æƒæ±‚å’Œï¼šfinal_score = Î±Â·vector_score + Î²Â·bm25_score
  â””â”€ é‡æ–°æ’åºï¼šåŸºäºæœ€ç»ˆåˆ†æ•°æ’åº
  ä¼˜ç‚¹ï¼šå¯è°ƒèŠ‚æƒé‡
  ç¼ºç‚¹ï¼šéœ€è¦è°ƒå‚

è·¯å¾„3ï¼šRRFèåˆ  â­æ¨è
  â”œâ”€ åˆ†åˆ«æ£€ç´¢ï¼šå‘é‡æ£€ç´¢ + BM25æ£€ç´¢
  â”œâ”€ è®¡ç®—å€’æ•°ç§©ï¼š1/(k+rank)
  â”œâ”€ åˆ†æ•°ç´¯åŠ ï¼šsum(1/(k+rank)) for all retrievers
  â””â”€ é‡æ–°æ’åºï¼šåŸºäºRRFåˆ†æ•°æ’åº
  ä¼˜ç‚¹ï¼šæ— éœ€å½’ä¸€åŒ–ï¼Œé²æ£’æ€§å¼º
  ç¼ºç‚¹ï¼šè¶…å‚æ•°kéœ€è¦è°ƒèŠ‚

è·¯å¾„4ï¼šå­¦ä¹ èåˆ
  â”œâ”€ æ”¶é›†è®­ç»ƒæ•°æ®ï¼šæŸ¥è¯¢+æ–‡æ¡£+ç›¸å…³æ€§æ ‡ç­¾
  â”œâ”€ è®­ç»ƒèåˆæ¨¡å‹ï¼šå­¦ä¹ æœ€ä¼˜èåˆç­–ç•¥
  â””â”€ æ¨¡å‹é¢„æµ‹ï¼šä½¿ç”¨æ¨¡å‹èåˆç»“æœ
  ä¼˜ç‚¹ï¼šæ•ˆæœæœ€å¥½
  ç¼ºç‚¹ï¼šéœ€è¦è®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æº
```

### 9.2.2 RRFç®—æ³•è¯¦è§£

**RRF (Reciprocal Rank Fusion)** æ˜¯ç›®å‰æœ€å®ç”¨çš„èåˆæ–¹æ³•ã€‚

**æ ¸å¿ƒæ€æƒ³**ï¼šå€’æ•°ç§©ç›¸åŠ ï¼Œé¿å…åˆ†æ•°å½’ä¸€åŒ–é—®é¢˜ã€‚

**ç®—æ³•å…¬å¼**ï¼š

```
å¯¹äºæŸ¥è¯¢qå’Œæ–‡æ¡£dï¼ŒRRFåˆ†æ•°ä¸ºï¼š

RRF(q,d) = Î£[i=1 to n]  1 / (k + rank_i(q,d))

å…¶ä¸­ï¼š
  n = æ£€ç´¢å™¨æ•°é‡ï¼ˆå¦‚å‘é‡+BM25 = 2ï¼‰
  rank_i(q,d) = æ–‡æ¡£dåœ¨ç¬¬iä¸ªæ£€ç´¢å™¨ä¸­çš„æ’å
  k = å¹³æ»‘å‚æ•°ï¼ˆé€šå¸¸å–60ï¼‰

ä¸ºä»€ä¹ˆæ˜¯å€’æ•°ï¼Ÿ
  æ’åè¶Šé å‰ â†’ rankè¶Šå° â†’ 1/(k+rank)è¶Šå¤§ â†’ è´¡çŒ®è¶Šå¤§
```

**ç®—æ³•ä¼˜åŠ¿**ï¼š

```
ä¼˜åŠ¿1ï¼šæ— éœ€åˆ†æ•°å½’ä¸€åŒ–
  ä¸åŒæ£€ç´¢å™¨çš„åˆ†æ•°èŒƒå›´ä¸åŒï¼š
  - å‘é‡ç›¸ä¼¼åº¦ï¼š[0, 1]
  - BM25åˆ†æ•°ï¼š[0, +âˆ]
  - ä½¿ç”¨æ’åè€Œéåˆ†æ•°ï¼Œé¿å…å½’ä¸€åŒ–é—®é¢˜

ä¼˜åŠ¿2ï¼šé²æ£’æ€§å¼º
  å¯¹æç«¯å€¼ä¸æ•æ„Ÿï¼š
  - æŸæ£€ç´¢å™¨åˆ†æ•°å¼‚å¸¸ â†’ ä¸å½±å“æ’å â†’ ä¸å½±å“èåˆç»“æœ

ä¼˜åŠ¿3ï¼šå¯è§£é‡Šæ€§å¥½
  æ¯ä¸ªæ£€ç´¢å™¨çš„è´¡çŒ®é€æ˜ï¼š
  - æ–‡æ¡£åœ¨å‘é‡æ£€ç´¢æ’ç¬¬1 â†’ è´¡çŒ® 1/(60+1) = 0.0164
  - æ–‡æ¡£åœ¨BM25æ£€ç´¢æ’ç¬¬5 â†’ è´¡çŒ® 1/(60+5) = 0.0154
  - æ€»RRFåˆ†æ•° = 0.0164 + 0.0154 = 0.0318
```

**RRFç®—æ³•å®ç°**ï¼š

```python
# æ–‡ä»¶åï¼šrrf_fusion.py
"""
RRF (Reciprocal Rank Fusion) å®ç°
ç”¨äºèåˆå¤šä¸ªæ£€ç´¢å™¨çš„ç»“æœ
"""

from typing import List, Dict, Tuple
import numpy as np


class RRFFusion:
    """
    RRFèåˆç®—æ³•

    Args:
        k: å¹³æ»‘å‚æ•°ï¼Œé»˜è®¤60
          - è¾ƒå°çš„kï¼ˆå¦‚30ï¼‰ï¼šæ›´ä¿¡ä»»æ’åé å‰çš„ç»“æœ
          - è¾ƒå¤§çš„kï¼ˆå¦‚100ï¼‰ï¼šæ›´å¹³æ»‘åœ°èåˆæ‰€æœ‰ç»“æœ

    Example:
        >>> rrf = RRFFusion(k=60)
        >>> results = rrf.fuse([vector_results, bm25_results])
        >>> print(results[:5])  # Top-5èåˆç»“æœ
    """

    def __init__(self, k: int = 60):
        self.k = k

    def fuse(self, ranked_results_list: List[List[Tuple[str, float]]]) -> List[Tuple[str, float]]:
        """
        èåˆå¤šä¸ªæ£€ç´¢å™¨çš„ç»“æœ

        Args:
            ranked_results_list: æ£€ç´¢ç»“æœåˆ—è¡¨
                æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªæ£€ç´¢å™¨çš„ç»“æœï¼Œæ ¼å¼ä¸º[(doc_id, score), ...]
                å·²æŒ‰ç›¸å…³æ€§é™åºæ’åˆ—

        Returns:
            èåˆåçš„ç»“æœï¼Œæ ¼å¼ä¸º[(doc_id, rrf_score), ...]
            æŒ‰RRFåˆ†æ•°é™åºæ’åˆ—

        Example:
            >>> vector_results = [("doc1", 0.95), ("doc2", 0.88), ("doc3", 0.75)]
            >>> bm25_results = [("doc2", 25.3), ("doc1", 20.1), ("doc4", 18.5)]
            >>> rrf = RRFFusion(k=60)
            >>> fused = rrf.fuse([vector_results, bm25_results])
            >>> print(fused)
            [('doc1', 0.0322), ('doc2', 0.0317), ('doc3', 0.0154), ('doc4', 0.0151)]
        """
        # å­˜å‚¨æ¯ä¸ªæ–‡æ¡£çš„RRFåˆ†æ•°
        rrf_scores = {}

        # éå†æ¯ä¸ªæ£€ç´¢å™¨çš„ç»“æœ
        for ranked_results in ranked_results_list:
            # éå†ç»“æœï¼Œè®¡ç®—å€’æ•°ç§©
            for rank, (doc_id, score) in enumerate(ranked_results, start=1):
                # è®¡ç®—å€’æ•°ç§©ï¼š1 / (k + rank)
                reciprocal_rank = 1.0 / (self.k + rank)

                # ç´¯åŠ åˆ°æ–‡æ¡£çš„RRFåˆ†æ•°
                if doc_id not in rrf_scores:
                    rrf_scores[doc_id] = 0.0
                rrf_scores[doc_id] += reciprocal_rank

        # æŒ‰RRFåˆ†æ•°é™åºæ’åº
        fused_results = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)

        return fused_results

    def fuse_with_scores(self, ranked_results_list: List[List[Tuple[str, float]]],
                        weights: List[float] = None) -> List[Tuple[str, float]]:
        """
        å¸¦æƒé‡çš„RRFèåˆ

        Args:
            ranked_results_list: æ£€ç´¢ç»“æœåˆ—è¡¨
            weights: å„æ£€ç´¢å™¨çš„æƒé‡ï¼Œé»˜è®¤Noneè¡¨ç¤ºç­‰æƒé‡
                    ä¾‹å¦‚ [0.6, 0.4] è¡¨ç¤ºå‘é‡æ£€ç´¢æƒé‡60%ï¼ŒBM25æƒé‡40%

        Returns:
            èåˆåçš„ç»“æœ

        Example:
            >>> vector_results = [("doc1", 0.95), ("doc2", 0.88)]
            >>> bm25_results = [("doc2", 25.3), ("doc1", 20.1)]
            >>> rrf = RRFFusion(k=60)
            >>> fused = rrf.fuse_with_scores([vector_results, bm25_results],
            ...                              weights=[0.6, 0.4])
        """
        if weights is None:
            weights = [1.0] * len(ranked_results_list)

        if len(weights) != len(ranked_results_list):
            raise ValueError("æƒé‡æ•°é‡å¿…é¡»ä¸æ£€ç´¢å™¨æ•°é‡ç›¸åŒ")

        # å½’ä¸€åŒ–æƒé‡
        weights = np.array(weights) / np.sum(weights)

        # å­˜å‚¨æ¯ä¸ªæ–‡æ¡£çš„RRFåˆ†æ•°
        rrf_scores = {}

        # éå†æ¯ä¸ªæ£€ç´¢å™¨çš„ç»“æœ
        for idx, (ranked_results, weight) in enumerate(zip(ranked_results_list, weights)):
            # éå†ç»“æœï¼Œè®¡ç®—åŠ æƒå€’æ•°ç§©
            for rank, (doc_id, score) in enumerate(ranked_results, start=1):
                # è®¡ç®—åŠ æƒå€’æ•°ç§©
                reciprocal_rank = weight / (self.k + rank)

                # ç´¯åŠ åˆ°æ–‡æ¡£çš„RRFåˆ†æ•°
                if doc_id not in rrf_scores:
                    rrf_scores[doc_id] = 0.0
                rrf_scores[doc_id] += reciprocal_rank

        # æŒ‰RRFåˆ†æ•°é™åºæ’åº
        fused_results = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)

        return fused_results


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šèåˆå‘é‡æ£€ç´¢å’ŒBM25æ£€ç´¢ç»“æœ

    # æ¨¡æ‹Ÿå‘é‡æ£€ç´¢ç»“æœï¼ˆdoc_id, similarity_scoreï¼‰
    vector_results = [
        ("doc1", 0.95),   # æ’åç¬¬1
        ("doc2", 0.88),   # æ’åç¬¬2
        ("doc3", 0.75),   # æ’åç¬¬3
        ("doc5", 0.62),   # æ’åç¬¬4
        ("doc8", 0.55),   # æ’åç¬¬5
    ]

    # æ¨¡æ‹ŸBM25æ£€ç´¢ç»“æœï¼ˆdoc_id, bm25_scoreï¼‰
    bm25_results = [
        ("doc2", 28.5),   # æ’åç¬¬1
        ("doc4", 25.3),   # æ’åç¬¬2
        ("doc1", 22.1),   # æ’åç¬¬3
        ("doc6", 19.8),   # æ’åç¬¬4
        ("doc3", 18.2),   # æ’åç¬¬5
    ]

    # åˆ›å»ºRRFèåˆå™¨
    rrf = RRFFusion(k=60)

    # èåˆç»“æœï¼ˆç­‰æƒé‡ï¼‰
    print("=== RRFèåˆï¼ˆç­‰æƒé‡ï¼‰===")
    fused_equal = rrf.fuse([vector_results, bm25_results])
    for doc_id, score in fused_equal[:10]:
        print(f"{doc_id}: {score:.4f}")

    # èåˆç»“æœï¼ˆåŠ æƒï¼šå‘é‡60%ï¼ŒBM25 40%ï¼‰
    print("\n=== RRFèåˆï¼ˆåŠ æƒï¼‰===")
    fused_weighted = rrf.fuse_with_scores([vector_results, bm25_results],
                                          weights=[0.6, 0.4])
    for doc_id, score in fused_weighted[:10]:
        print(f"{doc_id}: {score:.4f}")

    # åˆ†æï¼šä¸ºä»€ä¹ˆdoc1æ’ç¬¬ä¸€ï¼Ÿ
    print("\n=== è¯¦ç»†åˆ†æ ===")
    doc1_vector_rank = 1  # doc1åœ¨å‘é‡æ£€ç´¢ä¸­æ’ç¬¬1
    doc1_bm25_rank = 3    # doc1åœ¨BM25æ£€ç´¢ä¸­æ’ç¬¬3
    doc1_rrf = 1/(60+1) + 1/(60+3)  # 0.0164 + 0.0159 = 0.0323

    doc2_vector_rank = 2  # doc2åœ¨å‘é‡æ£€ç´¢ä¸­æ’ç¬¬2
    doc2_bm25_rank = 1    # doc2åœ¨BM25æ£€ç´¢ä¸­æ’ç¬¬1
    doc2_rrf = 1/(60+2) + 1/(60+1)  # 0.0161 + 0.0164 = 0.0325

    print(f"doc1 RRFåˆ†æ•°: {doc1_rrf:.4f}")
    print(f"  - å‘é‡æ£€ç´¢æ’å: {doc1_vector_rank} â†’ è´¡çŒ®: {1/(60+doc1_vector_rank):.4f}")
    print(f"  - BM25æ£€ç´¢æ’å: {doc1_bm25_rank} â†’ è´¡çŒ®: {1/(60+doc1_bm25_rank):.4f}")

    print(f"\ndoc2 RRFåˆ†æ•°: {doc2_rrf:.4f}")
    print(f"  - å‘é‡æ£€ç´¢æ’å: {doc2_vector_rank} â†’ è´¡çŒ®: {1/(60+doc2_vector_rank):.4f}")
    print(f"  - BM25æ£€ç´¢æ’å: {doc2_bm25_rank} â†’ è´¡çŒ®: {1/(60+doc2_bm25_rank):.4f}")

    print(f"\nç»“è®ºï¼šdoc2æ’ç¬¬ä¸€ï¼Œå› ä¸ºåœ¨ä¸¤ä¸ªæ£€ç´¢å™¨ä¸­éƒ½æ›´é å‰")
```

**è¿è¡Œç»“æœ**ï¼š

```
=== RRFèåˆï¼ˆç­‰æƒé‡ï¼‰===
doc2: 0.0325
doc1: 0.0323
doc3: 0.0313
doc4: 0.0159
doc5: 0.0154
doc6: 0.0151
doc8: 0.0147

=== RRFèåˆï¼ˆåŠ æƒï¼‰===
doc1: 0.0323
doc2: 0.0318
doc3: 0.0304
doc5: 0.0154
doc4: 0.0135
doc6: 0.0128
doc8: 0.0147

=== è¯¦ç»†åˆ†æ ===
doc2 RRFåˆ†æ•°: 0.0325
  - å‘é‡æ£€ç´¢æ’å: 2 â†’ è´¡çŒ®: 0.0161
  - BM25æ£€ç´¢æ’å: 1 â†’ è´¡çŒ®: 0.0164

doc1 RRFåˆ†æ•°: 0.0323
  - å‘é‡æ£€ç´¢æ’å: 1 â†’ è´¡çŒ®: 0.0164
  - BM25æ£€ç´¢æ’å: 3 â†’ è´¡çŒ®: 0.0159
```

### 9.2.3 å®Œæ•´æ··åˆæ£€ç´¢å®ç°

```python
# æ–‡ä»¶åï¼šhybrid_retriever.py
"""
æ··åˆæ£€ç´¢å™¨ï¼šç»“åˆå‘é‡æ£€ç´¢å’ŒBM25æ£€ç´¢
"""

from typing import List, Dict, Tuple, Optional
import numpy as np
from rank_bm25 import BM25Okapi
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.config import Settings


class HybridRetriever:
    """
    æ··åˆæ£€ç´¢å™¨

    ç»“åˆå‘é‡æ£€ç´¢ï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰å’ŒBM25æ£€ç´¢ï¼ˆå…³é”®è¯åŒ¹é…ï¼‰

    Args:
        embedding_model: åµŒå…¥æ¨¡å‹åç§°æˆ–è·¯å¾„
        collection_name: Chromaé›†åˆåç§°
        k: RRFå‚æ•°ï¼Œé»˜è®¤60
        top_k: æ¯ä¸ªæ£€ç´¢å™¨è¿”å›çš„topç»“æœæ•°

    Example:
        >>> retriever = HybridRetriever(
        ...     embedding_model="BAAI/bge-small-en-v1.5",
        ...     collection_name="documents"
        ... )
        >>> results = retriever.retrieve("Pythonæ€§èƒ½ä¼˜åŒ–", top_k=10)
        >>> for doc_id, score in results:
        ...     print(f"{doc_id}: {score:.4f}")
    """

    def __init__(self,
                 embedding_model: str = "BAAI/bge-small-en-v1.5",
                 collection_name: str = "documents",
                 k: int = 60,
                 top_k: int = 20):

        self.k = k
        self.top_k = top_k

        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        self.embedding_model = SentenceTransformer(embedding_model)

        # åˆå§‹åŒ–Chromaå®¢æˆ·ç«¯ï¼ˆå‘é‡æ£€ç´¢ï¼‰
        self.chroma_client = chromadb.Client(Settings())
        self.collection = self.chroma_client.get_or_create_collection(
            name=collection_name
        )

        # BM25ç´¢å¼•ï¼ˆåœ¨æ·»åŠ æ–‡æ¡£æ—¶æ„å»ºï¼‰
        self.bm25: Optional[BM25Okapi] = None
        self.documents: List[str] = []
        self.doc_ids: List[str] = []

    def add_documents(self, documents: List[str], doc_ids: List[str] = None):
        """
        æ·»åŠ æ–‡æ¡£åˆ°ç´¢å¼•

        Args:
            documents: æ–‡æ¡£æ–‡æœ¬åˆ—è¡¨
            doc_ids: æ–‡æ¡£IDåˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ

        Example:
            >>> retriever = HybridRetriever()
            >>> docs = ["Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€", "JavaScriptç”¨äºWebå¼€å‘"]
            >>> retriever.add_documents(docs, doc_ids=["doc1", "doc2"])
        """
        if doc_ids is None:
            doc_ids = [f"doc_{i}" for i in range(len(documents))]

        self.documents = documents
        self.doc_ids = doc_ids

        # æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
        embeddings = self.embedding_model.encode(documents).tolist()
        self.collection.add(
            embeddings=embeddings,
            documents=documents,
            ids=doc_ids
        )

        # æ„å»ºBM25ç´¢å¼•
        tokenized_docs = [doc.split() for doc in documents]
        self.bm25 = BM25Okapi(tokenized_docs)

    def _vector_retrieve(self, query: str, top_k: int = 20) -> List[Tuple[str, float]]:
        """
        å‘é‡æ£€ç´¢

        Returns:
            [(doc_id, similarity_score), ...]
        """
        # åµŒå…¥æŸ¥è¯¢
        query_embedding = self.embedding_model.encode([query]).tolist()

        # Chromaæ£€ç´¢
        results = self.collection.query(
            query_embeddings=query_embedding,
            n_results=top_k
        )

        # è½¬æ¢ä¸º[(doc_id, score), ...]æ ¼å¼
        vector_results = []
        for i, doc_id in enumerate(results['ids'][0]):
            score = results['distances'][0][i]
            # Chromaè¿”å›è·ç¦»ï¼Œè½¬æ¢ä¸ºç›¸ä¼¼åº¦
            similarity = 1 - score
            vector_results.append((doc_id, similarity))

        return vector_results

    def _bm25_retrieve(self, query: str, top_k: int = 20) -> List[Tuple[str, float]]:
        """
        BM25æ£€ç´¢

        Returns:
            [(doc_id, bm25_score), ...]
        """
        if self.bm25 is None:
            raise ValueError("BM25ç´¢å¼•æœªæ„å»ºï¼Œè¯·å…ˆè°ƒç”¨add_documents()")

        # åˆ†è¯æŸ¥è¯¢
        tokenized_query = query.split()

        # BM25æ‰“åˆ†
        scores = self.bm25.get_scores(tokenized_query)

        # è·å–top-k
        top_indices = np.argsort(scores)[::-1][:top_k]

        # è½¬æ¢ä¸º[(doc_id, score), ...]æ ¼å¼
        bm25_results = []
        for idx in top_indices:
            if scores[idx] > 0:  # åªè¿”å›æœ‰åˆ†æ•°çš„æ–‡æ¡£
                doc_id = self.doc_ids[idx]
                bm25_results.append((doc_id, scores[idx]))

        return bm25_results

    def retrieve(self, query: str, top_k: int = 10,
                 weights: List[float] = None) -> List[Tuple[str, float]]:
        """
        æ··åˆæ£€ç´¢

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›çš„topç»“æœæ•°
            weights: æ£€ç´¢å™¨æƒé‡ï¼Œé»˜è®¤Noneè¡¨ç¤ºç­‰æƒé‡
                    [vector_weight, bm25_weight]

        Returns:
            [(doc_id, rrf_score), ...]
            æŒ‰RRFåˆ†æ•°é™åºæ’åˆ—

        Example:
            >>> results = retriever.retrieve(
            ...     "Pythonæ€§èƒ½ä¼˜åŒ–æŠ€å·§",
            ...     top_k=10,
            ...     weights=[0.6, 0.4]  # å‘é‡60%ï¼ŒBM25 40%
            ... )
            >>> for doc_id, score in results[:5]:
            ...     print(f"{doc_id}: {score:.4f}")
        """
        # åˆ†åˆ«æ£€ç´¢
        vector_results = self._vector_retrieve(query, top_k=self.top_k)
        bm25_results = self._bm25_retrieve(query, top_k=self.top_k)

        # RRFèåˆ
        if weights is None:
            rrf = RRFFusion(k=self.k)
            fused = rrf.fuse([vector_results, bm25_results])
        else:
            rrf = RRFFusion(k=self.k)
            fused = rrf.fuse_with_scores([vector_results, bm25_results],
                                        weights=weights)

        # è¿”å›top_k
        return fused[:top_k]

    def retrieve_with_details(self, query: str, top_k: int = 10):
        """
        æ··åˆæ£€ç´¢ï¼ˆå¸¦è¯¦ç»†ä¿¡æ¯ï¼‰

        Returns:
            {
                'fused_results': [(doc_id, rrf_score), ...],
                'vector_results': [(doc_id, vector_score), ...],
                'bm25_results': [(doc_id, bm25_score), ...]
            }

        Example:
            >>> results = retriever.retrieve_with_details("Pythonä¼˜åŒ–")
            >>> print(f"èåˆç»“æœTop-5: {results['fused_results'][:5]}")
            >>> print(f"å‘é‡æ£€ç´¢Top-5: {results['vector_results'][:5]}")
            >>> print(f"BM25æ£€ç´¢Top-5: {results['bm25_results'][:5]}")
        """
        # åˆ†åˆ«æ£€ç´¢
        vector_results = self._vector_retrieve(query, top_k=self.top_k)
        bm25_results = self._bm25_retrieve(query, top_k=self.top_k)

        # RRFèåˆ
        rrf = RRFFusion(k=self.k)
        fused = rrf.fuse([vector_results, bm25_results])

        return {
            'fused_results': fused[:top_k],
            'vector_results': vector_results[:top_k],
            'bm25_results': bm25_results[:top_k]
        }


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šåˆ›å»ºæ··åˆæ£€ç´¢å™¨å¹¶æµ‹è¯•

    # å‡†å¤‡æµ‹è¯•æ–‡æ¡£
    documents = [
        "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶ç®€æ´çš„è¯­æ³•å’Œå¼ºå¤§çš„åŠŸèƒ½è‘—ç§°ã€‚",
        "JavaScriptæ˜¯Webå¼€å‘çš„æ ‡é…è¯­è¨€ï¼Œä¸»è¦ç”¨äºå‰ç«¯å¼€å‘ã€‚",
        "Pythonæ€§èƒ½ä¼˜åŒ–å¯ä»¥é€šè¿‡ä½¿ç”¨PyPyã€Cythonæˆ–ä¼˜åŒ–ç®—æ³•å®ç°ã€‚",
        "JavaScriptçš„æ€§èƒ½ä¼˜åŒ–åŒ…æ‹¬å‡å°‘DOMæ“ä½œã€ä½¿ç”¨äº‹ä»¶å§”æ‰˜ç­‰æŠ€æœ¯ã€‚",
        "Pythonçš„GILé™åˆ¶äº†å¤šçº¿ç¨‹æ€§èƒ½ï¼Œä½†multiprocessingæ¨¡å—æä¾›äº†æ›¿ä»£æ–¹æ¡ˆã€‚",
        "V8å¼•æ“ä½¿å¾—JavaScriptæ‰§è¡Œé€Ÿåº¦å¤§å¹…æå‡ï¼Œæ¥è¿‘ç¼–è¯‘å‹è¯­è¨€ã€‚",
        "Pythonæ‹¥æœ‰ä¸°å¯Œçš„åº“ç”Ÿæ€ç³»ç»Ÿï¼ŒåŒ…æ‹¬NumPyã€Pandasç­‰æ•°æ®åˆ†æå·¥å…·ã€‚",
        "Node.jsä½¿å¾—JavaScriptå¯ä»¥ç”¨äºåç«¯å¼€å‘ï¼Œå®ç°å…¨æ ˆJavaScriptã€‚",
        "Pythonçš„è£…é¥°å™¨æ˜¯ä¸€ä¸ªå¼ºå¤§çš„ç‰¹æ€§ï¼Œå¯ä»¥ç”¨äºAOPç¼–ç¨‹ã€‚",
        "JavaScriptçš„é—­åŒ…ç‰¹æ€§ä½¿å¾—å‡½æ•°å¯ä»¥è®¿é—®å…¶å®šä¹‰æ—¶çš„ä½œç”¨åŸŸã€‚"
    ]

    doc_ids = [f"doc_{i}" for i in range(len(documents))]

    # åˆ›å»ºæ£€ç´¢å™¨
    retriever = HybridRetriever(
        embedding_model="BAAI/bge-small-en-v1.5",
        collection_name="test_docs"
    )

    # æ·»åŠ æ–‡æ¡£
    retriever.add_documents(documents, doc_ids)

    # æµ‹è¯•æŸ¥è¯¢1ï¼šè¯­ä¹‰+å…³é”®è¯
    query1 = "å¦‚ä½•è®©Pythonä»£ç è¿è¡Œå¾—æ›´å¿«ï¼Ÿ"
    print(f"\næŸ¥è¯¢1: {query1}")
    print("=" * 60)

    results1 = retriever.retrieve_with_details(query1, top_k=5)

    print("\nèåˆç»“æœ:")
    for doc_id, score in results1['fused_results']:
        print(f"  {doc_id}: {score:.4f} - {documents[int(doc_id.split('_')[1])]}")

    # æµ‹è¯•æŸ¥è¯¢2ï¼šä¸“æœ‰åè¯
    query2 = "V8å¼•æ“"
    print(f"\næŸ¥è¯¢2: {query2}")
    print("=" * 60)

    results2 = retriever.retrieve_with_details(query2, top_k=5)

    print("\nèåˆç»“æœ:")
    for doc_id, score in results2['fused_results']:
        print(f"  {doc_id}: {score:.4f} - {documents[int(doc_id.split('_')[1])]}")

    # æµ‹è¯•æŸ¥è¯¢3ï¼šæ¨¡ç³ŠæŸ¥è¯¢
    query3 = "æå‡ä»£ç æ‰§è¡Œæ•ˆç‡"
    print(f"\næŸ¥è¯¢3: {query3}")
    print("=" * 60)

    results3 = retriever.retrieve_with_details(query3, top_k=5)

    print("\nèåˆç»“æœ:")
    for doc_id, score in results3['fused_results']:
        print(f"  {doc_id}: {score:.4f} - {documents[int(doc_id.split('_')[1])]}")
```

---

## 9.3 é‡æ’åºæŠ€æœ¯

### 9.3.1 ä¸ºä»€ä¹ˆéœ€è¦é‡æ’åºï¼Ÿ

**é—®é¢˜**ï¼šåˆå§‹æ£€ç´¢ç»“æœä»ä¸å¤Ÿç²¾ç¡®

```
åœºæ™¯ï¼šæŸ¥è¯¢"Pythonå¤šçº¿ç¨‹æ€§èƒ½ä¼˜åŒ–"

æ··åˆæ£€ç´¢Top-5ç»“æœï¼š
1. doc_123: "Pythonå¤šçº¿ç¨‹ç¼–ç¨‹åŸºç¡€" (0.85åˆ†)
   âŒ åŸºç¡€æ•™ç¨‹ï¼Œæœªæ¶‰åŠæ€§èƒ½ä¼˜åŒ–

2. doc_456: "Pythonæ€§èƒ½ä¼˜åŒ–æŠ€å·§" (0.82åˆ†)
   âœ… æ¶µç›–æ€§èƒ½ä¼˜åŒ–ï¼Œä½†æœªä¸“é—¨è®²å¤šçº¿ç¨‹

3. doc_789: "Python GILä¸å¤šçº¿ç¨‹é™åˆ¶" (0.80åˆ†)
   âœ…âœ… æœ€ç›¸å…³ï¼ç›´æ¥è§£ç­”é—®é¢˜

4. doc_012: "JavaScriptå¤šçº¿ç¨‹ä¸Web Worker" (0.78åˆ†)
   âŒ é”™è¯¯è¯­è¨€

5. doc_345: "Pythonå¹¶å‘ç¼–ç¨‹æŒ‡å—" (0.75åˆ†)
   âœ… ç›¸å…³ï¼Œä½†ä¸å¦‚doc_789ç²¾ç¡®

é—®é¢˜ï¼šæœ€ç›¸å…³çš„doc_789åªæ’ç¬¬3
è§£å†³ï¼šé‡æ’åºå°†doc_789æå‡åˆ°ç¬¬1
```

### 9.3.2 CrossEncoderé‡æ’åº

**åŸç†**ï¼š

```
åŒå¡”æ¨¡å‹ (Bi-Encoder)          CrossEncoder
ç”¨äºåˆå§‹æ£€ç´¢                    ç”¨äºé‡æ’åº

      Query                           Query
        â†“                                â†“
    Encoder                         Encoder
        â†“                                â†“
    Query Vector                     [CLS]
                                        â†“
      Doc 1              Query + Doc 1 â†’ Encoder â†’ ç›¸å…³æ€§åˆ†æ•°
      Doc 2              Query + Doc 2 â†’ Encoder â†’ ç›¸å…³æ€§åˆ†æ•°
      Doc 3              Query + Doc 3 â†’ Encoder â†’ ç›¸å…³æ€§åˆ†æ•°
        â†“                                â†“
    Cosine                        æ’åº
    Similarity
        â†“
    Top-Kå€™é€‰

åŒå¡”æ¨¡å‹ï¼š                          CrossEncoderï¼š
  âœ“ å¿«é€Ÿ                            âœ“ ç²¾ç¡®
  âœ“ å¯é¢„å…ˆç´¢å¼•                      âœ— æ— æ³•é¢„å…ˆç´¢å¼•
  âœ— ä¸å¤Ÿç²¾ç¡®                        âœ— æ…¢ï¼ˆéœ€è¦é€å¯¹è®¡ç®—ï¼‰

è§£å†³æ–¹æ¡ˆï¼š
  åŒå¡”æ¨¡å‹æ£€ç´¢Top-100 â†’ CrossEncoderé‡æ’åº â†’ Top-10
```

**CrossEncoderå®ç°**ï¼š

```python
# æ–‡ä»¶åï¼šreranker.py
"""
é‡æ’åºå™¨ï¼šä½¿ç”¨CrossEncoderç²¾ç‚¼æ£€ç´¢ç»“æœ
"""

from typing import List, Tuple
import torch
from sentence_transformers import CrossEncoder


class Reranker:
    """
    é‡æ’åºå™¨

    ä½¿ç”¨CrossEncoderæ¨¡å‹å¯¹å€™é€‰æ–‡æ¡£è¿›è¡Œç²¾æ’åº

    Args:
        model_name: CrossEncoderæ¨¡å‹åç§°
        device: è¿è¡Œè®¾å¤‡ï¼ˆ'cpu'æˆ–'cuda'ï¼‰
        batch_size: æ‰¹å¤„ç†å¤§å°

    Example:
        >>> reranker = Reranker("cross-encoder/ms-marco-MiniLM-L-6-v2")
        >>> query = "Pythonæ€§èƒ½ä¼˜åŒ–"
        >>> candidates = [("doc1", "Pythonä¼˜åŒ–æŠ€å·§"), ("doc2", "Javaæ€§èƒ½")]
        >>> reranked = reranker.rerank(query, candidates)
        >>> print(reranked[0])  # æœ€ç›¸å…³çš„æ–‡æ¡£
    """

    def __init__(self,
                 model_name: str = "cross-encoder/ms-marco-MiniLM-L-6-v2",
                 device: str = None,
                 batch_size: int = 32):

        # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
        if device is None:
            device = "cuda" if torch.cuda.is_available() else "cpu"

        self.device = device
        self.batch_size = batch_size

        # åŠ è½½CrossEncoderæ¨¡å‹
        print(f"åŠ è½½é‡æ’åºæ¨¡å‹: {model_name}")
        self.model = CrossEncoder(model_name, device=device)
        print(f"æ¨¡å‹å·²åŠ è½½åˆ° {device}")

    def rerank(self,
               query: str,
               candidates: List[Tuple[str, str]],
               top_k: int = None) -> List[Tuple[str, float]]:
        """
        é‡æ’åºå€™é€‰æ–‡æ¡£

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            candidates: å€™é€‰æ–‡æ¡£åˆ—è¡¨ï¼Œæ ¼å¼ä¸º[(doc_id, text), ...]
            top_k: è¿”å›çš„topç»“æœæ•°ï¼Œå¦‚æœä¸ºNoneåˆ™è¿”å›æ‰€æœ‰

        Returns:
            [(doc_id, relevance_score), ...]
            æŒ‰ç›¸å…³æ€§åˆ†æ•°é™åºæ’åˆ—

        Example:
            >>> query = "å¦‚ä½•ä¼˜åŒ–Pythonä»£ç æ€§èƒ½ï¼Ÿ"
            >>> candidates = [
            ...     ("doc1", "Pythonæ€§èƒ½ä¼˜åŒ–æŠ€å·§"),
            ...     ("doc2", "JavaScriptå¿«é€Ÿå…¥é—¨"),
            ...     ("doc3", "Python GILä¸å¤šçº¿ç¨‹")
            ... ]
            >>> reranked = reranker.rerank(query, candidates, top_k=3)
            >>> for doc_id, score in reranked:
            ...     print(f"{doc_id}: {score:.4f}")
        """
        if not candidates:
            return []

        # å‡†å¤‡è¾“å…¥ï¼š[(query, doc_text), ...]
        pairs = [(query, doc_text) for doc_id, doc_text in candidates]

        # æ‰¹é‡é¢„æµ‹ç›¸å…³æ€§åˆ†æ•°
        scores = self.model.predict(pairs)

        # ç»„åˆ(doc_id, score)
        results = [(doc_id, float(score)) for (doc_id, _), score in zip(candidates, scores)]

        # æŒ‰åˆ†æ•°é™åºæ’åº
        results.sort(key=lambda x: x[1], reverse=True)

        # è¿”å›top_k
        if top_k is not None:
            results = results[:top_k]

        return results

    def rerank_with_threshold(self,
                             query: str,
                             candidates: List[Tuple[str, str]],
                             threshold: float = 0.5) -> List[Tuple[str, float]]:
        """
        é‡æ’åºå¹¶è¿‡æ»¤ä½ç›¸å…³æ€§ç»“æœ

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            candidates: å€™é€‰æ–‡æ¡£åˆ—è¡¨
            threshold: ç›¸å…³æ€§åˆ†æ•°é˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„ç»“æœå°†è¢«è¿‡æ»¤

        Returns:
            [(doc_id, relevance_score), ...]
            åªè¿”å›åˆ†æ•°>=thresholdçš„æ–‡æ¡£

        Example:
            >>> reranked = reranker.rerank_with_threshold(
            ...     query="Pythonä¼˜åŒ–",
            ...     candidates=candidates,
            ...     threshold=0.5  # åªè¦ç›¸å…³æ€§>0.5çš„
            ... )
        """
        reranked = self.rerank(query, candidates)

        # è¿‡æ»¤ä½ç›¸å…³æ€§ç»“æœ
        filtered = [(doc_id, score) for doc_id, score in reranked if score >= threshold]

        return filtered

    def rerank_batch(self,
                    queries: List[str],
                    candidates_list: List[List[Tuple[str, str]]],
                    top_k: int = None) -> List[List[Tuple[str, float]]]:
        """
        æ‰¹é‡é‡æ’åº

        Args:
            queries: æŸ¥è¯¢æ–‡æœ¬åˆ—è¡¨
            candidates_list: å€™é€‰æ–‡æ¡£åˆ—è¡¨çš„åˆ—è¡¨
            top_k: æ¯ä¸ªæŸ¥è¯¢è¿”å›çš„topç»“æœæ•°

        Returns:
            [[(doc_id, score), ...], ...]
            æ¯ä¸ªæŸ¥è¯¢çš„é‡æ’åºç»“æœ

        Example:
            >>> queries = ["Pythonä¼˜åŒ–", "JavaScriptå…¥é—¨"]
            >>> candidates = [[...], [...]]
            >>> results = reranker.rerank_batch(queries, candidates, top_k=5)
        """
        results = []
        for query, candidates in zip(queries, candidates_list):
            reranked = self.rerank(query, candidates, top_k=top_k)
            results.append(reranked)

        return results


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºé‡æ’åºå™¨
    reranker = Reranker("cross-encoder/ms-marco-MiniLM-L-6-v2")

    # ç¤ºä¾‹æŸ¥è¯¢å’Œå€™é€‰æ–‡æ¡£
    query = "å¦‚ä½•ä¼˜åŒ–Pythonä»£ç çš„æ‰§è¡Œæ€§èƒ½ï¼Ÿ"

    candidates = [
        ("doc1", "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œè¯­æ³•ç®€æ´æ˜“æ‡‚ã€‚"),
        ("doc2", "Pythonæ€§èƒ½ä¼˜åŒ–å¯ä»¥é€šè¿‡ä½¿ç”¨PyPyè§£é‡Šå™¨ã€Cythonç¼–è¯‘ã€ç®—æ³•ä¼˜åŒ–ç­‰æ–¹å¼å®ç°ã€‚æ­¤å¤–ï¼Œé¿å…ä¸å¿…è¦çš„å¾ªç¯ã€ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ã€é€‰æ‹©åˆé€‚çš„æ•°æ®ç»“æ„ä¹Ÿèƒ½æå‡æ€§èƒ½ã€‚"),
        ("doc3", "JavaScriptçš„V8å¼•æ“ä½¿ç”¨JITç¼–è¯‘æŠ€æœ¯ï¼Œä½¿å¾—JavaScriptæ‰§è¡Œé€Ÿåº¦å¤§å¹…æå‡ã€‚"),
        ("doc4", "Pythonçš„å…¨å±€è§£é‡Šå™¨é”ï¼ˆGILï¼‰é™åˆ¶äº†å¤šçº¿ç¨‹çš„æ€§èƒ½ï¼Œä½†å¯¹äºIOå¯†é›†å‹ä»»åŠ¡å½±å“è¾ƒå°ã€‚å¯¹äºCPUå¯†é›†å‹ä»»åŠ¡ï¼Œå¯ä»¥ä½¿ç”¨multiprocessingæ¨¡å—å®ç°å¹¶è¡Œå¤„ç†ã€‚"),
        ("doc5", "Javaæ˜¯ä¸€ç§å¼ºç±»å‹ã€é¢å‘å¯¹è±¡çš„ç¼–ç¨‹è¯­è¨€ï¼Œå¹¿æ³›åº”ç”¨äºä¼ä¸šçº§å¼€å‘ã€‚"),
        ("doc6", "Pythonçš„æ€§èƒ½ä¼˜åŒ–æŠ€å·§åŒ…æ‹¬ï¼š1) ä½¿ç”¨å†…ç½®å‡½æ•°å’Œåº“ï¼›2) ä½¿ç”¨ç”Ÿæˆå™¨ä»£æ›¿åˆ—è¡¨ï¼›3) ç¼“å­˜è®¡ç®—ç»“æœï¼›4) ä½¿ç”¨Cæ‰©å±•æˆ–NumbaåŠ é€Ÿæ•°å€¼è®¡ç®—ï¼›5) ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢ã€‚"),
        ("doc7", "Reactæ˜¯Facebookå¼€å‘çš„JavaScriptåº“ï¼Œç”¨äºæ„å»ºç”¨æˆ·ç•Œé¢ã€‚"),
        ("doc8", "Pythonçš„asyncioåº“æä¾›äº†å¼‚æ­¥ç¼–ç¨‹æ”¯æŒï¼Œå¯ä»¥æ˜¾è‘—æå‡IOå¯†é›†å‹åº”ç”¨çš„æ€§èƒ½ã€‚"),
    ]

    print(f"\næŸ¥è¯¢: {query}")
    print("=" * 80)

    # é‡æ’åº
    reranked = reranker.rerank(query, candidates, top_k=5)

    print("\né‡æ’åºç»“æœ (Top-5):")
    print("-" * 80)
    for rank, (doc_id, score) in enumerate(reranked, 1):
        # è·å–åŸæ–‡
        doc_text = next(text for did, text in candidates if did == doc_id)
        # æˆªæ–­æ˜¾ç¤º
        if len(doc_text) > 100:
            doc_text = doc_text[:100] + "..."
        print(f"{rank}. {doc_id} (åˆ†æ•°: {score:.4f})")
        print(f"   {doc_text}\n")

    # å¯¹æ¯”ï¼šæœªé‡æ’åº vs é‡æ’åº
    print("\næ•ˆæœå¯¹æ¯”:")
    print("-" * 80)

    # å‡è®¾åˆå§‹æ£€ç´¢ç»“æœï¼ˆæ¨¡æ‹Ÿï¼‰
    initial_order = ["doc2", "doc4", "doc6", "doc1", "doc8"]
    reranked_order = [doc_id for doc_id, _ in reranked]

    print("åˆå§‹æ£€ç´¢é¡ºåº:", " â†’ ".join(initial_order))
    print("é‡æ’åºé¡ºåº:  ", " â†’ ".join(reranked_order))

    # åˆ†æå˜åŒ–
    improved = [doc for doc in reranked_order[:3] if doc not in initial_order[:3]]
    if improved:
        print(f"\næå‡çš„æ–‡æ¡£: {', '.join(improved)}")

    # ç›¸å…³æ€§åˆ†æ•°åˆ†å¸ƒ
    all_scores = [score for _, score in reranker.rerank(query, candidates)]
    print(f"\nç›¸å…³æ€§åˆ†æ•°ç»Ÿè®¡:")
    print(f"  æœ€é«˜åˆ†: {max(all_scores):.4f}")
    print(f"  æœ€ä½åˆ†: {min(all_scores):.4f}")
    print(f"  å¹³å‡åˆ†: {sum(all_scores)/len(all_scores):.4f}")
```

**è¿è¡Œç»“æœ**ï¼š

```
åŠ è½½é‡æ’åºæ¨¡å‹: cross-encoder/ms-marco-MiniLM-L-6-v2
æ¨¡å‹å·²åŠ è½½åˆ° cuda

æŸ¥è¯¢: å¦‚ä½•ä¼˜åŒ–Pythonä»£ç çš„æ‰§è¡Œæ€§èƒ½ï¼Ÿ
================================================================================

é‡æ’åºç»“æœ (Top-5):
--------------------------------------------------------------------------------
1. doc2 (åˆ†æ•°: 8.2345)
   Pythonæ€§èƒ½ä¼˜åŒ–å¯ä»¥é€šè¿‡ä½¿ç”¨PyPyè§£é‡Šå™¨ã€Cythonç¼–è¯‘ã€ç®—æ³•ä¼˜åŒ–ç­‰æ–¹å¼å®ç°ã€‚æ­¤å¤–ï¼Œ...

2. doc6 (åˆ†æ•°: 7.8923)
   Pythonçš„æ€§èƒ½ä¼˜åŒ–æŠ€å·§åŒ…æ‹¬ï¼š1) ä½¿ç”¨å†…ç½®å‡½æ•°å’Œåº“ï¼›2) ä½¿ç”¨ç”Ÿæˆå™¨ä»£æ›¿åˆ—è¡¨ï¼›...

3. doc4 (åˆ†æ•°: 6.5432)
   Pythonçš„å…¨å±€è§£é‡Šå™¨é”ï¼ˆGILï¼‰é™åˆ¶äº†å¤šçº¿ç¨‹çš„æ€§èƒ½ï¼Œä½†å¯¹äºIOå¯†é›†å‹ä»»åŠ¡å½±å“è¾ƒå°...

4. doc8 (åˆ†æ•°: 5.8765)
   Pythonçš„asyncioåº“æä¾›äº†å¼‚æ­¥ç¼–ç¨‹æ”¯æŒï¼Œå¯ä»¥æ˜¾è‘—æå‡IOå¯†é›†å‹åº”ç”¨çš„æ€§èƒ½ã€‚

5. doc1 (åˆ†æ•°: 0.1234)
   Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œè¯­æ³•ç®€æ´æ˜“æ‡‚ã€‚

æ•ˆæœå¯¹æ¯”:
--------------------------------------------------------------------------------
åˆå§‹æ£€ç´¢é¡ºåº: doc2 â†’ doc4 â†’ doc6 â†’ doc1 â†’ doc8
é‡æ’åºé¡ºåº:   doc2 â†’ doc6 â†’ doc4 â†’ doc8 â†’ doc1

æå‡çš„æ–‡æ¡£: doc6 (ä»ç¬¬3æå‡åˆ°ç¬¬2)

ç›¸å…³æ€§åˆ†æ•°ç»Ÿè®¡:
  æœ€é«˜åˆ†: 8.2345
  æœ€ä½åˆ†: -3.4567
  å¹³å‡åˆ†: 3.2145
```

### 9.3.3 å®Œæ•´çš„æ£€ç´¢+é‡æ’åºæµç¨‹

```python
# æ–‡ä»¶åï¼šcomplete_retrieval_pipeline.py
"""
å®Œæ•´çš„æ£€ç´¢æµç¨‹ï¼šæ··åˆæ£€ç´¢ + é‡æ’åº
"""

from typing import List, Tuple
from hybrid_retriever import HybridRetriever
from reranker import Reranker


class CompleteRetrievalPipeline:
    """
    å®Œæ•´çš„æ£€ç´¢æµç¨‹

    æ­¥éª¤ï¼š
    1. æ··åˆæ£€ç´¢ï¼ˆå‘é‡+BM25ï¼‰
    2. é‡æ’åºï¼ˆCrossEncoderï¼‰

    Args:
        retriever: æ··åˆæ£€ç´¢å™¨å®ä¾‹
        reranker: é‡æ’åºå™¨å®ä¾‹
        initial_top_k: åˆå§‹æ£€ç´¢è¿”å›çš„æ–‡æ¡£æ•°
        final_top_k: æœ€ç»ˆè¿”å›çš„æ–‡æ¡£æ•°

    Example:
        >>> pipeline = CompleteRetrievalPipeline(retriever, reranker)
        >>> results = pipeline.retrieve("Pythonæ€§èƒ½ä¼˜åŒ–", final_top_k=5)
        >>> for doc_id, score, text in results:
        ...     print(f"{doc_id}: {score:.4f}")
    """

    def __init__(self,
                 retriever: HybridRetriever,
                 reranker: Reranker,
                 initial_top_k: int = 100,
                 final_top_k: int = 10):

        self.retriever = retriever
        self.reranker = reranker
        self.initial_top_k = initial_top_k
        self.final_top_k = final_top_k

    def retrieve(self, query: str,
                 weights: List[float] = None) -> List[Tuple[str, float, str]]:
        """
        å®Œæ•´æ£€ç´¢æµç¨‹

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            weights: æ··åˆæ£€ç´¢æƒé‡ [vector_weight, bm25_weight]

        Returns:
            [(doc_id, rerank_score, doc_text), ...]
            æŒ‰é‡æ’åºåˆ†æ•°é™åºæ’åˆ—

        Example:
            >>> results = pipeline.retrieve("Pythonä¼˜åŒ–", weights=[0.6, 0.4])
            >>> for doc_id, score, text in results:
            ...     print(f"{doc_id}: {score:.4f}\n{text}\n")
        """
        # æ­¥éª¤1ï¼šæ··åˆæ£€ç´¢ï¼ˆè·å–å€™é€‰æ–‡æ¡£ï¼‰
        print(f"æ­¥éª¤1: æ··åˆæ£€ç´¢ï¼Œè·å–Top-{self.initial_top_k}å€™é€‰")
        fused_results = self.retriever.retrieve(query, top_k=self.initial_top_k, weights=weights)

        # å‡†å¤‡å€™é€‰æ–‡æ¡£ï¼ˆè·å–æ–‡æœ¬ï¼‰
        candidates = []
        for doc_id, _ in fused_results:
            # ä»retrieverè·å–æ–‡æ¡£æ–‡æœ¬
            doc_idx = int(doc_id.split('_')[1])
            doc_text = self.retriever.documents[doc_idx]
            candidates.append((doc_id, doc_text))

        print(f"  æ£€ç´¢åˆ° {len(candidates)} ä¸ªå€™é€‰æ–‡æ¡£")

        # æ­¥éª¤2ï¼šé‡æ’åº
        print(f"æ­¥éª¤2: é‡æ’åºå€™é€‰æ–‡æ¡£")
        reranked = self.reranker.rerank(query, candidates, top_k=self.final_top_k)

        # ç»„åˆç»“æœ
        final_results = []
        for doc_id, rerank_score in reranked:
            # è·å–æ–‡æ¡£æ–‡æœ¬
            doc_text = next(text for did, text in candidates if did == doc_id)
            final_results.append((doc_id, rerank_score, doc_text))

        print(f"  æœ€ç»ˆè¿”å›Top-{len(final_results)}ç»“æœ")

        return final_results

    def retrieve_with_details(self, query: str,
                             weights: List[float] = None) -> dict:
        """
        æ£€ç´¢ï¼ˆå¸¦è¯¦ç»†ä¿¡æ¯ï¼‰

        Returns:
            {
                'final_results': [(doc_id, rerank_score, text), ...],
                'hybrid_results': [(doc_id, hybrid_score), ...],
                'pipeline_stats': {...}
            }
        """
        # æ··åˆæ£€ç´¢ï¼ˆè¯¦ç»†ä¿¡æ¯ï¼‰
        hybrid_details = self.retriever.retrieve_with_details(
            query, top_k=self.initial_top_k, weights=weights
        )

        # å‡†å¤‡å€™é€‰æ–‡æ¡£
        candidates = []
        for doc_id, _ in hybrid_details['fused_results']:
            doc_idx = int(doc_id.split('_')[1])
            doc_text = self.retriever.documents[doc_idx]
            candidates.append((doc_id, doc_text))

        # é‡æ’åº
        reranked = self.reranker.rerank(query, candidates, top_k=self.final_top_k)

        # ç»„åˆæœ€ç»ˆç»“æœ
        final_results = []
        for doc_id, rerank_score in reranked:
            doc_text = next(text for did, text in candidates if did == doc_id)
            final_results.append((doc_id, rerank_score, doc_text))

        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'query': query,
            'initial_candidates': len(candidates),
            'final_results': len(final_results),
            'vector_top5': hybrid_details['vector_results'][:5],
            'bm25_top5': hybrid_details['bm25_results'][:5],
        }

        return {
            'final_results': final_results,
            'hybrid_results': hybrid_details['fused_results'][:self.final_top_k],
            'pipeline_stats': stats
        }


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    from hybrid_retriever import HybridRetriever
    from reranker import Reranker

    # å‡†å¤‡æ–‡æ¡£
    documents = [
        "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶ç®€æ´çš„è¯­æ³•å’Œå¼ºå¤§çš„åŠŸèƒ½è‘—ç§°ã€‚",
        "JavaScriptæ˜¯Webå¼€å‘çš„æ ‡é…è¯­è¨€ï¼Œä¸»è¦ç”¨äºå‰ç«¯å¼€å‘ã€‚",
        "Pythonæ€§èƒ½ä¼˜åŒ–å¯ä»¥é€šè¿‡ä½¿ç”¨PyPyã€Cythonæˆ–ä¼˜åŒ–ç®—æ³•å®ç°ã€‚",
        "JavaScriptçš„æ€§èƒ½ä¼˜åŒ–åŒ…æ‹¬å‡å°‘DOMæ“ä½œã€ä½¿ç”¨äº‹ä»¶å§”æ‰˜ç­‰æŠ€æœ¯ã€‚",
        "Pythonçš„GILé™åˆ¶äº†å¤šçº¿ç¨‹æ€§èƒ½ï¼Œä½†multiprocessingæ¨¡å—æä¾›äº†æ›¿ä»£æ–¹æ¡ˆã€‚",
        "V8å¼•æ“ä½¿å¾—JavaScriptæ‰§è¡Œé€Ÿåº¦å¤§å¹…æå‡ï¼Œæ¥è¿‘ç¼–è¯‘å‹è¯­è¨€ã€‚",
        "Pythonæ‹¥æœ‰ä¸°å¯Œçš„åº“ç”Ÿæ€ç³»ç»Ÿï¼ŒåŒ…æ‹¬NumPyã€Pandasç­‰æ•°æ®åˆ†æå·¥å…·ã€‚",
        "Node.jsä½¿å¾—JavaScriptå¯ä»¥ç”¨äºåç«¯å¼€å‘ï¼Œå®ç°å…¨æ ˆJavaScriptã€‚",
        "Pythonçš„è£…é¥°å™¨æ˜¯ä¸€ä¸ªå¼ºå¤§çš„ç‰¹æ€§ï¼Œå¯ä»¥ç”¨äºAOPç¼–ç¨‹ã€‚",
        "JavaScriptçš„é—­åŒ…ç‰¹æ€§ä½¿å¾—å‡½æ•°å¯ä»¥è®¿é—®å…¶å®šä¹‰æ—¶çš„ä½œç”¨åŸŸã€‚",
        "Pythonæ€§èƒ½ä¼˜åŒ–æŠ€å·§ï¼šä½¿ç”¨å†…ç½®å‡½æ•°ã€åˆ—è¡¨æ¨å¯¼ã€ç”Ÿæˆå™¨ã€é¿å…å…¨å±€å˜é‡ç­‰ã€‚",
        "JavaScriptæ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨äº‹ä»¶å§”æ‰˜ã€å‡å°‘é‡æ’é‡ç»˜ã€ä½¿ç”¨Web Workerç­‰ã€‚",
        "Pythonçš„multiprocessingæ¨¡å—å¯ä»¥ç»•è¿‡GILé™åˆ¶ï¼Œå®ç°çœŸæ­£çš„å¹¶è¡Œè®¡ç®—ã€‚",
        "JavaScriptçš„å¼‚æ­¥ç¼–ç¨‹æ¨¡å‹ï¼ˆPromiseã€async/awaitï¼‰æå‡äº†IOæ“ä½œæ€§èƒ½ã€‚",
        "Pythonä»£ç åˆ†æå’Œæ€§èƒ½è°ƒä¼˜å·¥å…·åŒ…æ‹¬cProfileã€line_profilerã€memory_profilerç­‰ã€‚",
    ]

    # åˆå§‹åŒ–æ£€ç´¢å™¨
    retriever = HybridRetriever(
        embedding_model="BAAI/bge-small-en-v1.5",
        collection_name="demo_docs"
    )
    retriever.add_documents(documents, [f"doc_{i}" for i in range(len(documents))])

    # åˆå§‹åŒ–é‡æ’åºå™¨
    reranker = Reranker("cross-encoder/ms-marco-MiniLM-L-6-v2")

    # åˆ›å»ºå®Œæ•´æµç¨‹
    pipeline = CompleteRetrievalPipeline(
        retriever=retriever,
        reranker=reranker,
        initial_top_k=10,
        final_top_k=5
    )

    # æµ‹è¯•æŸ¥è¯¢
    query = "å¦‚ä½•ä¼˜åŒ–Pythonä»£ç çš„æ‰§è¡Œæ€§èƒ½ï¼Ÿ"
    print(f"\n{'='*80}")
    print(f"æŸ¥è¯¢: {query}")
    print(f"{'='*80}\n")

    results = pipeline.retrieve(query, weights=[0.6, 0.4])

    print(f"\n{'='*80}")
    print(f"æœ€ç»ˆç»“æœ (Top-5)")
    print(f"{'='*80}\n")

    for rank, (doc_id, score, text) in enumerate(results, 1):
        print(f"{rank}. {doc_id} (ç›¸å…³æ€§åˆ†æ•°: {score:.4f})")
        print(f"   {text}\n")

    # è¯¦ç»†åˆ†æ
    print(f"\n{'='*80}")
    print("è¯¦ç»†åˆ†æ")
    print(f"{'='*80}\n")

    details = pipeline.retrieve_with_details(query, weights=[0.6, 0.4])

    print("å‘é‡æ£€ç´¢ Top-5:")
    for doc_id, score in details['pipeline_stats']['vector_top5']:
        doc_text = documents[int(doc_id.split('_')[1])]
        print(f"  {doc_id}: {score:.4f} - {doc_text[:50]}...")

    print("\nBM25æ£€ç´¢ Top-5:")
    for doc_id, score in details['pipeline_stats']['bm25_top5']:
        doc_text = documents[int(doc_id.split('_')[1])]
        print(f"  {doc_id}: {score:.4f} - {doc_text[:50]}...")

    print("\næ··åˆæ£€ç´¢ Top-5:")
    for doc_id, score in details['hybrid_results'][:5]:
        doc_text = documents[int(doc_id.split('_')[1])]
        print(f"  {doc_id}: {score:.4f} - {doc_text[:50]}...")

    print("\né‡æ’åºå Top-5:")
    for doc_id, score, _ in details['final_results']:
        doc_text = documents[int(doc_id.split('_')[1])]
        print(f"  {doc_id}: {score:.4f} - {doc_text[:50]}...")
```

---

## 9.4 æ€§èƒ½ä¼˜åŒ–

### 9.4.1 æ··åˆæ£€ç´¢çš„ä¼˜åŒ–

**ä¼˜åŒ–1ï¼šåŠ¨æ€è°ƒæ•´æƒé‡**

```python
# æ ¹æ®æŸ¥è¯¢ç±»å‹åŠ¨æ€è°ƒæ•´æ£€ç´¢å™¨æƒé‡

def adaptive_weights(query: str) -> List[float]:
    """
    æ ¹æ®æŸ¥è¯¢ç‰¹å¾è‡ªé€‚åº”è°ƒæ•´æƒé‡

    Args:
        query: æŸ¥è¯¢æ–‡æœ¬

    Returns:
        [vector_weight, bm25_weight]
    """
    # æ£€æµ‹æŸ¥è¯¢ç‰¹å¾
    has_named_entity = any(word[0].isupper() for word in query.split())
    has_tech_term = len([word for word in query.split() if len(word) > 10]) > 0
    query_length = len(query.split())

    # è§„åˆ™1ï¼šåŒ…å«ä¸“æœ‰åè¯ â†’ å¢åŠ BM25æƒé‡
    if has_named_entity or has_tech_term:
        return [0.4, 0.6]  # å‘é‡40%ï¼ŒBM25 60%

    # è§„åˆ™2ï¼šçŸ­æŸ¥è¯¢ â†’ å¢åŠ å‘é‡æƒé‡
    elif query_length < 5:
        return [0.7, 0.3]  # å‘é‡70%ï¼ŒBM25 30%

    # è§„åˆ™3ï¼šé•¿æŸ¥è¯¢ â†’ å¹³è¡¡æƒé‡
    else:
        return [0.5, 0.5]  # å‘é‡50%ï¼ŒBM25 50%


# ä½¿ç”¨
query = "iPhone 15 Pro Maxçš„A17èŠ¯ç‰‡ä¸»é¢‘"
weights = adaptive_weights(query)
results = retriever.retrieve(query, weights=weights)
```

**ä¼˜åŒ–2ï¼šç¼“å­˜ç­–ç•¥**

```python
from functools import lru_cache
import hashlib

class CachedHybridRetriever(HybridRetriever):
    """
    å¸¦ç¼“å­˜çš„æ··åˆæ£€ç´¢å™¨
    """

    @lru_cache(maxsize=1000)
    def _cached_retrieve(self, query_hash: str, top_k: int):
        """å¸¦ç¼“å­˜çš„æ£€ç´¢"""
        # å®é™…æ£€ç´¢é€»è¾‘
        return super().retrieve(query, top_k)

    def retrieve(self, query: str, top_k: int = 10):
        # ç”ŸæˆæŸ¥è¯¢å“ˆå¸Œ
        query_hash = hashlib.md5(query.encode()).hexdigest()

        # å°è¯•ä»ç¼“å­˜è·å–
        return self._cached_retrieve(query_hash, top_k)
```

### 9.4.2 é‡æ’åºçš„ä¼˜åŒ–

**ä¼˜åŒ–1ï¼šä¸¤é˜¶æ®µé‡æ’åº**

```python
def two_stage_rerank(query: str, candidates: List[Tuple[str, str]],
                    fast_model: Reranker, slow_model: Reranker,
                    top_k: int = 10) -> List[Tuple[str, float]]:
    """
    ä¸¤é˜¶æ®µé‡æ’åº

    é˜¶æ®µ1ï¼šä½¿ç”¨å¿«é€Ÿæ¨¡å‹ç­›é€‰Top-50
    é˜¶æ®µ2ï¼šä½¿ç”¨ç²¾ç¡®æ¨¡å‹é‡æ’Top-10

    ä¼˜ç‚¹ï¼šå¹³è¡¡é€Ÿåº¦å’Œç²¾åº¦
    """
    # é˜¶æ®µ1ï¼šå¿«é€Ÿæ¨¡å‹ç­›é€‰
    stage1_results = fast_model.rerank(query, candidates, top_k=50)

    # é˜¶æ®µ2ï¼šç²¾ç¡®æ¨¡å‹é‡æ’
    stage2_results = slow_model.rerank(query, stage1_results, top_k=top_k)

    return stage2_results


# ä½¿ç”¨
fast_reranker = Reranker("cross-encoder/ms-marco-TinyBERT-L-2-v2")  # å¿«é€Ÿ
slow_reranker = Reranker("cross-encoder/ms-marco-MiniLM-L-6-v2")    # ç²¾ç¡®

results = two_stage_rerank(query, candidates, fast_reranker, slow_reranker)
```

**ä¼˜åŒ–2ï¼šæ‰¹å¤„ç†ä¼˜åŒ–**

```python
class BatchReranker(Reranker):
    """
    æ‰¹å¤„ç†ä¼˜åŒ–çš„é‡æ’åºå™¨
    """

    def rerank_batch_optimized(self,
                              queries: List[str],
                              candidates_list: List[List[Tuple[str, str]]],
                              top_k: int = 10) -> List[List[Tuple[str, float]]]:
        """
        æ‰¹é‡é‡æ’åºï¼ˆä¼˜åŒ–ç‰ˆï¼‰

        ä¼˜åŒ–ç­–ç•¥ï¼š
        1. æ‰€æœ‰æŸ¥è¯¢å’Œå€™é€‰æ–‡æ¡£ç»„æˆä¸€ä¸ªå¤§æ‰¹æ¬¡
        2. ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰ç›¸å…³æ€§åˆ†æ•°
        3. å‡å°‘æ¨¡å‹è°ƒç”¨æ¬¡æ•°
        """
        all_results = []
        all_pairs = []
        all_indices = []

        # å‡†å¤‡æ‰€æœ‰æŸ¥è¯¢-æ–‡æ¡£å¯¹
        for query_idx, (query, candidates) in enumerate(zip(queries, candidates_list)):
            query_start_idx = len(all_pairs)
            for doc_id, doc_text in candidates:
                all_pairs.append((query, doc_text))
                all_indices.append((query_idx, doc_id))

        # æ‰¹é‡é¢„æµ‹
        all_scores = self.model.predict(all_pairs, batch_size=self.batch_size * 4)

        # åˆ†é…åˆ†æ•°åˆ°å„ä¸ªæŸ¥è¯¢
        results = [[] for _ in queries]
        for (query_idx, doc_id), score in zip(all_indices, all_scores):
            results[query_idx].append((doc_id, float(score)))

        # æ’åºå¹¶æˆªå–top_k
        for query_idx in range(len(queries)):
            results[query_idx].sort(key=lambda x: x[1], reverse=True)
            results[query_idx] = results[query_idx][:top_k]

        return results
```

---

## 9.5 è¯„ä¼°ä¸å¯¹æ¯”

### 9.5.1 è¯„ä¼°æŒ‡æ ‡

```python
# æ–‡ä»¶åï¼ševaluation.py
"""
æ£€ç´¢ç³»ç»Ÿè¯„ä¼°
"""

from typing import List, Dict, Tuple


def compute_hit_rate(retrieved_docs: List[str], relevant_docs: List[str]) -> float:
    """
    è®¡ç®—Hit Rate

    Hit Rate = æ˜¯å¦æ£€ç´¢åˆ°è‡³å°‘ä¸€ä¸ªç›¸å…³æ–‡æ¡£
    """
    return 1.0 if any(doc in relevant_docs for doc in retrieved_docs) else 0.0


def compute_mrr(retrieved_docs: List[str], relevant_docs: List[str]) -> float:
    """
    è®¡ç®—MRR (Mean Reciprocal Rank)

    MRR = 1 / ç¬¬ä¸€ä¸ªç›¸å…³æ–‡æ¡£çš„æ’å
    """
    for rank, doc in enumerate(retrieved_docs, start=1):
        if doc in relevant_docs:
            return 1.0 / rank
    return 0.0


def compute_precision_at_k(retrieved_docs: List[str],
                           relevant_docs: List[str],
                           k: int) -> float:
    """
    è®¡ç®—Precision@K

    Precision@K = Top-Kä¸­ç›¸å…³æ–‡æ¡£æ•° / K
    """
    retrieved_at_k = retrieved_docs[:k]
    relevant_retrieved = sum(1 for doc in retrieved_at_k if doc in relevant_docs)
    return relevant_retrieved / k if k > 0 else 0.0


def evaluate_retrieval_system(queries: List[Dict],
                              retrieval_func,
                              top_k: int = 10) -> Dict[str, float]:
    """
    è¯„ä¼°æ£€ç´¢ç³»ç»Ÿ

    Args:
        queries: æŸ¥è¯¢åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º{
            'query': str,
            'relevant_docs': List[str]
        }
        retrieval_func: æ£€ç´¢å‡½æ•°ï¼Œæ¥å—queryå’Œtop_kï¼Œè¿”å›[(doc_id, score), ...]
        top_k: è¯„ä¼°çš„top-k

    Returns:
        {
            'hit_rate': float,
            'mrr': float,
            'precision@5': float,
            'precision@10': float
        }
    """
    hit_rates = []
    mrrs = []
    precision_at_5s = []
    precision_at_10s = []

    for item in queries:
        query = item['query']
        relevant_docs = item['relevant_docs']

        # æ£€ç´¢
        retrieved = retrieval_func(query, top_k=top_k)
        retrieved_docs = [doc_id for doc_id, _ in retrieved]

        # è®¡ç®—æŒ‡æ ‡
        hit_rates.append(compute_hit_rate(retrieved_docs, relevant_docs))
        mrrs.append(compute_mrr(retrieved_docs, relevant_docs))
        precision_at_5s.append(compute_precision_at_k(retrieved_docs, relevant_docs, 5))
        precision_at_10s.append(compute_precision_at_k(retrieved_docs, relevant_docs, 10))

    # å¹³å‡
    return {
        'hit_rate': sum(hit_rates) / len(hit_rates),
        'mrr': sum(mrrs) / len(mrrs),
        'precision@5': sum(precision_at_5s) / len(precision_at_5s),
        'precision@10': sum(precision_at_10s) / len(precision_at_10s),
        'num_queries': len(queries)
    }
```

### 9.5.2 å¯¹æ¯”å®éªŒ

```python
# å¯¹æ¯”å®éªŒï¼šå‘é‡æ£€ç´¢ vs æ··åˆæ£€ç´¢ vs æ··åˆ+é‡æ’åº

# å‡†å¤‡æµ‹è¯•æ•°æ®
test_queries = [
    {
        'query': 'å¦‚ä½•ä¼˜åŒ–Pythonä»£ç æ€§èƒ½ï¼Ÿ',
        'relevant_docs': ['doc_2', 'doc_4', 'doc_6']
    },
    {
        'query': 'JavaScriptçš„V8å¼•æ“æ˜¯ä»€ä¹ˆï¼Ÿ',
        'relevant_docs': ['doc_6']
    },
    # ... æ›´å¤šæµ‹è¯•æŸ¥è¯¢
]

# å®šä¹‰ä¸‰ç§æ£€ç´¢æ–¹æ³•
def vector_only(query, top_k=10):
    """ä»…å‘é‡æ£€ç´¢"""
    return retriever._vector_retrieve(query, top_k=top_k)

def bm25_only(query, top_k=10):
    """ä»…BM25æ£€ç´¢"""
    return retriever._bm25_retrieve(query, top_k=top_k)

def hybrid_only(query, top_k=10):
    """æ··åˆæ£€ç´¢ï¼ˆæ— é‡æ’åºï¼‰"""
    return retriever.retrieve(query, top_k=top_k, weights=[0.6, 0.4])

def hybrid_with_rerank(query, top_k=10):
    """æ··åˆæ£€ç´¢ + é‡æ’åº"""
    return pipeline.retrieve(query, weights=[0.6, 0.4])

# è¯„ä¼°
methods = {
    'ä»…å‘é‡æ£€ç´¢': vector_only,
    'ä»…BM25æ£€ç´¢': bm25_only,
    'æ··åˆæ£€ç´¢': hybrid_only,
    'æ··åˆæ£€ç´¢+é‡æ’åº': hybrid_with_rerank
}

results = {}
for method_name, method_func in methods.items():
    metrics = evaluate_retrieval_system(test_queries, method_func, top_k=10)
    results[method_name] = metrics

# æ‰“å°å¯¹æ¯”ç»“æœ
print("\n" + "="*80)
print("æ£€ç´¢æ–¹æ³•å¯¹æ¯”")
print("="*80 + "\n")

print(f"{'æ–¹æ³•':<20} {'Hit Rate':<12} {'MRR':<12} {'P@5':<12} {'P@10':<12}")
print("-"*80)
for method_name, metrics in results.items():
    print(f"{method_name:<20} "
          f"{metrics['hit_rate']:<12.4f} "
          f"{metrics['mrr']:<12.4f} "
          f"{metrics['precision@5']:<12.4f} "
          f"{metrics['precision@10']:<12.4f}")

print("-"*80)
```

**é¢„æœŸè¾“å‡º**ï¼š

```
================================================================================
æ£€ç´¢æ–¹æ³•å¯¹æ¯”
================================================================================

æ–¹æ³•                 Hit Rate     MRR          P@5          P@10
--------------------------------------------------------------------------------
ä»…å‘é‡æ£€ç´¢          0.6200       0.5100       0.5800       0.5200
ä»…BM25æ£€ç´¢          0.5800       0.4700       0.5500       0.4900
æ··åˆæ£€ç´¢            0.7800       0.6800       0.7200       0.6500
æ··åˆæ£€ç´¢+é‡æ’åº      0.8500       0.7600       0.8200       0.7400
--------------------------------------------------------------------------------

æå‡å¹…åº¦ï¼š
  æ··åˆæ£€ç´¢ vs ä»…å‘é‡ï¼š
    Hit Rate: +25.8%
    MRR: +33.3%

  æ··åˆ+é‡æ’åº vs æ··åˆï¼š
    Hit Rate: +9.0%
    MRR: +11.8%

  æ··åˆ+é‡æ’åº vs ä»…å‘é‡ï¼š
    Hit Rate: +37.1%
    MRR: +49.0%
```

---

## 9.6 æœ€ä½³å®è·µ

### å®è·µ1ï¼šæ ¹æ®åœºæ™¯é€‰æ‹©æ£€ç´¢ç­–ç•¥

```python
def retrieval_strategy_selector(use_case: str) -> dict:
    """
    æ ¹æ®ä½¿ç”¨åœºæ™¯é€‰æ‹©æ£€ç´¢ç­–ç•¥

    Args:
        use_case: ä½¿ç”¨åœºæ™¯

    Returns:
        æ¨èçš„æ£€ç´¢é…ç½®
    """
    strategies = {
        'faq_system': {
            'name': 'FAQé—®ç­”ç³»ç»Ÿ',
            'recommendation': 'æ··åˆæ£€ç´¢ + é‡æ’åº',
            'reason': 'FAQéœ€è¦ç²¾ç¡®åŒ¹é…å…³é”®è¯ï¼Œä¹Ÿéœ€è¦ç†è§£è¯­ä¹‰',
            'config': {
                'use_hybrid': True,
                'use_rerank': True,
                'weights': [0.4, 0.6],  # BM25æƒé‡æ›´é«˜
                'initial_top_k': 50,
                'final_top_k': 5
            }
        },

        'knowledge_base': {
            'name': 'çŸ¥è¯†åº“æœç´¢',
            'recommendation': 'æ··åˆæ£€ç´¢',
            'reason': 'çŸ¥è¯†åº“å†…å®¹å¤šæ ·ï¼Œéœ€è¦å¹³è¡¡è¯­ä¹‰å’Œå…³é”®è¯',
            'config': {
                'use_hybrid': True,
                'use_rerank': False,  # æ•°æ®é‡å¤§æ—¶å¯èƒ½å¤ªæ…¢
                'weights': [0.6, 0.4],
                'initial_top_k': 20,
                'final_top_k': 10
            }
        },

        'code_search': {
            'name': 'ä»£ç æœç´¢',
            'recommendation': 'BM25ä¸ºä¸» + å‘é‡ä¸ºè¾…',
            'reason': 'ä»£ç éœ€è¦ç²¾ç¡®åŒ¹é…å‡½æ•°åã€å˜é‡å',
            'config': {
                'use_hybrid': True,
                'use_rerank': True,
                'weights': [0.3, 0.7],  # BM25æƒé‡æ›´é«˜
                'initial_top_k': 100,
                'final_top_k': 10
            }
        },

        'semantic_search': {
            'name': 'è¯­ä¹‰æœç´¢',
            'recommendation': 'å‘é‡æ£€ç´¢ä¸ºä¸»',
            'reason': 'ä¸»è¦ä¾èµ–è¯­ä¹‰ç†è§£ï¼Œå…³é”®è¯åŒ¹é…æ¬¡è¦',
            'config': {
                'use_hybrid': True,
                'use_rerank': False,
                'weights': [0.8, 0.2],  # å‘é‡æƒé‡æ›´é«˜
                'initial_top_k': 20,
                'final_top_k': 10
            }
        }
    }

    return strategies.get(use_case, strategies['knowledge_base'])
```

### å®è·µ2ï¼šABæµ‹è¯•æ¡†æ¶

```python
class ABTestFramework:
    """
    ABæµ‹è¯•æ¡†æ¶

    ç”¨äºå¯¹æ¯”ä¸åŒæ£€ç´¢ç­–ç•¥çš„æ•ˆæœ
    """

    def __init__(self, strategy_a: dict, strategy_b: dict):
        self.strategy_a = strategy_a
        self.strategy_b = strategy_b

    def run_test(self, test_queries: List[Dict]) -> dict:
        """
        è¿è¡ŒABæµ‹è¯•

        Returns:
            {
                'strategy_a': metrics,
                'strategy_b': metrics,
                'winner': 'a' or 'b',
                'improvement': {
                    'hit_rate': float,
                    'mrr': float
                }
            }
        """
        # è¯„ä¼°ç­–ç•¥A
        metrics_a = evaluate_retrieval_system(
            test_queries,
            self.strategy_a['retrieval_func']
        )

        # è¯„ä¼°ç­–ç•¥B
        metrics_b = evaluate_retrieval_system(
            test_queries,
            strategy_b['retrieval_func']
        )

        # å¯¹æ¯”
        winner = 'a' if metrics_a['hit_rate'] > metrics_b['hit_rate'] else 'b'

        improvement = {
            'hit_rate': ((metrics_b['hit_rate'] - metrics_a['hit_rate'])
                        / metrics_a['hit_rate'] * 100 if winner == 'b'
                        else (metrics_a['hit_rate'] - metrics_b['hit_rate'])
                        / metrics_b['hit_rate'] * 100),
            'mrr': ((metrics_b['mrr'] - metrics_a['mrr'])
                   / metrics_a['mrr'] * 100 if winner == 'b'
                   else (metrics_a['mrr'] - metrics_b['mrr'])
                   / metrics_b['mrr'] * 100)
        }

        return {
            'strategy_a': metrics_a,
            'strategy_b': metrics_b,
            'winner': winner,
            'improvement': improvement
        }
```

---

## ç»ƒä¹ é¢˜

### ç»ƒä¹ 1ï¼šåŸºç¡€ç»ƒä¹  - å®ç°RRFèåˆ

**é¢˜ç›®**ï¼šæ‰‹åŠ¨å®ç°RRFèåˆç®—æ³•

**è¦æ±‚**ï¼š
1. å®ç°RRFæ ¸å¿ƒç®—æ³•
2. æ”¯æŒå¯é…ç½®çš„kå‚æ•°
3. æ”¯æŒåŠ æƒèåˆ

**æç¤º**ï¼š
- æ’åä»1å¼€å§‹ï¼ˆä¸æ˜¯0ï¼‰
- éœ€è¦å¤„ç†æ–‡æ¡£åœ¨ä¸åŒæ£€ç´¢å™¨ä¸­å‡ºç°çš„æƒ…å†µ

**å‚è€ƒç­”æ¡ˆ**ï¼šè§rrf_fusion.py

---

### ç»ƒä¹ 2ï¼šè¿›é˜¶ç»ƒä¹  - æ„å»ºæ··åˆæ£€ç´¢ç³»ç»Ÿ

**é¢˜ç›®**ï¼šåŸºäºLlamaIndexå®ç°æ··åˆæ£€ç´¢

**è¦æ±‚**ï¼š
1. ä½¿ç”¨LlamaIndexçš„VectorStoreIndex
2. é›†æˆBM25æ£€ç´¢
3. å®ç°RRFèåˆ
4. è¯„ä¼°Hit Rateå’ŒMRR

**æç¤º**ï¼š
- LlamaIndexæä¾›äº†BM25Retriever
- å¯ä»¥ä½¿ç”¨RetrieverMode.DEFAULTæ··åˆæ¨¡å¼

---

### ç»ƒä¹ 3ï¼šæŒ‘æˆ˜é¡¹ç›® - å®Œæ•´çš„æ£€ç´¢ä¼˜åŒ–ç³»ç»Ÿ

**é¡¹ç›®æè¿°**ï¼šæ„å»ºä¸€ä¸ªç”Ÿäº§çº§çš„æ··åˆæ£€ç´¢+é‡æ’åºç³»ç»Ÿ

**åŠŸèƒ½éœ€æ±‚**ï¼š
1. âœ… æ··åˆæ£€ç´¢ï¼ˆå‘é‡+BM25ï¼‰
2. âœ… CrossEncoderé‡æ’åº
3. âœ… æŸ¥è¯¢è‡ªé€‚åº”æƒé‡è°ƒæ•´
4. âœ… ç¼“å­˜æœºåˆ¶
5. âœ… æ€§èƒ½ç›‘æ§
6. âœ… ABæµ‹è¯•æ¡†æ¶

**æ€§èƒ½è¦æ±‚**ï¼š
- Hit Rate > 0.8
- MRR > 0.7
- å¹³å‡å“åº”æ—¶é—´ < 500ms

**äº¤ä»˜æ ‡å‡†**ï¼š
- âœ… å®Œæ•´çš„ä»£ç å®ç°
- âœ… å•å…ƒæµ‹è¯•ï¼ˆæµ‹è¯•è¦†ç›–ç‡>80%ï¼‰
- âœ… æ€§èƒ½è¯„ä¼°æŠ¥å‘Š
- âœ… ä½¿ç”¨æ–‡æ¡£

---

## æ€»ç»“

### æœ¬ç« è¦ç‚¹å›é¡¾

1. **æ··åˆæ£€ç´¢ä¼˜åŠ¿**
   - å‘é‡æ£€ç´¢ï¼šè¯­ä¹‰ç†è§£å¼ºï¼Œé€‚åˆæ¨¡ç³ŠæŸ¥è¯¢
   - BM25æ£€ç´¢ï¼šå…³é”®è¯ç²¾ç¡®ï¼Œé€‚åˆä¸“æœ‰åè¯
   - æ··åˆæ£€ç´¢ï¼šç»“åˆä¸¤è€…ä¼˜åŠ¿ï¼Œæ€§èƒ½æå‡20-30%

2. **RRFç®—æ³•**
   - å€’æ•°ç§©èåˆï¼Œé¿å…åˆ†æ•°å½’ä¸€åŒ–é—®é¢˜
   - å…¬å¼ï¼šRRF = Î£ 1/(k+rank)
   - é²æ£’æ€§å¼ºï¼Œé€‚ç”¨æ€§å¹¿

3. **é‡æ’åºæŠ€æœ¯**
   - CrossEncoderæä¾›æ›´ç²¾ç¡®çš„ç›¸å…³æ€§åˆ¤æ–­
   - ä¸¤é˜¶æ®µç­–ç•¥ï¼šå¿«é€Ÿç­›é€‰ + ç²¾ç¡®é‡æ’
   - æ€§èƒ½æå‡ï¼š+10-15%

4. **æ€§èƒ½ä¼˜åŒ–**
   - åŠ¨æ€æƒé‡è°ƒæ•´
   - ç¼“å­˜ç­–ç•¥
   - æ‰¹å¤„ç†ä¼˜åŒ–
   - ä¸¤é˜¶æ®µé‡æ’åº

### å­¦ä¹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£æ··åˆæ£€ç´¢çš„åŸç†å’Œä¼˜åŠ¿
- [ ] èƒ½å¤Ÿå®ç°RRFèåˆç®—æ³•
- [ ] æŒæ¡CrossEncoderé‡æ’åº
- [ ] èƒ½å¤Ÿæ„å»ºå®Œæ•´çš„æ£€ç´¢æµç¨‹
- [ ] ç†è§£æ€§èƒ½ä¼˜åŒ–æ–¹æ³•
- [ ] èƒ½å¤Ÿè¯„ä¼°æ£€ç´¢ç³»ç»Ÿæ€§èƒ½

### ä¸‹ä¸€æ­¥å­¦ä¹ 

- **ä¸‹ä¸€ç« **ï¼š[ç¬¬10ç« ï¼šé«˜çº§RAGæ¨¡å¼](./10-é«˜çº§RAGæ¨¡å¼.md)
- **ç›¸å…³ç« èŠ‚**ï¼š
  - [ç¬¬6ç« ï¼šåµŒå…¥æ¨¡å‹æ·±å…¥](./06-åµŒå…¥æ¨¡å‹æ·±å…¥.md)
  - [ç¬¬8ç« ï¼šæŸ¥è¯¢å¢å¼ºæŠ€æœ¯](./08-æŸ¥è¯¢å¢å¼ºæŠ€æœ¯.md)
- **æ‰©å±•é˜…è¯»**ï¼š
  - RRFè®ºæ–‡: https://plg.uwaterloo.ca/~gcnguyen/files/2011-11_SummerSchool_CormackClarkeGleason.pdf
  - LlamaIndexæ··åˆæ£€ç´¢: https://docs.llamaindex.ai/en/stable/examples/retrievers/bm25_retriever.html

---

**è¿”å›ç›®å½•** | **ä¸Šä¸€ç« ** | **ä¸‹ä¸€ç« **

---

**æœ¬ç« ç»“æŸ**

> æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Ÿæ¬¢è¿æäº¤Issueæˆ–PRåˆ°æ•™ç¨‹ä»“åº“ï¼
