# ç¬¬10ç« ï¼šé«˜çº§RAGæ¨¡å¼

> åŸºç¡€RAGä¸å¤Ÿç”¨ï¼Ÿé«˜çº§RAGæ¨¡å¼è®©ç³»ç»Ÿ"æ€è€ƒ"ä½•æ—¶æ£€ç´¢ã€æ£€ç´¢ä»€ä¹ˆã€æ£€ç´¢å¤šå°‘ï¼Œæ˜¾è‘—æå‡å¤æ‚é—®é¢˜çš„å¤„ç†èƒ½åŠ›ï¼

---

## ğŸ“š å­¦ä¹ ç›®æ ‡

å­¦å®Œæœ¬ç« åï¼Œä½ å°†èƒ½å¤Ÿï¼š

- [ ] ç†è§£è¿­ä»£æ£€ç´¢çš„åŸç†å’Œåº”ç”¨åœºæ™¯
- [ ] æŒæ¡è‡ªé€‚åº”æ£€ç´¢çš„å®ç°æ–¹æ³•
- [ ] åº”ç”¨è·³è·ƒè¯»å–ï¼ˆSkip Readingï¼‰ç­–ç•¥
- [ ] ä½¿ç”¨å…ƒæ•°æ®è¿‡æ»¤ä¼˜åŒ–æ£€ç´¢
- [ ] é€‰æ‹©åˆé€‚çš„RAGæ¨¡å¼è§£å†³å®é™…é—®é¢˜

**é¢„è®¡å­¦ä¹ æ—¶é—´**ï¼š3å°æ—¶
**éš¾åº¦ç­‰çº§**ï¼šâ­â­â­â­â˜†

---

## å‰ç½®çŸ¥è¯†

åœ¨å¼€å§‹æœ¬ç« å­¦ä¹ å‰ï¼Œä½ éœ€è¦å…·å¤‡ï¼š

- [ ] å®Œæˆæ¨¡å—1çš„åŸºç¡€RAGå®ç°
- [ ] ç†è§£æ··åˆæ£€ç´¢åŸç†ï¼ˆç¬¬9ç« ï¼‰
- [ ] ç†Ÿæ‚‰æŸ¥è¯¢å¢å¼ºæŠ€æœ¯ï¼ˆç¬¬8ç« ï¼‰

**ç¯å¢ƒè¦æ±‚**ï¼š
- Python >= 3.9
- LLM APIï¼ˆOpenAI/GPT-4ç­‰ï¼‰
- å‘é‡æ•°æ®åº“ï¼ˆæ”¯æŒå…ƒæ•°æ®è¿‡æ»¤ï¼‰

---

## 10.1 RAGæ¨¡å¼æ¼”è¿›

### 10.1.1 ä»Naiveåˆ°Advanced

```
RAGæ¨¡å¼æ¼”è¿›è·¯å¾„ï¼š

Level 1: Naive RAGï¼ˆæ¨¡å—1ï¼‰
  â””â”€ ä¸€æ¬¡æ£€ç´¢ â†’ ä¸€æ¬¡ç”Ÿæˆ
  é€‚ç”¨ï¼šç®€å•é—®ç­”

Level 2: RAG + ä¼˜åŒ–ï¼ˆæ¨¡å—2ï¼‰
  â”œâ”€ æ›´å¥½çš„åµŒå…¥æ¨¡å‹
  â”œâ”€ é«˜çº§åˆ†å—ç­–ç•¥
  â”œâ”€ æŸ¥è¯¢å¢å¼º
  â””â”€ æ··åˆæ£€ç´¢ + é‡æ’åº
  é€‚ç”¨ï¼šä¸­ç­‰å¤æ‚åº¦é—®ç­”

Level 3: Advanced RAGï¼ˆæœ¬ç« ï¼‰â­
  â”œâ”€ è¿­ä»£æ£€ç´¢
  â”œâ”€ è‡ªé€‚åº”æ£€ç´¢
  â”œâ”€ è·³è·ƒè¯»å–
  â””â”€ å…ƒæ•°æ®è¿‡æ»¤
  é€‚ç”¨ï¼šå¤æ‚å¤šè·³é—®ç­”

Level 4: Agentic RAGï¼ˆæ¨¡å—3ï¼‰
  â”œâ”€ Agentè‡ªä¸»å†³ç­–
  â”œâ”€ å·¥å…·è°ƒç”¨
  â””â”€ å¤šAgentåä½œ
  é€‚ç”¨ï¼šé«˜åº¦å¤æ‚ä»»åŠ¡
```

### 10.1.2 ä½•æ—¶éœ€è¦é«˜çº§RAGï¼Ÿ

**åœºæ™¯1ï¼šå¤šè·³æ¨ç†**

```
ç”¨æˆ·é—®é¢˜ï¼š"é©¬æ–¯å…‹çš„ç«ç®­å…¬å¸æœ€è¿‘ä¸€æ¬¡å‘å°„æ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿ"

Naive RAGï¼š
  âŒ æ£€ç´¢"é©¬æ–¯å…‹ç«ç®­å…¬å¸å‘å°„"
  âŒ æ— æ³•å…³è”"é©¬æ–¯å…‹"â†’"SpaceX"â†’"æœ€æ–°å‘å°„"

Advanced RAGï¼ˆè¿­ä»£æ£€ç´¢ï¼‰ï¼š
  âœ… ç¬¬1è½®ï¼šæ£€ç´¢"é©¬æ–¯å…‹ç«ç®­å…¬å¸" â†’ å‘ç°SpaceX
  âœ… ç¬¬2è½®ï¼šæ£€ç´¢"SpaceXæœ€æ–°å‘å°„" â†’ æ‰¾åˆ°å‘å°„ä¿¡æ¯
  âœ… ç¬¬3è½®ï¼šæ£€ç´¢å…·ä½“å‘å°„æ—¶é—´å’Œè¯¦æƒ… â†’ å®Œæ•´ç­”æ¡ˆ
```

**åœºæ™¯2ï¼šä¿¡æ¯ä¸å…¨**

```
ç”¨æˆ·é—®é¢˜ï¼š"è¿™ä¸ªAPIæœ‰ä»€ä¹ˆé™åˆ¶ï¼Ÿ"

Naive RAGï¼š
  âŒ ä¸ç¡®å®šæ˜¯å“ªä¸ªAPI
  âŒ æ£€ç´¢ç»“æœå¯èƒ½ä¸ç›¸å…³

Advanced RAGï¼ˆè‡ªé€‚åº”æ£€ç´¢ï¼‰ï¼š
  âœ… æ£€æµ‹ä¿¡æ¯ä¸è¶³
  âœ… è¯¢é—®ç”¨æˆ·ï¼š"æ‚¨æŒ‡çš„æ˜¯å“ªä¸ªAPIï¼Ÿ"
  âœ… æ ¹æ®ç”¨æˆ·å›ç­”ç²¾ç¡®æ£€ç´¢
```

**åœºæ™¯3ï¼šé•¿å°¾çŸ¥è¯†**

```
ç”¨æˆ·é—®é¢˜ï¼š"è§£é‡Šé‡å­çº ç¼ åœ¨é‡å­è®¡ç®—ä¸­çš„åº”ç”¨"

Naive RAGï¼š
  âŒ æ£€ç´¢åˆ°å¤§é‡åŸºç¡€æ–‡æ¡£
  âŒ ç­”æ¡ˆè¿‡äºå®½æ³›

Advanced RAGï¼ˆå…ƒæ•°æ®è¿‡æ»¤ï¼‰ï¼š
  âœ… æŒ‰éš¾åº¦ç­‰çº§è¿‡æ»¤ï¼ˆé«˜çº§ï¼‰
  âœ… æŒ‰ä¸»é¢˜è¿‡æ»¤ï¼ˆé‡å­è®¡ç®—ï¼‰
  âœ… æ£€ç´¢åˆ°ç²¾ç¡®çš„é«˜çº§æ–‡æ¡£
```

---

## 10.2 è¿­ä»£æ£€ç´¢

### 10.2.1 åŸç†

**ä»€ä¹ˆæ˜¯è¿­ä»£æ£€ç´¢ï¼Ÿ**

```
ä¼ ç»ŸRAGï¼š
  Query â†’ [ä¸€æ¬¡æ£€ç´¢] â†’ Context â†’ Answer

è¿­ä»£RAGï¼š
  Query â†’ [æ£€ç´¢1] â†’ Context1 â†’ [åˆ†æ/åˆ¤æ–­]
                â†“
          éœ€è¦æ›´å¤šä¿¡æ¯ï¼Ÿ
           â†™          â†˜
         Yes          No
         â†“             â†“
  [ç”Ÿæˆæ–°æŸ¥è¯¢]    [ç»¼åˆç­”æ¡ˆ]
         â†“
  [æ£€ç´¢2] â†’ Context2 â†’ [åˆ†æ/åˆ¤æ–­]
              â†“
        ...
```

**æ ¸å¿ƒæ€æƒ³**ï¼š
- ä¸ä¸€æ¬¡æ€§æ£€ç´¢æ‰€æœ‰ä¿¡æ¯
- æ ¹æ®å½“å‰æ£€ç´¢ç»“æœï¼Œå†³å®šæ˜¯å¦éœ€è¦ç»§ç»­æ£€ç´¢
- æ¯è½®æ£€ç´¢éƒ½åŸºäºä¸Šä¸€è½®çš„ç†è§£

### 10.2.2 å®ç°æ–¹æ³•

**æ–¹æ³•1ï¼šå›ºå®šè¿­ä»£æ¬¡æ•°**

```python
# æ–‡ä»¶åï¼šiterative_retrieval.py
"""
è¿­ä»£æ£€ç´¢å®ç°
"""

from typing import List, Tuple, Optional
import time


class IterativeRetriever:
    """
    è¿­ä»£æ£€ç´¢å™¨

    é€šè¿‡å¤šè½®æ£€ç´¢é€æ­¥æ”¶é›†ä¿¡æ¯ï¼Œç”Ÿæˆå®Œæ•´ç­”æ¡ˆ

    Args:
        retriever: åŸºç¡€æ£€ç´¢å™¨
        llm_client: LLMå®¢æˆ·ç«¯
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        stop_threshold: åœæ­¢é˜ˆå€¼ï¼ˆåˆ†æ•°ä½äºæ­¤å€¼æ—¶åœæ­¢ï¼‰

    Example:
        >>> iterative_retriever = IterativeRetriever(retriever, llm_client)
        >>> result = iterative_retriever.retrieve(
        ...     "é©¬æ–¯å…‹çš„ç«ç®­å…¬å¸æœ€è¿‘ä¸€æ¬¡å‘å°„æ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿ",
        ...     max_iterations=3
        ... )
        >>> print(result['answer'])
    """

    def __init__(self,
                 retriever,
                 llm_client,
                 max_iterations: int = 3,
                 stop_threshold: float = 0.5):

        self.retriever = retriever
        self.llm_client = llm_client
        self.max_iterations = max_iterations
        self.stop_threshold = stop_threshold

    def retrieve(self, query: str, max_iterations: int = None) -> dict:
        """
        è¿­ä»£æ£€ç´¢

        Args:
            query: åŸå§‹æŸ¥è¯¢
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œè¦†ç›–åˆå§‹åŒ–æ—¶çš„è®¾ç½®

        Returns:
            {
                'answer': str,              # æœ€ç»ˆç­”æ¡ˆ
                'contexts': List[str],       # æ‰€æœ‰æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
                'iteration_count': int,      # å®é™…è¿­ä»£æ¬¡æ•°
                'queries_used': List[str],   # æ¯è½®ä½¿ç”¨çš„æŸ¥è¯¢
                'reasoning_trace': List[str] # æ¨ç†è¿‡ç¨‹
            }

        Example:
            >>> result = iterative_retriever.retrieve(
            ...     "Pythonå’ŒJavaScriptåœ¨Webå¼€å‘ä¸­çš„å·®å¼‚"
            ... )
            >>> print(f"è¿­ä»£æ¬¡æ•°: {result['iteration_count']}")
            >>> print(f"ç­”æ¡ˆ: {result['answer']}")
        """
        if max_iterations is None:
            max_iterations = self.max_iterations

        # åˆå§‹åŒ–
        all_contexts = []
        queries_used = []
        reasoning_trace = []
        current_query = query

        # è¿­ä»£æ£€ç´¢
        for iteration in range(1, max_iterations + 1):
            print(f"\n=== ç¬¬{iteration}è½®è¿­ä»£ ===")

            # æ£€ç´¢
            retrieved_docs = self.retriever.retrieve(current_query, top_k=3)
            context = "\n\n".join([doc['text'] for doc in retrieved_docs])
            all_contexts.append(context)
            queries_used.append(current_query)

            print(f"æŸ¥è¯¢: {current_query}")
            print(f"æ£€ç´¢åˆ° {len(retrieved_docs)} ä¸ªæ–‡æ¡£")

            # åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­
            if iteration < max_iterations:
                decision = self._decide_continue(
                    original_query=query,
                    current_query=current_query,
                    context=context,
                    iteration=iteration
                )

                reasoning_trace.append(decision['reasoning'])

                if decision['should_continue']:
                    # æ›´æ–°æŸ¥è¯¢
                    current_query = decision['next_query']
                    print(f"ç»§ç»­æ£€ç´¢: {current_query}")
                else:
                    print("åœæ­¢è¿­ä»£ï¼Œä¿¡æ¯å·²å……è¶³")
                    break
            else:
                print(f"è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°({max_iterations})ï¼Œåœæ­¢")

        # ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        print("\n=== ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ ===")
        final_context = "\n\n".join(all_contexts)
        answer = self._generate_answer(query, final_context)

        return {
            'answer': answer,
            'contexts': all_contexts,
            'iteration_count': len(all_contexts),
            'queries_used': queries_used,
            'reasoning_trace': reasoning_trace
        }

    def _decide_continue(self,
                        original_query: str,
                        current_query: str,
                        context: str,
                        iteration: int) -> dict:
        """
        å†³å®šæ˜¯å¦ç»§ç»­æ£€ç´¢

        Returns:
            {
                'should_continue': bool,
                'next_query': str,
                'reasoning': str
            }
        """
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¿¡æ¯æ£€ç´¢ä¸“å®¶ã€‚è¯·åˆ†æå½“å‰æ£€ç´¢ç»“æœæ˜¯å¦è¶³å¤Ÿå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

åŸå§‹é—®é¢˜ï¼š{original_query}
å½“å‰æŸ¥è¯¢ï¼š{current_query}
å½“å‰è¿­ä»£ï¼šç¬¬{iteration}è½®

æ£€ç´¢åˆ°çš„ä¿¡æ¯ï¼š
{context[:1000]}...

è¯·åˆ¤æ–­ï¼š
1. å½“å‰ä¿¡æ¯æ˜¯å¦è¶³ä»¥å›ç­”åŸå§‹é—®é¢˜ï¼Ÿ
2. å¦‚æœä¸è¶³ï¼Œè¿˜éœ€è¦ä»€ä¹ˆä¿¡æ¯ï¼Ÿ
3. ä¸‹ä¸€è½®åº”è¯¥æ£€ç´¢ä»€ä¹ˆï¼Ÿ

ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
    "should_continue": true/false,
    "next_query": "å¦‚æœç»§ç»­ï¼Œä¸‹ä¸€è½®çš„æŸ¥è¯¢",
    "reasoning": "åˆ¤æ–­ç†ç”±"
}}
"""

        response = self.llm_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0
        )

        import json
        try:
            decision = json.loads(response.choices[0].message.content)
            return decision
        except:
            # è§£æå¤±è´¥ï¼Œé»˜è®¤åœæ­¢
            return {
                'should_continue': False,
                'next_query': '',
                'reasoning': 'LLMè¿”å›æ ¼å¼é”™è¯¯ï¼Œåœæ­¢è¿­ä»£'
            }

    def _generate_answer(self, query: str, context: str) -> str:
        """
        åŸºäºæ‰€æœ‰æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆ
        """
        prompt = f"""
åŸºäºä»¥ä¸‹æ£€ç´¢åˆ°çš„ä¿¡æ¯ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚è¯·ç»¼åˆæ‰€æœ‰ä¿¡æ¯ï¼Œç»™å‡ºå®Œæ•´å‡†ç¡®çš„ç­”æ¡ˆã€‚

ç”¨æˆ·é—®é¢˜ï¼š{query}

æ£€ç´¢åˆ°çš„ä¿¡æ¯ï¼š
{context}

ç­”æ¡ˆï¼š
"""

        response = self.llm_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )

        return response.choices[0].message.content


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    from openai import OpenAI

    # åˆå§‹åŒ–
    client = OpenAI()

    # æ¨¡æ‹Ÿæ£€ç´¢å™¨ï¼ˆå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºçœŸå®æ£€ç´¢å™¨ï¼‰
    class MockRetriever:
        def retrieve(self, query, top_k=3):
            # æ¨¡æ‹Ÿè¿”å›
            return [
                {'text': f'{query}çš„ç›¸å…³æ–‡æ¡£1...'},
                {'text': f'{query}çš„ç›¸å…³æ–‡æ¡£2...'},
                {'text': f'{query}çš„ç›¸å…³æ–‡æ¡£3...'}
            ]

    retriever = MockRetriever()

    # åˆ›å»ºè¿­ä»£æ£€ç´¢å™¨
    iterative_retriever = IterativeRetriever(
        retriever=retriever,
        llm_client=client,
        max_iterations=3
    )

    # æµ‹è¯•æŸ¥è¯¢
    query = "é©¬æ–¯å…‹çš„ç«ç®­å…¬å¸æœ€è¿‘ä¸€æ¬¡å‘å°„æ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿ"
    print(f"\n{'='*80}")
    print(f"æŸ¥è¯¢: {query}")
    print(f"{'='*80}")

    result = iterative_retriever.retrieve(query)

    # æ‰“å°ç»“æœ
    print(f"\n{'='*80}")
    print("æœ€ç»ˆç»“æœ")
    print(f"{'='*80}")
    print(f"\nè¿­ä»£æ¬¡æ•°: {result['iteration_count']}")
    print(f"\nä½¿ç”¨çš„æŸ¥è¯¢:")
    for i, q in enumerate(result['queries_used'], 1):
        print(f"  ç¬¬{i}è½®: {q}")

    print(f"\næ¨ç†è¿‡ç¨‹:")
    for i, reasoning in enumerate(result['reasoning_trace'], 1):
        print(f"  ç¬¬{i}è½®: {reasoning}")

    print(f"\næœ€ç»ˆç­”æ¡ˆ:")
    print(result['answer'])
```

**æ–¹æ³•2ï¼šåŠ¨æ€åœæ­¢åˆ¤æ–­**

```python
class DynamicIterativeRetriever(IterativeRetriever):
    """
    åŠ¨æ€è¿­ä»£æ£€ç´¢å™¨

    æ ¹æ®ä¿¡æ¯å®Œæ•´åº¦åŠ¨æ€å†³å®šæ˜¯å¦åœæ­¢
    """

    def _decide_continue(self,
                        original_query: str,
                        current_query: str,
                        context: str,
                        iteration: int) -> dict:
        """
        å¢å¼ºçš„åœæ­¢åˆ¤æ–­

        åˆ¤æ–­æ ‡å‡†ï¼š
        1. ä¿¡æ¯å®Œæ•´åº¦ï¼ˆåŸºäºLLMè¯„åˆ†ï¼‰
        2. æ£€ç´¢ç»“æœç›¸å…³æ€§
        3. æŸ¥è¯¢è¦†ç›–åº¦
        """
        # è¯„åˆ†ä¿¡æ¯å®Œæ•´åº¦ï¼ˆ1-10åˆ†ï¼‰
        completeness_score = self._score_completeness(
            original_query, context
        )

        print(f"ä¿¡æ¯å®Œæ•´åº¦è¯„åˆ†: {completeness_score}/10")

        # é˜ˆå€¼åˆ¤æ–­
        if completeness_score >= 8:
            return {
                'should_continue': False,
                'next_query': '',
                'reasoning': f'ä¿¡æ¯å®Œæ•´åº¦({completeness_score}/10)å·²è¶³å¤Ÿ'
            }

        # ç”Ÿæˆä¸‹ä¸€è½®æŸ¥è¯¢
        next_query = self._generate_next_query(
            original_query=original_query,
            current_context=context,
            iteration=iteration
        )

        return {
            'should_continue': True,
            'next_query': next_query,
            'reasoning': f'ä¿¡æ¯å®Œæ•´åº¦({completeness_score}/10)ä¸è¶³ï¼Œéœ€è¦ç»§ç»­æ£€ç´¢'
        }

    def _score_completeness(self, query: str, context: str) -> float:
        """
        è¯„åˆ†ä¿¡æ¯å®Œæ•´åº¦

        Returns:
            1-10çš„è¯„åˆ†
        """
        prompt = f"""
è¯·è¯„åˆ†å½“å‰ä¿¡æ¯æ˜¯å¦è¶³ä»¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼ˆ1-10åˆ†ï¼‰ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{query}

å½“å‰ä¿¡æ¯ï¼š
{context[:500]}...

è¯„åˆ†æ ‡å‡†ï¼š
- 1-3åˆ†ï¼šä¿¡æ¯ä¸¥é‡ä¸è¶³ï¼Œæ— æ³•å›ç­”
- 4-6åˆ†ï¼šä¿¡æ¯éƒ¨åˆ†å……è¶³ï¼Œå¯ä»¥ç»™å‡ºåˆæ­¥ç­”æ¡ˆ
- 7-8åˆ†ï¼šä¿¡æ¯åŸºæœ¬å……è¶³ï¼Œå¯ä»¥ç»™å‡ºè¾ƒå®Œæ•´ç­”æ¡ˆ
- 9-10åˆ†ï¼šä¿¡æ¯éå¸¸å……è¶³ï¼Œå¯ä»¥ç»™å‡ºè¯¦ç»†å®Œæ•´ç­”æ¡ˆ

è¯·åªè¿”å›ä¸€ä¸ªæ•°å­—ï¼ˆ1-10ï¼‰ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""

        response = self.llm_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0
        )

        try:
            score = float(response.choices[0].message.content.strip())
            return min(max(score, 1.0), 10.0)  # é™åˆ¶åœ¨[1,10]
        except:
            return 5.0  # è§£æå¤±è´¥ï¼Œè¿”å›ä¸­é—´å€¼

    def _generate_next_query(self,
                            original_query: str,
                            current_context: str,
                            iteration: int) -> str:
        """
        ç”Ÿæˆä¸‹ä¸€è½®æŸ¥è¯¢
        """
        prompt = f"""
åŸºäºåŸå§‹é—®é¢˜å’Œå½“å‰å·²çŸ¥ä¿¡æ¯ï¼Œç”Ÿæˆä¸‹ä¸€è½®æ£€ç´¢æŸ¥è¯¢ã€‚

åŸå§‹é—®é¢˜ï¼š{original_query}

å·²çŸ¥ä¿¡æ¯ï¼š
{current_context[:500]}...

è¯·ç”Ÿæˆä¸€ä¸ªå…·ä½“çš„æ£€ç´¢æŸ¥è¯¢ï¼Œå¸®åŠ©è·å–ç¼ºå¤±çš„å…³é”®ä¿¡æ¯ã€‚

æŸ¥è¯¢è¦æ±‚ï¼š
1. å…·ä½“æ˜ç¡®ï¼ŒåŒ…å«å…³é”®å®ä½“
2. é¿å…é‡å¤å·²æœ‰ä¿¡æ¯
3. ä¸“æ³¨äºç¼ºå¤±çš„å…³é”®ç‚¹

è¿”å›æ ¼å¼ï¼šç›´æ¥è¿”å›æŸ¥è¯¢æ–‡æœ¬ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""

        response = self.llm_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )

        return response.choices[0].message.content.strip()
```

### 10.2.3 è¿­ä»£æ£€ç´¢çš„åœºæ™¯

**åœºæ™¯1ï¼šå¤šè·³æ¨ç†**

```
é—®é¢˜ï¼š"ã€Šé˜¿å‡¡è¾¾ã€‹å¯¼æ¼”çš„ä¸‹ä¸€éƒ¨ç”µå½±æ˜¯ä»€ä¹ˆï¼Ÿ"

è¿­ä»£è¿‡ç¨‹ï¼š
  ç¬¬1è½®ï¼šæ£€ç´¢"é˜¿å‡¡è¾¾å¯¼æ¼”" â†’ è©¹å§†æ–¯Â·å¡æ¢…éš†
  ç¬¬2è½®ï¼šæ£€ç´¢"è©¹å§†æ–¯Â·å¡æ¢…éš†ä¸‹ä¸€éƒ¨ç”µå½±" â†’ ã€Šé˜¿å‡¡è¾¾3ã€‹
  ç¬¬3è½®ï¼šæ£€ç´¢"é˜¿å‡¡è¾¾3ä¸Šæ˜ æ—¶é—´" â†’ 2025å¹´12æœˆ

ç­”æ¡ˆï¼šè©¹å§†æ–¯Â·å¡æ¢…éš†çš„ä¸‹ä¸€éƒ¨ç”µå½±æ˜¯ã€Šé˜¿å‡¡è¾¾3ã€‹ï¼Œé¢„è®¡2025å¹´12æœˆä¸Šæ˜ ã€‚
```

**åœºæ™¯2ï¼šå¤æ‚æ¯”è¾ƒ**

```
é—®é¢˜ï¼š"å¯¹æ¯”Pythonå’ŒJavaScriptåœ¨æœºå™¨å­¦ä¹ é¢†åŸŸçš„åº”ç”¨"

è¿­ä»£è¿‡ç¨‹ï¼š
  ç¬¬1è½®ï¼šæ£€ç´¢"Pythonæœºå™¨å­¦ä¹ åº”ç”¨" â†’ Pythonçš„MLç”Ÿæ€
  ç¬¬2è½®ï¼šæ£€ç´¢"JavaScriptæœºå™¨å­¦ä¹ åº”ç”¨" â†’ TensorFlow.jsç­‰
  ç¬¬3è½®ï¼šæ£€ç´¢"Python vs JavaScriptæœºå™¨å­¦ä¹ " â†’ ç›´æ¥å¯¹æ¯”æ–‡ç« 

ç­”æ¡ˆï¼šPythonåœ¨MLé¢†åŸŸå ä¸»å¯¼ï¼ˆä¸°å¯Œçš„åº“ï¼‰ï¼ŒJSé€‚åˆWebç«¯MLæ¨ç†ã€‚
```

---

## 10.3 è‡ªé€‚åº”æ£€ç´¢

### 10.3.1 åŸç†

**ä»€ä¹ˆæ˜¯è‡ªé€‚åº”æ£€ç´¢ï¼Ÿ**

```
ä¼ ç»ŸRAGï¼š
  æ‰€æœ‰æŸ¥è¯¢ â†’ ç»Ÿä¸€çš„æ£€ç´¢ç­–ç•¥ â†’ å›ºå®šTop-K

è‡ªé€‚åº”RAGï¼š
  åˆ†ææŸ¥è¯¢ç‰¹å¾
       â†“
  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
  â”‚         â”‚
ç®€å•æŸ¥è¯¢   å¤æ‚æŸ¥è¯¢
  â”‚         â”‚
  â†“         â†“
ç›´æ¥å›ç­”   æ·±åº¦æ£€ç´¢
  â†“         â†“
å¿«é€Ÿå“åº”   å®Œæ•´ç­”æ¡ˆ
```

**æ ¸å¿ƒæ€æƒ³**ï¼š
- ä¸å¯¹æ‰€æœ‰æŸ¥è¯¢ä½¿ç”¨ç›¸åŒç­–ç•¥
- æ ¹æ®æŸ¥è¯¢å¤æ‚åº¦åŠ¨æ€è°ƒæ•´
- å¹³è¡¡é€Ÿåº¦å’Œè´¨é‡

### 10.3.2 æŸ¥è¯¢å¤æ‚åº¦è¯„ä¼°

```python
# æ–‡ä»¶åï¼šadaptive_retrieval.py
"""
è‡ªé€‚åº”æ£€ç´¢å®ç°
"""

from typing import Dict, List
import re


class QueryComplexityAnalyzer:
    """
    æŸ¥è¯¢å¤æ‚åº¦åˆ†æå™¨

    Args:
        llm_client: LLMå®¢æˆ·ç«¯

    Example:
        >>> analyzer = QueryComplexityAnalyzer(llm_client)
        >>> complexity = analyzer.analyze("Pythonæ€§èƒ½ä¼˜åŒ–æŠ€å·§")
        >>> print(complexity['level'])  # 'simple', 'medium', 'complex'
    """

    def __init__(self, llm_client):
        self.llm_client = llm_client

    def analyze(self, query: str) -> Dict:
        """
        åˆ†ææŸ¥è¯¢å¤æ‚åº¦

        Returns:
            {
                'level': 'simple' | 'medium' | 'complex',
                'score': float,  # 0-1
                'features': Dict,
                'strategy': str
            }
        """
        # ç‰¹å¾æå–
        features = self._extract_features(query)

        # è§„åˆ™åˆ†ç±»
        rule_based_level = self._rule_based_classification(features)

        # LLMéªŒè¯ï¼ˆå¯é€‰ï¼‰
        llm_based_level = self._llm_based_classification(query)

        # ç»¼åˆåˆ¤æ–­
        final_level = self._combine_classification(
            rule_based_level,
            llm_based_level
        )

        # æ¨èæ£€ç´¢ç­–ç•¥
        strategy = self._recommend_strategy(final_level)

        return {
            'level': final_level,
            'score': self._level_to_score(final_level),
            'features': features,
            'strategy': strategy
        }

    def _extract_features(self, query: str) -> Dict:
        """
        æå–æŸ¥è¯¢ç‰¹å¾
        """
        features = {
            'length': len(query.split()),
            'has_entities': bool(re.findall(r'[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*', query)),
            'has_numbers': bool(re.search(r'\d+', query)),
            'has_compare_words': bool(re.search(r'å¯¹æ¯”|æ¯”è¾ƒ|å·®å¼‚|åŒºåˆ«|vs|versus', query, re.I)),
            'has_how_words': bool(re.search(r'å¦‚ä½•|æ€ä¹ˆ|æ€æ ·|æ–¹æ³•', query, re.I)),
            'has_why_words': bool(re.search(r'ä¸ºä»€ä¹ˆ|ä¸ºä½•|åŸå› ', query, re.I)),
            'has_what_words': bool(re.search(r'æ˜¯ä»€ä¹ˆ|ä»€ä¹ˆæ˜¯|å®šä¹‰', query, re.I)),
            'question_marks': query.count('?') + query.count('ï¼Ÿ'),
            'has_multi_part': bool(re.search(r'[ï¼Œ,ã€]', query)),
        }

        return features

    def _rule_based_classification(self, features: Dict) -> str:
        """
        åŸºäºè§„åˆ™çš„åˆ†ç±»
        """
        score = 0

        # é•¿åº¦å¾—åˆ†
        if features['length'] > 15:
            score += 2
        elif features['length'] > 8:
            score += 1

        # å®ä½“è¯†åˆ«
        if features['has_entities']:
            score += 1

        # å¤æ‚é—®é¢˜è¯
        if features['has_compare_words']:
            score += 2
        if features['has_how_words']:
            score += 1
        if features['has_why_words']:
            score += 2

        # å¤šéƒ¨åˆ†é—®é¢˜
        if features['has_multi_part']:
            score += 2

        # åˆ†ç±»
        if score >= 5:
            return 'complex'
        elif score >= 3:
            return 'medium'
        else:
            return 'simple'

    def _llm_based_classification(self, query: str) -> str:
        """
        åŸºäºLLMçš„åˆ†ç±»ï¼ˆå¯é€‰ï¼‰
        """
        prompt = f"""
è¯·è¯„ä¼°ä»¥ä¸‹æŸ¥è¯¢çš„å¤æ‚åº¦ï¼ˆsimple/medium/complexï¼‰ï¼š

æŸ¥è¯¢ï¼š{query}

è¯„ä¼°æ ‡å‡†ï¼š
- Simple: å•ä¸€äº‹å®ï¼Œç›´æ¥æŸ¥è¯¢ï¼Œå¦‚"Pythonæ˜¯ä»€ä¹ˆï¼Ÿ"
- Medium: éœ€è¦ä¸€å®šæ¨ç†ï¼Œå¦‚"å¦‚ä½•ä¼˜åŒ–Pythonä»£ç ï¼Ÿ"
- Complex: å¤šè·³æ¨ç†ï¼Œæ¯”è¾ƒåˆ†æï¼Œå¦‚"å¯¹æ¯”Pythonå’ŒJavaScriptåœ¨Webå¼€å‘ä¸­çš„ä¼˜åŠ£åŠ¿"

è¿”å›æ ¼å¼ï¼šåªè¿”å›ä¸€ä¸ªè¯ï¼ˆsimple/medium/complexï¼‰ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""

        try:
            response = self.llm_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.0
            )

            result = response.choices[0].message.content.strip().lower()
            if result in ['simple', 'medium', 'complex']:
                return result
        except:
            pass

        return 'medium'  # é»˜è®¤ä¸­ç­‰

    def _combine_classification(self,
                               rule_level: str,
                               llm_level: str) -> str:
        """
        ç»¼åˆä¸¤ç§åˆ†ç±»ç»“æœ
        """
        # ä¼˜å…ˆLLMåˆ¤æ–­
        return llm_level

    def _level_to_score(self, level: str) -> float:
        """
        å°†çº§åˆ«è½¬æ¢ä¸º0-1åˆ†æ•°
        """
        scores = {'simple': 0.2, 'medium': 0.5, 'complex': 0.8}
        return scores.get(level, 0.5)

    def _recommend_strategy(self, level: str) -> str:
        """
        æ¨èæ£€ç´¢ç­–ç•¥
        """
        strategies = {
            'simple': 'direct_retrieval',  # ç›´æ¥æ£€ç´¢
            'medium': 'hybrid_retrieval',  # æ··åˆæ£€ç´¢
            'complex': 'iterative_retrieval'  # è¿­ä»£æ£€ç´¢
        }
        return strategies.get(level, 'hybrid_retrieval')


class AdaptiveRetrievalSystem:
    """
    è‡ªé€‚åº”æ£€ç´¢ç³»ç»Ÿ

    æ ¹æ®æŸ¥è¯¢å¤æ‚åº¦è‡ªåŠ¨é€‰æ‹©æ£€ç´¢ç­–ç•¥
    """

    def __init__(self,
                 retriever,
                 llm_client,
                 iterative_retriever=None):

        self.retriever = retriever
        self.llm_client = llm_client
        self.iterative_retriever = iterative_retriever

        self.complexity_analyzer = QueryComplexityAnalyzer(llm_client)

    def retrieve(self, query: str) -> Dict:
        """
        è‡ªé€‚åº”æ£€ç´¢

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬

        Returns:
            {
                'answer': str,
                'strategy_used': str,
                'complexity_level': str,
                'retrieval_time': float
            }
        """
        import time
        start_time = time.time()

        # åˆ†æå¤æ‚åº¦
        print(f"\nåˆ†ææŸ¥è¯¢å¤æ‚åº¦...")
        complexity = self.complexity_analyzer.analyze(query)

        print(f"å¤æ‚åº¦çº§åˆ«: {complexity['level']}")
        print(f"æ¨èç­–ç•¥: {complexity['strategy']}")

        # æ ¹æ®ç­–ç•¥æ£€ç´¢
        strategy = complexity['strategy']

        if strategy == 'direct_retrieval':
            # ç®€å•æŸ¥è¯¢ï¼šç›´æ¥æ£€ç´¢
            print("ä½¿ç”¨ç­–ç•¥ï¼šç›´æ¥æ£€ç´¢")
            answer = self._direct_retrieve(query)

        elif strategy == 'hybrid_retrieval':
            # ä¸­ç­‰æŸ¥è¯¢ï¼šæ··åˆæ£€ç´¢
            print("ä½¿ç”¨ç­–ç•¥ï¼šæ··åˆæ£€ç´¢")
            answer = self._hybrid_retrieve(query)

        elif strategy == 'iterative_retrieval':
            # å¤æ‚æŸ¥è¯¢ï¼šè¿­ä»£æ£€ç´¢
            print("ä½¿ç”¨ç­–ç•¥ï¼šè¿­ä»£æ£€ç´¢")
            if self.iterative_retriever:
                result = self.iterative_retriever.retrieve(query)
                answer = result['answer']
            else:
                # å›é€€åˆ°æ··åˆæ£€ç´¢
                print("è­¦å‘Šï¼šè¿­ä»£æ£€ç´¢å™¨æœªé…ç½®ï¼Œå›é€€åˆ°æ··åˆæ£€ç´¢")
                answer = self._hybrid_retrieve(query)

        retrieval_time = time.time() - start_time

        return {
            'answer': answer,
            'strategy_used': strategy,
            'complexity_level': complexity['level'],
            'retrieval_time': retrieval_time
        }

    def _direct_retrieve(self, query: str) -> str:
        """
        ç›´æ¥æ£€ç´¢ï¼ˆç®€å•æŸ¥è¯¢ï¼‰
        """
        # æ£€ç´¢Top-3
        results = self.retriever.retrieve(query, top_k=3)

        # ç›´æ¥ç”Ÿæˆç­”æ¡ˆ
        context = "\n".join([doc['text'] for doc in results[:3]])

        answer = self._generate_answer(query, context)
        return answer

    def _hybrid_retrieve(self, query: str) -> str:
        """
        æ··åˆæ£€ç´¢ï¼ˆä¸­ç­‰æŸ¥è¯¢ï¼‰
        """
        # æ£€ç´¢Top-5
        results = self.retriever.retrieve(query, top_k=5)

        # ç”Ÿæˆç­”æ¡ˆ
        context = "\n".join([doc['text'] for doc in results[:5]])

        answer = self._generate_answer(query, context)
        return answer

    def _generate_answer(self, query: str, context: str) -> str:
        """
        ç”Ÿæˆç­”æ¡ˆ
        """
        prompt = f"""
åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜ï¼š

é—®é¢˜ï¼š{query}

ä¿¡æ¯ï¼š
{context}

ç­”æ¡ˆï¼š
"""

        response = self.llm_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )

        return response.choices[0].message.content


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    from openai import OpenAI

    client = OpenAI()

    # æ¨¡æ‹Ÿæ£€ç´¢å™¨
    class MockRetriever:
        def retrieve(self, query, top_k=5):
            return [
                {'text': f'{query}çš„ç›¸å…³æ–‡æ¡£1...'},
                {'text': f'{query}çš„ç›¸å…³æ–‡æ¡£2...'},
                {'text': f'{query}çš„ç›¸å…³æ–‡æ¡£3...'},
            ]

    retriever = MockRetriever()

    # åˆ›å»ºè‡ªé€‚åº”æ£€ç´¢ç³»ç»Ÿ
    adaptive_system = AdaptiveRetrievalSystem(
        retriever=retriever,
        llm_client=client
    )

    # æµ‹è¯•ä¸åŒå¤æ‚åº¦çš„æŸ¥è¯¢
    test_queries = [
        "Pythonæ˜¯ä»€ä¹ˆï¼Ÿ",  # Simple
        "å¦‚ä½•ä¼˜åŒ–Pythonä»£ç æ€§èƒ½ï¼Ÿ",  # Medium
        "å¯¹æ¯”Pythonå’ŒJavaScriptåœ¨Webå¼€å‘ä¸­çš„ä¼˜åŠ£åŠ¿"  # Complex
    ]

    for query in test_queries:
        print(f"\n{'='*80}")
        print(f"æŸ¥è¯¢: {query}")
        print(f"{'='*80}")

        result = adaptive_system.retrieve(query)

        print(f"\nä½¿ç”¨ç­–ç•¥: {result['strategy_used']}")
        print(f"å¤æ‚åº¦: {result['complexity_level']}")
        print(f"æ£€ç´¢æ—¶é—´: {result['retrieval_time']:.2f}ç§’")
        print(f"\nç­”æ¡ˆ:\n{result['answer']}\n")
```

---

## 10.4 è·³è·ƒè¯»å–ï¼ˆSkip Readingï¼‰

### 10.4.1 åŸç†

**ä»€ä¹ˆæ˜¯Skip Readingï¼Ÿ**

```
ä¼ ç»Ÿæ£€ç´¢ï¼š
  æ£€ç´¢Top-Kæ–‡æ¡£ â†’ è¯»å–å…¨éƒ¨ â†’ ç”Ÿæˆç­”æ¡ˆ
  é—®é¢˜ï¼šå¯èƒ½åŒ…å«ä¸ç›¸å…³çš„æ–‡æ¡£

Skip Readingï¼š
  æ£€ç´¢Top-Kæ–‡æ¡£ â†’ æ™ºèƒ½ç­›é€‰ â†’ åªè¯»é‡è¦æ–‡æ¡£ â†’ ç”Ÿæˆç­”æ¡ˆ
  ä¼˜åŠ¿ï¼šå‡å°‘æ— å…³ä¿¡æ¯ï¼Œæå‡æ•ˆç‡
```

**æ ¸å¿ƒæ€æƒ³**ï¼š
- ä¸æ˜¯æ‰€æœ‰æ£€ç´¢åˆ°çš„æ–‡æ¡£éƒ½éœ€è¦è¯»å–
- é€šè¿‡é‡æ’åºå¿«é€Ÿè¯†åˆ«é‡è¦æ–‡æ¡£
- è·³è¿‡ä½ç›¸å…³æ€§æ–‡æ¡£

### 10.4.2 å®ç°æ–¹æ³•

```python
# æ–‡ä»¶åï¼šskip_reading.py
"""
è·³è·ƒè¯»å–å®ç°
"""

from typing import List, Dict, Tuple


class SkipReadingRetriever:
    """
    è·³è·ƒè¯»å–æ£€ç´¢å™¨

    å…ˆå¿«é€Ÿç­›é€‰é‡è¦æ–‡æ¡£ï¼Œå†è¯¦ç»†è¯»å–

    Args:
        retriever: åŸºç¡€æ£€ç´¢å™¨
        reranker: é‡æ’åºå™¨
        skip_threshold: è·³è¿‡é˜ˆå€¼ï¼ˆç›¸å…³æ€§åˆ†æ•°ä½äºæ­¤å€¼åˆ™è·³è¿‡ï¼‰

    Example:
        >>> skip_reader = SkipReadingRetriever(retriever, reranker)
        >>> results = skip_reader.retrieve("Pythonæ€§èƒ½ä¼˜åŒ–")
        >>> åªè¯»å–é«˜ç›¸å…³æ€§æ–‡æ¡£
    """

    def __init__(self,
                 retriever,
                 reranker,
                 skip_threshold: float = 0.5):

        self.retriever = retriever
        self.reranker = reranker
        self.skip_threshold = skip_threshold

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_queries': 0,
            'total_retrieved': 0,
            'total_read': 0,
            'skip_rate': 0.0
        }

    def retrieve(self, query: str,
                initial_top_k: int = 50,
                final_top_k: int = 10) -> Dict:
        """
        è·³è·ƒè¯»å–æ£€ç´¢

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            initial_top_k: åˆå§‹æ£€ç´¢æ–‡æ¡£æ•°
            final_top_k: æœ€ç»ˆè¿”å›æ–‡æ¡£æ•°

        Returns:
            {
                'read_docs': List[dict],  # å®é™…è¯»å–çš„æ–‡æ¡£
                'skipped_docs': List[dict],  # è·³è¿‡çš„æ–‡æ¡£
                'skip_rate': float,
                'answer': str
            }
        """
        print(f"\n=== è·³è·ƒè¯»å–æ£€ç´¢ ===")
        print(f"æŸ¥è¯¢: {query}")

        # æ­¥éª¤1ï¼šåˆå§‹æ£€ç´¢ï¼ˆè·å–å€™é€‰ï¼‰
        print(f"\næ­¥éª¤1: åˆå§‹æ£€ç´¢Top-{initial_top_k}")
        initial_results = self.retriever.retrieve(query, top_k=initial_top_k)

        print(f"  æ£€ç´¢åˆ° {len(initial_results)} ä¸ªå€™é€‰æ–‡æ¡£")

        # æ­†éª¤2ï¼šå¿«é€Ÿé‡æ’åº
        print(f"\næ­¥éª¤2: å¿«é€Ÿé‡æ’åº")
        reranked = self.reranker.rerank(query, initial_results)

        # æ­¥éª¤3ï¼šé€‰æ‹©æ€§è¯»å–
        print(f"\næ­¥éª¤3: é€‰æ‹©æ€§è¯»å–ï¼ˆé˜ˆå€¼={self.skip_threshold}ï¼‰")
        read_docs = []
        skipped_docs = []

        for doc_id, score in reranked:
            doc = next((d for d in initial_results if d['id'] == doc_id), None)

            if score >= self.skip_threshold:
                # è¯»å–æ–‡æ¡£
                read_docs.append({
                    'id': doc_id,
                    'score': score,
                    'text': doc['text'] if doc else ''
                })
                print(f"  âœ“ è¯»å–: {doc_id} (åˆ†æ•°: {score:.4f})")
            else:
                # è·³è¿‡æ–‡æ¡£
                skipped_docs.append({
                    'id': doc_id,
                    'score': score,
                    'reason': 'ç›¸å…³æ€§åˆ†æ•°è¿‡ä½'
                })

        print(f"\n  è¯»å–: {len(read_docs)} ä¸ªæ–‡æ¡£")
        print(f"  è·³è¿‡: {len(skipped_docs)} ä¸ªæ–‡æ¡£")
        print(f"  è·³è·ƒç‡: {len(skipped_docs)/len(initial_results)*100:.1f}%")

        # æ­¥éª¤4ï¼šç”Ÿæˆç­”æ¡ˆ
        print(f"\næ­¥éª¤4: ç”Ÿæˆç­”æ¡ˆ")
        context = "\n\n".join([doc['text'] for doc in read_docs[:final_top_k]])

        answer = self._generate_answer(query, context)

        # æ›´æ–°ç»Ÿè®¡
        self._update_stats(
            total_retrieved=len(initial_results),
            total_read=len(read_docs)
        )

        return {
            'read_docs': read_docs,
            'skipped_docs': skipped_docs,
            'skip_rate': len(skipped_docs) / len(initial_results),
            'answer': answer
        }

    def _generate_answer(self, query: str, context: str) -> str:
        """
        ç”Ÿæˆç­”æ¡ˆï¼ˆå ä½ç¬¦ï¼‰
        """
        # å®é™…ä½¿ç”¨æ—¶è°ƒç”¨LLM
        return f"åŸºäº{len(context)}å­—çš„ç›¸å…³ä¿¡æ¯ç”Ÿæˆçš„ç­”æ¡ˆ..."

    def _update_stats(self, total_retrieved: int, total_read: int):
        """
        æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        """
        self.stats['total_queries'] += 1
        self.stats['total_retrieved'] += total_retrieved
        self.stats['total_read'] += total_read
        self.stats['skip_rate'] = (
            (self.stats['total_retrieved'] - self.stats['total_read']) /
            self.stats['total_retrieved']
        )

    def get_stats(self) -> Dict:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯
        """
        avg_skip_rate = self.stats['skip_rate']
        avg_retrieved = (
            self.stats['total_retrieved'] / self.stats['total_queries']
            if self.stats['total_queries'] > 0 else 0
        )
        avg_read = (
            self.stats['total_read'] / self.stats['total_queries']
            if self.stats['total_queries'] > 0 else 0
        )

        return {
            'total_queries': self.stats['total_queries'],
            'avg_retrieved_per_query': avg_retrieved,
            'avg_read_per_query': avg_read,
            'overall_skip_rate': avg_skip_rate
        }


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æ¨¡æ‹Ÿæ£€ç´¢å™¨
    class MockRetriever:
        def retrieve(self, query, top_k=50):
            results = []
            for i in range(top_k):
                relevance = 1.0 - (i * 0.02)  # æ¨¡æ‹Ÿé€’å‡çš„ç›¸å…³æ€§
                results.append({
                    'id': f'doc_{i}',
                    'text': f'æ–‡æ¡£{i}çš„ç›¸å…³å†…å®¹...'
                })
            return results

    # æ¨¡æ‹Ÿé‡æ’åºå™¨
    class MockReranker:
        def rerank(self, query, documents):
            # æ¨¡æ‹Ÿé‡æ’åºåˆ†æ•°
            reranked = []
            for i, doc in enumerate(documents):
                # å‰å‡ ä¸ªæ–‡æ¡£åˆ†æ•°é«˜ï¼Œåé¢çš„é€’å‡
                score = max(0, 1.0 - (i * 0.03))
                reranked.append((doc['id'], score))
            return reranked

    retriever = MockRetriever()
    reranker = MockReranker()

    # åˆ›å»ºè·³è·ƒè¯»å–æ£€ç´¢å™¨
    skip_reader = SkipReadingRetriever(
        retriever=retriever,
        reranker=reranker,
        skip_threshold=0.4
    )

    # æµ‹è¯•æŸ¥è¯¢
    query = "Pythonæ€§èƒ½ä¼˜åŒ–æŠ€å·§"
    result = skip_reader.retrieve(query, initial_top_k=50, final_top_k=10)

    print(f"\n{'='*80}")
    print("æœ€ç»ˆç­”æ¡ˆ")
    print(f"{'='*80}")
    print(result['answer'])

    print(f"\n{'='*80}")
    print("ç»Ÿè®¡ä¿¡æ¯")
    print(f"{'='*80}")

    stats = skip_reader.get_stats()
    print(f"æ€»æŸ¥è¯¢æ•°: {stats['total_queries']}")
    print(f"å¹³å‡æ£€ç´¢æ–‡æ¡£æ•°: {stats['avg_retrieved_per_query']:.1f}")
    print(f"å¹³å‡è¯»å–æ–‡æ¡£æ•°: {stats['avg_read_per_query']:.1f}")
    print(f"æ•´ä½“è·³è·ƒç‡: {stats['overall_skip_rate']*100:.1f}%")

    print(f"\næ•ˆç‡æå‡:")
    print(f"  å‡å°‘ {stats['avg_retrieved_per_query'] - stats['avg_read_per_query']:.1f} ä¸ªæ–‡æ¡£çš„è¯»å–")
    print(f"  èŠ‚çœ {(1 - stats['avg_read_per_query']/stats['avg_retrieved_per_query'])*100:.1f}% çš„è¯»å–æ—¶é—´")
```

---

## 10.5 å…ƒæ•°æ®è¿‡æ»¤

### 10.5.1 åŸç†

**ä»€ä¹ˆæ˜¯å…ƒæ•°æ®è¿‡æ»¤ï¼Ÿ**

```
ä¼ ç»Ÿæ£€ç´¢ï¼š
  Query â†’ å‘é‡ç›¸ä¼¼åº¦ â†’ æ£€ç´¢ç»“æœ
  é—®é¢˜ï¼šæ— æ³•æ§åˆ¶æ£€ç´¢ç»“æœçš„å±æ€§

å…ƒæ•°æ®è¿‡æ»¤ï¼š
  Query + è¿‡æ»¤æ¡ä»¶ â†’ å‘é‡æ£€ç´¢ + è¿‡æ»¤ â†’ æ£€ç´¢ç»“æœ
  ä¼˜åŠ¿ï¼šç²¾ç¡®æ§åˆ¶æ£€ç´¢èŒƒå›´
```

**å¸¸ç”¨å…ƒæ•°æ®**ï¼š

```python
metadata = {
    'author': 'Author Name',        # ä½œè€…
    'date': '2025-01-01',           # æ—¥æœŸ
    'category': 'Technology',       # åˆ†ç±»
    'tags': ['python', 'ml'],       # æ ‡ç­¾
    'difficulty': 'advanced',       # éš¾åº¦
    'language': 'zh-CN',            # è¯­è¨€
    'length': 5000,                 # é•¿åº¦
    'source': 'arxiv',              # æ¥æº
    'version': '2.0'                # ç‰ˆæœ¬
}
```

### 10.5.2 å®ç°æ–¹æ³•

```python
# æ–‡ä»¶åï¼šmetadata_filtering.py
"""
å…ƒæ•°æ®è¿‡æ»¤å®ç°
"""

from typing import List, Dict, Any
from datetime import datetime


class MetadataFilter:
    """
    å…ƒæ•°æ®è¿‡æ»¤å™¨

    æ”¯æŒå¤šç§è¿‡æ»¤æ¡ä»¶ç»„åˆ

    Example:
        >>> filter = MetadataFilter()
        >>> conditions = {
        ...     'category': 'Technology',
        ...     'date': {'>': '2024-01-01'},
        ...     'difficulty': ['advanced', 'intermediate']
        ... }
        >>> filtered = filter.apply(documents, conditions)
    """

    def __init__(self):
        pass

    def apply(self,
             documents: List[Dict],
             conditions: Dict) -> List[Dict]:
        """
        åº”ç”¨è¿‡æ»¤æ¡ä»¶

        Args:
            documents: æ–‡æ¡£åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡æ¡£åŒ…å«'metadata'å­—æ®µ
            conditions: è¿‡æ»¤æ¡ä»¶

        Returns:
            è¿‡æ»¤åçš„æ–‡æ¡£åˆ—è¡¨

        Example:
            >>> conditions = {
            ...     'author': 'å¼ ä¸‰',
            ...     'date': {'>': '2024-01-01', '<': '2024-12-31'},
            ...     'tags': {'in': ['python', 'ml']},
            ...     'difficulty': ['advanced', 'intermediate']
            ... }
            >>> filtered = filter.apply(docs, conditions)
        """
        filtered_docs = documents.copy()

        for key, value in conditions.items():
            if isinstance(value, dict):
                # æ¯”è¾ƒæ“ä½œ
                filtered_docs = self._apply_comparison(
                    filtered_docs, key, value
                )
            elif isinstance(value, list):
                # å¤šå€¼åŒ¹é…ï¼ˆORï¼‰
                filtered_docs = [
                    doc for doc in filtered_docs
                    if doc.get('metadata', {}).get(key) in value
                ]
            else:
                # ç²¾ç¡®åŒ¹é…
                filtered_docs = [
                    doc for doc in filtered_docs
                    if doc.get('metadata', {}).get(key) == value
                ]

        return filtered_docs

    def _apply_comparison(self,
                         documents: List[Dict],
                         key: str,
                         ops: Dict) -> List[Dict]:
        """
        åº”ç”¨æ¯”è¾ƒæ“ä½œ

        æ”¯æŒçš„æ“ä½œï¼š
        - '>', '>=', '<', '<=': æ•°å€¼/æ—¥æœŸæ¯”è¾ƒ
        - 'in', 'not_in': åŒ…å«/ä¸åŒ…å«
        - 'contains': å­—ç¬¦ä¸²åŒ…å«
        """
        filtered = []

        for doc in documents:
            metadata = doc.get('metadata', {})
            doc_value = metadata.get(key)

            # æ£€æŸ¥æ‰€æœ‰æ“ä½œ
            match = True
            for op, op_value in ops.items():
                if not self._compare(doc_value, op, op_value):
                    match = False
                    break

            if match:
                filtered.append(doc)

        return filtered

    def _compare(self, doc_value, op, op_value) -> bool:
        """
        æ‰§è¡Œå•ä¸ªæ¯”è¾ƒæ“ä½œ
        """
        try:
            if op == '>':
                return doc_value > op_value
            elif op == '>=':
                return doc_value >= op_value
            elif op == '<':
                return doc_value < op_value
            elif op == '<=':
                return doc_value <= op_value
            elif op == 'in':
                return doc_value in op_value
            elif op == 'not_in':
                return doc_value not in op_value
            elif op == 'contains':
                return op_value in str(doc_value)
            else:
                return False
        except:
            return False


class MetadataAwareRetriever:
    """
    æ”¯æŒå…ƒæ•°æ®è¿‡æ»¤çš„æ£€ç´¢å™¨

    ç»“åˆå‘é‡æ£€ç´¢å’Œå…ƒæ•°æ®è¿‡æ»¤
    """

    def __init__(self, vector_store, metadata_filter: MetadataFilter = None):
        self.vector_store = vector_store
        self.metadata_filter = metadata_filter or MetadataFilter()

    def retrieve(self,
                query: str,
                top_k: int = 10,
                filters: Dict = None) -> List[Dict]:
        """
        å¸¦å…ƒæ•°æ®è¿‡æ»¤çš„æ£€ç´¢

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°
            filters: å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶

        Returns:
            [(doc, score), ...]

        Example:
            >>> results = retriever.retrieve(
            ...     "Pythonæœºå™¨å­¦ä¹ ",
            ...     top_k=10,
            ...     filters={
            ...         'category': 'Technology',
            ...         'difficulty': ['advanced', 'intermediate'],
            ...         'date': {'>': '2024-01-01'}
            ...     }
            ... )
        """
        # æ­¥éª¤1ï¼šå‘é‡æ£€ç´¢ï¼ˆè·å–å€™é€‰ï¼‰
        candidates = self.vector_store.search(query, top_k=top_k * 3)

        # æ­¥éª¤2ï¼šå…ƒæ•°æ®è¿‡æ»¤
        if filters:
            print(f"åº”ç”¨å…ƒæ•°æ®è¿‡æ»¤: {filters}")
            filtered = self.metadata_filter.apply(candidates, filters)
            print(f"  è¿‡æ»¤å‰: {len(candidates)} ä¸ªæ–‡æ¡£")
            print(f"  è¿‡æ»¤å: {len(filtered)} ä¸ªæ–‡æ¡£")
        else:
            filtered = candidates

        # æ­¥éª¤3ï¼šè¿”å›Top-K
        return filtered[:top_k]


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹æ–‡æ¡£
    documents = [
        {
            'id': 'doc1',
            'text': 'Pythonæ€§èƒ½ä¼˜åŒ–æŠ€å·§...',
            'metadata': {
                'author': 'å¼ ä¸‰',
                'date': '2024-03-15',
                'category': 'Technology',
                'tags': ['python', 'performance'],
                'difficulty': 'intermediate',
                'language': 'zh-CN',
                'length': 3000
            }
        },
        {
            'id': 'doc2',
            'text': 'JavaScripté«˜çº§ç‰¹æ€§...',
            'metadata': {
                'author': 'æå››',
                'date': '2024-05-20',
                'category': 'Technology',
                'tags': ['javascript', 'advanced'],
                'difficulty': 'advanced',
                'language': 'zh-CN',
                'length': 5000
            }
        },
        {
            'id': 'doc3',
            'text': 'Pythonå…¥é—¨æ•™ç¨‹...',
            'metadata': {
                'author': 'ç‹äº”',
                'date': '2023-11-10',
                'category': 'Technology',
                'tags': ['python', 'beginner'],
                'difficulty': 'beginner',
                'language': 'zh-CN',
                'length': 2000
            }
        },
        {
            'id': 'doc4',
            'text': 'Machine Learning with Python...',
            'metadata': {
                'author': 'å¼ ä¸‰',
                'date': '2024-06-01',
                'category': 'Technology',
                'tags': ['python', 'ml', 'advanced'],
                'difficulty': 'advanced',
                'language': 'en',
                'length': 8000
            }
        }
    ]

    # åˆ›å»ºè¿‡æ»¤å™¨
    metadata_filter = MetadataFilter()

    # ç¤ºä¾‹1ï¼šç²¾ç¡®åŒ¹é…
    print("\n" + "="*80)
    print("ç¤ºä¾‹1: æŸ¥æ‰¾ä½œè€…ä¸º'å¼ ä¸‰'çš„æ–‡æ¡£")
    print("="*80)

    conditions1 = {'author': 'å¼ ä¸‰'}
    filtered1 = metadata_filter.apply(documents, conditions1)

    for doc in filtered1:
        print(f"  {doc['id']}: {doc['metadata']['author']} - {doc['text'][:30]}...")

    # ç¤ºä¾‹2ï¼šå¤šå€¼åŒ¹é…ï¼ˆORï¼‰
    print("\n" + "="*80)
    print("ç¤ºä¾‹2: æŸ¥æ‰¾éš¾åº¦ä¸º'intermediate'æˆ–'advanced'çš„æ–‡æ¡£")
    print("="*80)

    conditions2 = {'difficulty': ['intermediate', 'advanced']}
    filtered2 = metadata_filter.apply(documents, conditions2)

    for doc in filtered2:
        print(f"  {doc['id']}: {doc['metadata']['difficulty']} - {doc['text'][:30]}...")

    # ç¤ºä¾‹3ï¼šæ—¥æœŸèŒƒå›´
    print("\n" + "="*80)
    print("ç¤ºä¾‹3: æŸ¥æ‰¾2024å¹´1æœˆ1æ—¥ä¹‹åçš„æ–‡æ¡£")
    print("="*80)

    conditions3 = {'date': {'>': '2024-01-01'}}
    filtered3 = metadata_filter.apply(documents, conditions3)

    for doc in filtered3:
        print(f"  {doc['id']}: {doc['metadata']['date']} - {doc['text'][:30]}...")

    # ç¤ºä¾‹4ï¼šå¤æ‚æ¡ä»¶ç»„åˆ
    print("\n" + "="*80)
    print("ç¤ºä¾‹4: å¤æ‚æ¡ä»¶ç»„åˆ")
    print("  - åˆ†ç±»: Technology")
    print("  - æ ‡ç­¾åŒ…å«'python'")
    print("  - éš¾åº¦: intermediateæˆ–advanced")
    print("  - æ—¥æœŸ: 2024-01-01ä¹‹å")
    print("="*80)

    conditions4 = {
        'category': 'Technology',
        'tags': {'in': ['python']},
        'difficulty': ['intermediate', 'advanced'],
        'date': {'>': '2024-01-01'}
    }

    filtered4 = metadata_filter.apply(documents, conditions4)

    print(f"\næ‰¾åˆ° {len(filtered4)} ä¸ªç¬¦åˆæ¡ä»¶çš„æ–‡æ¡£:")
    for doc in filtered4:
        print(f"\n  {doc['id']}:")
        print(f"    ä½œè€…: {doc['metadata']['author']}")
        print(f"    æ—¥æœŸ: {doc['metadata']['date']}")
        print(f"    éš¾åº¦: {doc['metadata']['difficulty']}")
        print(f"    æ ‡ç­¾: {', '.join(doc['metadata']['tags'])}")
        print(f"    å†…å®¹: {doc['text'][:50]}...")
```

---

## 10.6 RAGæ¨¡å¼é€‰æ‹©æŒ‡å—

### 10.6.1 å†³ç­–æ ‘

```
æŸ¥è¯¢ç‰¹å¾åˆ†æ
       â”‚
       â”œâ”€ åŒ…å«ä¸“æœ‰åè¯ï¼Ÿ
       â”‚   â”œâ”€ æ˜¯ â†’ å…ƒæ•°æ®è¿‡æ»¤ + BM25æ£€ç´¢
       â”‚   â””â”€ å¦ â†“
       â”‚
       â”œâ”€ å¤šè·³æ¨ç†ï¼Ÿ
       â”‚   â”œâ”€ æ˜¯ â†’ è¿­ä»£æ£€ç´¢
       â”‚   â””â”€ å¦ â†“
       â”‚
       â”œâ”€ æŸ¥è¯¢å¤æ‚ï¼Ÿ
       â”‚   â”œâ”€ æ˜¯ â†’ è‡ªé€‚åº”æ£€ç´¢
       â”‚   â””â”€ å¦ â†“
       â”‚
       â””â”€ æ£€ç´¢ç»“æœå¤šï¼Ÿ
           â”œâ”€ æ˜¯ â†’ è·³è·ƒè¯»å–
           â””â”€ å¦ â†’ æ ‡å‡†æ£€ç´¢
```

### 10.6.2 æ€§èƒ½å¯¹æ¯”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RAGæ¨¡å¼æ€§èƒ½å¯¹æ¯”                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  æ¨¡å¼                Hit Rate    MRR    å“åº”æ—¶é—´    æˆæœ¬  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Naive RAG           0.60       0.50    1.0s       ä½    â”‚
â”‚  æ··åˆæ£€ç´¢            0.78       0.68    2.0s       ä¸­    â”‚
â”‚  æ··åˆ+é‡æ’åº          0.85       0.76    3.5s       é«˜    â”‚
â”‚  è¿­ä»£æ£€ç´¢            0.82       0.74    5.0s       é«˜    â”‚
â”‚  è‡ªé€‚åº”æ£€ç´¢          0.83       0.75    2.5s       ä¸­    â”‚
â”‚  è·³è·ƒè¯»å–            0.84       0.73    2.0s       ä¸­    â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ç»ƒä¹ é¢˜

### ç»ƒä¹ 1ï¼šåŸºç¡€ç»ƒä¹  - å®ç°è¿­ä»£æ£€ç´¢

**é¢˜ç›®**ï¼šå®ç°ä¸€ä¸ªç®€å•çš„è¿­ä»£æ£€ç´¢ç³»ç»Ÿ

**è¦æ±‚**ï¼š
1. æœ€å¤šè¿­ä»£3æ¬¡
2. æ¯è½®æ£€ç´¢Top-3æ–‡æ¡£
3. åŸºäºLLMåˆ¤æ–­æ˜¯å¦ç»§ç»­
4. æœ€ç»ˆç”Ÿæˆç»¼åˆç­”æ¡ˆ

**æç¤º**ï¼š
- ä½¿ç”¨_openai_ APIè°ƒç”¨LLM
- å¯ä»¥ä½¿ç”¨æ¨¡æ‹Ÿçš„æ£€ç´¢å™¨æµ‹è¯•

---

### ç»ƒä¹ 2ï¼šè¿›é˜¶ç»ƒä¹  - æ„å»ºè‡ªé€‚åº”æ£€ç´¢ç³»ç»Ÿ

**é¢˜ç›®**ï¼šå®ç°æŸ¥è¯¢å¤æ‚åº¦åˆ†æå™¨

**è¦æ±‚**ï¼š
1. æå–æŸ¥è¯¢ç‰¹å¾ï¼ˆé•¿åº¦ã€å®ä½“ã€é—®é¢˜è¯ç­‰ï¼‰
2. åŸºäºè§„åˆ™åˆ†ç±»ï¼ˆsimple/medium/complexï¼‰
3. æ ¹æ®åˆ†ç±»é€‰æ‹©æ£€ç´¢ç­–ç•¥
4. è¯„ä¼°åˆ†ç±»å‡†ç¡®ç‡

---

### ç»ƒä¹ 3ï¼šæŒ‘æˆ˜é¡¹ç›® - å®Œæ•´çš„é«˜çº§RAGç³»ç»Ÿ

**é¡¹ç›®æè¿°**ï¼šæ„å»ºä¸€ä¸ªé›†æˆå¤šç§é«˜çº§æ¨¡å¼çš„RAGç³»ç»Ÿ

**åŠŸèƒ½éœ€æ±‚**ï¼š
1. âœ… æŸ¥è¯¢å¤æ‚åº¦è‡ªåŠ¨åˆ†æ
2. âœ… è‡ªé€‚åº”é€‰æ‹©æ£€ç´¢ç­–ç•¥
3. âœ… æ”¯æŒè¿­ä»£æ£€ç´¢ï¼ˆå¤šè·³é—®é¢˜ï¼‰
4. âœ… å…ƒæ•°æ®è¿‡æ»¤
5. âœ… æ€§èƒ½ç›‘æ§å’Œæ—¥å¿—

**æ€§èƒ½è¦æ±‚**ï¼š
- ç®€å•æŸ¥è¯¢å“åº” < 2ç§’
- å¤æ‚æŸ¥è¯¢å“åº” < 10ç§’
- Hit Rate > 0.80

---

## æ€»ç»“

### æœ¬ç« è¦ç‚¹å›é¡¾

1. **è¿­ä»£æ£€ç´¢**
   - å¤šè½®æ£€ç´¢é€æ­¥æ”¶é›†ä¿¡æ¯
   - é€‚ç”¨äºå¤šè·³æ¨ç†é—®é¢˜
   - éœ€è¦"ä½•æ—¶åœæ­¢"çš„åˆ¤æ–­æœºåˆ¶

2. **è‡ªé€‚åº”æ£€ç´¢**
   - æ ¹æ®æŸ¥è¯¢å¤æ‚åº¦åŠ¨æ€é€‰æ‹©ç­–ç•¥
   - å¹³è¡¡é€Ÿåº¦å’Œè´¨é‡
   - èŠ‚çœè®¡ç®—èµ„æº

3. **è·³è·ƒè¯»å–**
   - æ™ºèƒ½ç­›é€‰é‡è¦æ–‡æ¡£
   - è·³è¿‡ä½ç›¸å…³æ€§æ–‡æ¡£
   - æå‡æ£€ç´¢æ•ˆç‡

4. **å…ƒæ•°æ®è¿‡æ»¤**
   - ç²¾ç¡®æ§åˆ¶æ£€ç´¢èŒƒå›´
   - æ”¯æŒå¤æ‚æ¡ä»¶ç»„åˆ
   - æå‡æ£€ç´¢ç²¾åº¦

5. **æ¨¡å¼é€‰æ‹©**
   - æ ¹æ®åœºæ™¯é€‰æ‹©åˆé€‚çš„RAGæ¨¡å¼
   - æƒè¡¡æ€§èƒ½ã€æˆæœ¬ã€æ•ˆæœ
   - å¯ä»¥ç»„åˆä½¿ç”¨å¤šç§æ¨¡å¼

### å­¦ä¹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£å„ç§é«˜çº§RAGæ¨¡å¼çš„åŸç†
- [ ] èƒ½å¤Ÿå®ç°è¿­ä»£æ£€ç´¢
- [ ] æŒæ¡è‡ªé€‚åº”æ£€ç´¢æ–¹æ³•
- [ ] èƒ½å¤Ÿåº”ç”¨å…ƒæ•°æ®è¿‡æ»¤
- [ ] ç†è§£è·³è·ƒè¯»å–çš„ä¼˜åŠ¿
- [ ] èƒ½å¤Ÿæ ¹æ®åœºæ™¯é€‰æ‹©åˆé€‚çš„RAGæ¨¡å¼

### ä¸‹ä¸€æ­¥å­¦ä¹ 

- **ä¸‹ä¸€ç« **ï¼š[ç¬¬11ç« ï¼šæ€§èƒ½ä¼˜åŒ–](./11-æ€§èƒ½ä¼˜åŒ–.md)
- **ç›¸å…³ç« èŠ‚**ï¼š
  - [ç¬¬8ç« ï¼šæŸ¥è¯¢å¢å¼ºæŠ€æœ¯](./08-æŸ¥è¯¢å¢å¼ºæŠ€æœ¯.md)
  - [ç¬¬9ç« ï¼šæ··åˆæ£€ç´¢ä¸é‡æ’åº](./09-æ··åˆæ£€ç´¢ä¸é‡æ’åº.md)
- **æ‰©å±•é˜…è¯»**ï¼š
  - LlamaIndex Advanced RAG: https://docs.llamaindex.ai/en/stable/examples/query_engine/knowledge_graph_rag_query_engine.html
  - LangChain Multi-hop: https://python.langchain.com/docs/use_cases/question_answering/

---

**è¿”å›ç›®å½•** | **ä¸Šä¸€ç« ** | **ä¸‹ä¸€ç« **

---

**æœ¬ç« ç»“æŸ**

> æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Ÿæ¬¢è¿æäº¤Issueæˆ–PRåˆ°æ•™ç¨‹ä»“åº“ï¼
