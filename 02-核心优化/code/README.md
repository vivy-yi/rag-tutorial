# InteliKB v2.0 ä»£ç ä»“åº“

> å®Œæ•´çš„RAGç³»ç»Ÿä¼˜åŒ–å®ç°ä»£ç 

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
RAGå®Œæ•´æ•™ç¨‹/
â”œâ”€â”€ 02-æ ¸å¿ƒä¼˜åŒ–/
â”‚   â”œâ”€â”€ code/                          # æ¨¡å—2å®Œæ•´ä»£ç 
â”‚   â”‚   â”œâ”€â”€ config.py                  # é…ç½®æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ models/                    # æ¨¡å‹ç›¸å…³
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ embedding.py          # åµŒå…¥æ¨¡å‹å°è£…
â”‚   â”‚   â”‚   â”œâ”€â”€ reranker.py           # é‡æ’åºæ¨¡å‹
â”‚   â”‚   â”‚   â””â”€â”€ llm.py                # LLMæ¥å£
â”‚   â”‚   â”œâ”€â”€ retrievers/                # æ£€ç´¢å™¨
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ vector.py             # å‘é‡æ£€ç´¢
â”‚   â”‚   â”‚   â”œâ”€â”€ bm25.py               # BM25æ£€ç´¢
â”‚   â”‚   â”‚   â””â”€â”€ hybrid.py             # æ··åˆæ£€ç´¢
â”‚   â”‚   â”œâ”€â”€ cache/                     # ç¼“å­˜ç³»ç»Ÿ
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ l1_cache.py           # L1å†…å­˜ç¼“å­˜
â”‚   â”‚   â”‚   â””â”€â”€ l2_cache.py           # L2 Redisç¼“å­˜
â”‚   â”‚   â”œâ”€â”€ optimization/              # ä¼˜åŒ–æŠ€æœ¯
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ query_enhancement.py  # æŸ¥è¯¢å¢å¼º
â”‚   â”‚   â”‚   â”œâ”€â”€ chunking.py           # åˆ†å—ç­–ç•¥
â”‚   â”‚   â”‚   â””â”€â”€ advanced_rag.py       # é«˜çº§RAGæ¨¡å¼
â”‚   â”‚   â”œâ”€â”€ engine/                    # RAGå¼•æ“
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ rag_engine.py         # ä¸»å¼•æ“
â”‚   â”‚   â”œâ”€â”€ evaluation/                # è¯„ä¼°å·¥å…·
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ metrics.py            # è¯„ä¼°æŒ‡æ ‡
â”‚   â”‚   â”‚   â””â”€â”€ ab_testing.py         # A/Bæµ‹è¯•
â”‚   â”‚   â”œâ”€â”€ api/                       # APIæœåŠ¡
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ app.py                # FastAPIåº”ç”¨
â”‚   â”‚   â”œâ”€â”€ monitoring/                # ç›‘æ§
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ metrics_collector.py  # æŒ‡æ ‡æ”¶é›†
â”‚   â”‚   â”œâ”€â”€ utils/                     # å·¥å…·å‡½æ•°
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ helpers.py            # è¾…åŠ©å‡½æ•°
â”‚   â”‚   â””â”€â”€ main.py                    # ä¸»ç¨‹åºå…¥å£
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒé…ç½®

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### requirements.txt

```
# æ ¸å¿ƒä¾èµ–
sentence-transformers==2.2.2
rank-bm25==0.2.2
chromadb==0.4.18
openai==1.3.5
numpy==1.24.3
pandas==2.0.3

# å¯é€‰ä¾èµ–
redis==4.6.0          # L2ç¼“å­˜
fastapi==0.104.1      # APIæœåŠ¡
uvicorn==0.24.0       # ASGIæœåŠ¡å™¨
prometheus-client==0.19.0  # ç›‘æ§

# å¼€å‘å·¥å…·
jupyter==1.0.0
pytest==7.4.3
black==23.12.0
```

---

## ğŸ“¦ æ ¸å¿ƒæ¨¡å—è¯´æ˜

### 1. config.py - é…ç½®ç®¡ç†

```python
"""
InteliKB v2.0 é…ç½®
"""

class Config:
    # åµŒå…¥æ¨¡å‹
    EMBEDDING_MODEL = "BAAI/bge-small-en-v1.5"
    EMBEDDING_DIM = 768
    EMBEDDING_BATCH_SIZE = 32

    # åˆ†å—
    CHUNK_SIZE = 512
    CHUNK_OVERLAP = 50
    CHUNKING_STRATEGY = "semantic"

    # æ£€ç´¢
    VECTOR_WEIGHT = 0.6
    BM25_WEIGHT = 0.4
    RRF_K = 60
    INITIAL_TOP_K = 50
    FINAL_TOP_K = 10

    # é‡æ’åº
    RERANKER_MODEL = "cross-encoder/ms-marco-MiniLM-L-6-v2"

    # ç¼“å­˜
    L1_CACHE_SIZE = 1000
    L1_CACHE_TTL = 3600
    L2_CACHE_TTL = 86400

    # LLM
    LLM_MODEL = "gpt-3.5-turbo"
    LLM_TEMPERATURE = 0.3
    LLM_MAX_TOKENS = 500

    # å¹¶å‘
    MAX_WORKERS = 10
    BATCH_SIZE = 8
```

### 2. engine/rag_engine.py - æ ¸å¿ƒå¼•æ“

```python
"""
InteliKB v2.0 RAGå¼•æ“
æ•´åˆæ‰€æœ‰ä¼˜åŒ–æŠ€æœ¯
"""

from ..config import Config
from ..models.embedding import EmbeddingModel
from ..retrievers.hybrid import HybridRetriever
from ..models.reranker import Reranker
from ..cache.l1_cache import L1Cache
from ..cache.l2_cache import L2Cache
from ..evaluation.metrics import compute_metrics


class IntelikBEngine:
    """InteliKB v2.0 å¼•æ“"""

    def __init__(self, config: Config):
        self.config = config

        # åˆå§‹åŒ–ç»„ä»¶
        self.embedding_model = EmbeddingModel(config.EMBEDDING_MODEL)
        self.retriever = HybridRetriever(config)
        self.reranker = Reranker(config.RERANKER_MODEL)
        self.l1_cache = L1Cache(config.L1_CACHE_SIZE, config.L1_CACHE_TTL)
        self.l2_cache = L2Cache(config.L2_CACHE_TTL)

    def add_documents(self, documents, metadata=None):
        """æ·»åŠ æ–‡æ¡£"""
        # åµŒå…¥æ–‡æ¡£
        embeddings = self.embedding_model.encode(documents)

        # æ·»åŠ åˆ°æ£€ç´¢å™¨
        self.retriever.add_documents(documents, embeddings, metadata)

    def query(self, query: str, use_cache: bool = True):
        """æŸ¥è¯¢"""
        # æ£€æŸ¥ç¼“å­˜
        if use_cache:
            cached = self._get_cached(query)
            if cached:
                return cached

        # æ£€ç´¢
        candidates = self.retriever.retrieve(query)

        # é‡æ’åº
        reranked = self.reranker.rerank(query, candidates)

        # ç”Ÿæˆç­”æ¡ˆ
        answer = self._generate_answer(query, reranked)

        # ç¼“å­˜ç»“æœ
        if use_cache:
            self._set_cached(query, answer)

        return answer

    def _get_cached(self, query: str):
        """è·å–ç¼“å­˜"""
        # L1
        result = self.l1_cache.get(query)
        if result:
            return result

        # L2
        result = self.l2_cache.get(query)
        if result:
            # å›å¡«L1
            self.l1_cache.set(query, result)
            return result

        return None

    def _set_cached(self, query: str, value: dict):
        """è®¾ç½®ç¼“å­˜"""
        self.l1_cache.set(query, value)
        self.l2_cache.set(query, value)
```

### 3. api/app.py - APIæœåŠ¡

```python
"""
FastAPIæœåŠ¡
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Optional
import uvicorn

from ..engine.rag_engine import IntelikBEngine
from ..config import Config


class QueryRequest(BaseModel):
    query: str
    use_cache: bool = True


class QueryResponse(BaseModel):
    answer: str
    sources: List[str]
    cache_hit: bool
    response_time_ms: float


app = FastAPI(title="InteliKB v2.0 API")

# åˆå§‹åŒ–å¼•æ“
config = Config()
engine = IntelikBEngine(config)


@app.post("/query", response_model=QueryResponse)
async def query(request: QueryRequest):
    """æŸ¥è¯¢æ¥å£"""
    import time
    start = time.time()

    try:
        result = engine.query(request.query, request.use_cache)
        response_time = (time.time() - start) * 1000

        return QueryResponse(
            answer=result['answer'],
            sources=result.get('sources', []),
            cache_hit=result.get('cache', 'None') != 'None',
            response_time_ms=response_time
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy"}


@app.get("/stats")
async def get_stats():
    """è·å–ç»Ÿè®¡ä¿¡æ¯"""
    return engine.get_stats()


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

---

## ğŸ§ª æµ‹è¯•

### è¿è¡Œæµ‹è¯•

```bash
# å•å…ƒæµ‹è¯•
pytest tests/ -v

# æ€§èƒ½æµ‹è¯•
python tests/performance_test.py

# A/Bæµ‹è¯•
python tests/ab_test.py
```

### æµ‹è¯•è¦†ç›–

- `tests/test_embedding.py` - åµŒå…¥æ¨¡å‹æµ‹è¯•
- `tests/test_retriever.py` - æ£€ç´¢å™¨æµ‹è¯•
- `tests/test_cache.py` - ç¼“å­˜æµ‹è¯•
- `tests/test_engine.py` - å¼•æ“é›†æˆæµ‹è¯•

---

## ğŸ“Š æ€§èƒ½åŸºå‡†

### é¢„æœŸæ€§èƒ½

| æŒ‡æ ‡ | v1.0 | v2.0 | æå‡ |
|------|------|------|------|
| Hit Rate | 0.60 | 0.85 | +42% |
| MRR | 0.50 | 0.75 | +50% |
| P95å»¶è¿Ÿ | 3000ms | 1500ms | -50% |
| QPS | 5 | 50 | +900% |

### è¿è¡ŒåŸºå‡†æµ‹è¯•

```bash
python scripts/run_benchmark.py
```

---

## ğŸ³ Dockeréƒ¨ç½²

### Dockerfile

```dockerfile
FROM python:3.9-slim

WORKDIR /app

# å®‰è£…ä¾èµ–
COPY requirements.txt .
RUN pip install -r requirements.txt --no-cache-dir

# å¤åˆ¶ä»£ç 
COPY . .

# æš´éœ²ç«¯å£
EXPOSE 8000

# è¿è¡ŒæœåŠ¡
CMD ["uvicorn", "api.app:app", "--host", "0.0.0.0", "--port", "8000"]
```

### docker-compose.yml

```yaml
version: '3.8'

services:
  rag-api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      - redis

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
```

### éƒ¨ç½²å‘½ä»¤

```bash
# æ„å»ºé•œåƒ
docker-compose build

# å¯åŠ¨æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f
```

---

## ğŸ“ˆ ç›‘æ§

### Prometheusé…ç½®

```python
from prometheus_client import Counter, Histogram, generate_latest

# å®šä¹‰æŒ‡æ ‡
query_counter = Counter('rag_queries_total', 'Total queries')
query_duration = Histogram('rag_query_duration_seconds', 'Query duration')

# ä½¿ç”¨
query_counter.inc()
with query_duration.time():
    result = engine.query(query)
```

### Grafana Dashboard

å¯¼å…¥ `monitoring/grafana_dashboard.json` è·å¾—é¢„é…ç½®çš„ä»ªè¡¨æ¿ã€‚

---

## ğŸ”§ å¼€å‘æŒ‡å—

### ä»£ç è§„èŒƒ

```bash
# æ ¼å¼åŒ–ä»£ç 
black .

# è¿è¡Œlinter
flake8 .

# ç±»å‹æ£€æŸ¥
mypy .
```

### æäº¤ä»£ç 

```bash
# è¿è¡Œæµ‹è¯•
pytest

# æ ¼å¼åŒ–
black .

# æäº¤
git add .
git commit -m "feat: add new feature"
```

---

## ğŸ“š æ–‡æ¡£

- APIæ–‡æ¡£ï¼šhttp://localhost:8000/docs
- æ•™ç¨‹ï¼š`../docs/`
- ç¤ºä¾‹ï¼š`examples/`

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Forkæœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ï¼š`git checkout -b feature/amazing-feature`
3. æäº¤æ›´æ”¹ï¼š`git commit -m 'feat: add amazing feature'`
4. æ¨é€åˆ†æ”¯ï¼š`git push origin feature/amazing-feature`
5. æäº¤Pull Request

---

## ğŸ“ è®¸å¯è¯

MIT License

---

## ğŸ™ è‡´è°¢

- LlamaIndexå›¢é˜Ÿ
- LangChainå›¢é˜Ÿ
- Sentence-Transformerså›¢é˜Ÿ
- æ‰€æœ‰è´¡çŒ®è€…

---

**æœ€åæ›´æ–°**ï¼š2025-02-10
**ç‰ˆæœ¬**ï¼šv2.0.0
