# ç¬¬12ç« ï¼šç»¼åˆé¡¹ç›®ä¼˜åŒ–

> ç†è®ºå­¦å®Œäº†ï¼Ÿé€šè¿‡ä¸€ä¸ªå®Œæ•´çš„InteliKB v2.0é¡¹ç›®ï¼Œå°†æ‰€æœ‰ä¼˜åŒ–æŠ€æœ¯æ•´åˆåº”ç”¨ï¼Œå®ç°ä»60%åˆ°85% Hit Rateçš„è·¨è¶Šï¼

---

## ğŸ“š å­¦ä¹ ç›®æ ‡

å­¦å®Œæœ¬ç« åï¼Œä½ å°†èƒ½å¤Ÿï¼š

- [ ] æ•´åˆåº”ç”¨æ‰€æœ‰ä¼˜åŒ–æŠ€æœ¯
- [ ] è®¾è®¡å®Œæ•´çš„ä¼˜åŒ–æ–¹æ¡ˆ
- [ ] è¿›è¡ŒA/Bæµ‹è¯•éªŒè¯æ•ˆæœ
- [ ] åˆ†ææ€§èƒ½ç“¶é¢ˆå¹¶è§£å†³
- [ ] å®ŒæˆInteliKB v2.0é¡¹ç›®
- [ ] è¾¾åˆ°æ€§èƒ½æå‡ç›®æ ‡

**é¢„è®¡å­¦ä¹ æ—¶é—´**ï¼š3å°æ—¶
**éš¾åº¦ç­‰çº§**ï¼šâ­â­â­â­â­

---

## å‰ç½®çŸ¥è¯†

åœ¨å¼€å§‹æœ¬ç« å­¦ä¹ å‰ï¼Œä½ éœ€è¦å®Œæˆï¼š

- [ ] æ¨¡å—1ï¼šåŸºç¡€RAGå®ç°
- [ ] æ¨¡å—2ç¬¬6-11ç« ï¼šæ‰€æœ‰ä¼˜åŒ–æŠ€æœ¯
- [ ] æœ‰ä¸€ä¸ªå¯è¿è¡Œçš„RAGç³»ç»Ÿ

**ç¯å¢ƒè¦æ±‚**ï¼š
- å®Œæ•´çš„RAGå¼€å‘ç¯å¢ƒ
- æµ‹è¯•æ•°æ®é›†
- è¯„ä¼°å·¥å…·

---

## 12.1 é¡¹ç›®æ¦‚è¿°

### 12.1.1 é¡¹ç›®ç›®æ ‡

**InteliKB v2.0ï¼šæ™ºèƒ½çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ**

å°†InteliKB-Liteï¼ˆæ¨¡å—1ï¼‰å‡çº§åˆ°v2.0ç‰ˆæœ¬ï¼Œåº”ç”¨æ‰€æœ‰ä¼˜åŒ–æŠ€æœ¯ã€‚

**æ€§èƒ½ç›®æ ‡**ï¼š

```
æŒ‡æ ‡                v1.0 (åŸºå‡†)    v2.0 (ç›®æ ‡)    æå‡
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Hit Rate           0.60          0.85          +42%
MRR                0.50          0.75          +50%
P95å»¶è¿Ÿ            3000ms        1500ms        -50%
ç”¨æˆ·æ»¡æ„åº¦         70%           90%           +29%
```

### 12.1.2 æŠ€æœ¯æ–¹æ¡ˆ

```
InteliKB v2.0 æŠ€æœ¯æ¶æ„

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     å‰ç«¯å±‚                              â”‚
â”‚  Streamlit Webç•Œé¢                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   APIå±‚                                 â”‚
â”‚  - æŸ¥è¯¢æ¥å£                                             â”‚
â”‚  - ç®¡ç†æ¥å£                                             â”‚
â”‚  - ç›‘æ§æ¥å£                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ä¸šåŠ¡å±‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  æŸ¥è¯¢å¤„ç†å™¨                                      â”‚   â”‚
â”‚  â”‚  - æŸ¥è¯¢å¤æ‚åº¦åˆ†æ                                â”‚   â”‚
â”‚  â”‚  - è‡ªé€‚åº”ç­–ç•¥é€‰æ‹©                                â”‚   â”‚
â”‚  â”‚  - ç¼“å­˜ç®¡ç†                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ä¼˜åŒ–å¼•æ“                                        â”‚   â”‚
â”‚  â”‚  - æ··åˆæ£€ç´¢ (å‘é‡+BM25)                          â”‚   â”‚
â”‚  â”‚  - RRFèåˆ                                       â”‚   â”‚
â”‚  â”‚  - é‡æ’åº (CrossEncoder)                         â”‚   â”‚
â”‚  â”‚  - è¿­ä»£æ£€ç´¢                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  æ•°æ®å±‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ å‘é‡æ•°æ®åº“   â”‚  â”‚ å…ƒæ•°æ®å­˜å‚¨   â”‚  â”‚ ç¼“å­˜ (Redis)â”‚  â”‚
â”‚  â”‚ Chroma       â”‚  â”‚ PostgreSQL   â”‚  â”‚ L1+L2       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 12.2 é¡¹ç›®è§„åˆ’

### 12.2.1 ä¼˜åŒ–è·¯çº¿å›¾

```
Phase 1: åŸºç¡€ä¼˜åŒ– (ç¬¬1-2å‘¨)
  âœ… æ›´å¥½çš„åµŒå…¥æ¨¡å‹
  âœ… è¯­ä¹‰åˆ†å—
  âœ… æŸ¥è¯¢å¢å¼º (HyDE)

  é¢„æœŸæå‡: Hit Rate 0.60 â†’ 0.70 (+17%)

Phase 2: æ£€ç´¢ä¼˜åŒ– (ç¬¬3-4å‘¨)
  âœ… æ··åˆæ£€ç´¢ (å‘é‡+BM25)
  âœ… RRFèåˆ
  âœ… é‡æ’åº

  é¢„æœŸæå‡: Hit Rate 0.70 â†’ 0.80 (+14%)

Phase 3: é«˜çº§æ¨¡å¼ (ç¬¬5-6å‘¨)
  âœ… è¿­ä»£æ£€ç´¢
  âœ… è‡ªé€‚åº”æ£€ç´¢
  âœ… å…ƒæ•°æ®è¿‡æ»¤

  é¢„æœŸæå‡: Hit Rate 0.80 â†’ 0.85 (+6%)

Phase 4: æ€§èƒ½ä¼˜åŒ– (ç¬¬7-8å‘¨)
  âœ… å¤šå±‚ç¼“å­˜
  âœ… æ‰¹å¤„ç†
  âœ… å¹¶å‘å¤„ç†

  é¢„æœŸæå‡: å»¶è¿Ÿ 3000ms â†’ 1500ms (-50%)

Phase 5: è¯„ä¼°ä¸è°ƒä¼˜ (ç¬¬9-10å‘¨)
  âœ… A/Bæµ‹è¯•
  âœ… æ€§èƒ½ç›‘æ§
  âœ… æŒç»­ä¼˜åŒ–

  é¢„æœŸ: è¾¾åˆ°æ‰€æœ‰ç›®æ ‡
```

### 12.2.2 æŠ€æœ¯é€‰å‹

```python
# æ–‡ä»¶åï¼šconfig.py
"""
InteliKB v2.0 é…ç½®
"""

class Config:
    """é…ç½®ç±»"""

    # ========== åµŒå…¥æ¨¡å‹ ==========
    # ä½¿ç”¨BGEæ¨¡å‹ï¼ˆæ€§èƒ½ä¼˜äºOpenAIï¼‰
    EMBEDDING_MODEL = "BAAI/bge-small-en-v1.5"
    EMBEDDING_DIM = 768
    EMBEDDING_BATCH_SIZE = 32

    # ========== åˆ†å—ç­–ç•¥ ==========
    # è¯­ä¹‰åˆ†å— + ä¸Šä¸‹æ–‡ä¿ç•™
    CHUNKING_STRATEGY = "semantic"
    CHUNK_SIZE = 512
    CHUNK_OVERLAP = 50
    KEEP_HEADERS = True

    # ========== æ£€ç´¢é…ç½® ==========
    # æ··åˆæ£€ç´¢æƒé‡
    VECTOR_WEIGHT = 0.6
    BM25_WEIGHT = 0.4

    # RRFå‚æ•°
    RRF_K = 60

    # æ£€ç´¢æ•°é‡
    INITIAL_TOP_K = 50
    FINAL_TOP_K = 10

    # ========== é‡æ’åº ==========
    RERANKER_MODEL = "cross-encoder/ms-marco-MiniLM-L-6-v2"
    RERANK_TOP_K = 10

    # ========== ç¼“å­˜é…ç½® ==========
    # L1ç¼“å­˜ï¼ˆå†…å­˜ï¼‰
    L1_CACHE_SIZE = 1000
    L1_CACHE_TTL = 3600

    # L2ç¼“å­˜ï¼ˆRedisï¼‰
    ENABLE_L2_CACHE = True
    L2_CACHE_TTL = 86400
    REDIS_HOST = "localhost"
    REDIS_PORT = 6379

    # ========== å¹¶å‘é…ç½® ==========
    MAX_WORKERS = 10
    BATCH_SIZE = 8

    # ========== é«˜çº§æ¨¡å¼ ==========
    ENABLE_ITERATIVE_RETRIEVAL = True
    MAX_ITERATIONS = 3
    ENABLE_ADAPTIVE_RETRIEVAL = True

    # ========== LLMé…ç½® ==========
    LLM_MODEL = "gpt-3.5-turbo"
    LLM_TEMPERATURE = 0.3
    LLM_MAX_TOKENS = 500
    LLM_TIMEOUT = 30

    # ========== ç›‘æ§é…ç½® ==========
    ENABLE_MONITORING = True
    LOG_LEVEL = "INFO"
    METRICS_PORT = 9090
```

---

## 12.3 æ ¸å¿ƒä»£ç å®ç°

### 12.3.1 ä¼˜åŒ–çš„RAGå¼•æ“

```python
# æ–‡ä»¶åï¼šintelikb_v2.py
"""
InteliKB v2.0 - ä¼˜åŒ–çš„RAGå¼•æ“
"""

from typing import List, Dict, Optional, Tuple
import time
import numpy as np
from sentence_transformers import SentenceTransformer, CrossEncoder
from rank_bm25 import BM25Okapi
import chromadb
from chromadb.config import Settings


class IntelikBEngine:
    """
    InteliKB v2.0 å¼•æ“

    æ•´åˆæ‰€æœ‰ä¼˜åŒ–æŠ€æœ¯

    Args:
        config: é…ç½®å¯¹è±¡

    Example:
        >>> engine = IntelikBEngine(Config())
        >>> engine.add_documents(documents)
        >>> result = engine.query("Pythonæ€§èƒ½ä¼˜åŒ–æŠ€å·§")
        >>> print(result['answer'])
    """

    def __init__(self, config):
        self.config = config

        # åˆå§‹åŒ–ç»„ä»¶
        self._init_embedding_model()
        self._init_vector_store()
        self._init_reranker()
        self._init_cache()
        self._init_bm25()

        # æ–‡æ¡£å­˜å‚¨
        self.documents = []
        self.doc_ids = []

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_queries': 0,
            'cache_hits': 0,
            'iterative_queries': 0,
            'avg_response_time_ms': 0.0
        }

    def _init_embedding_model(self):
        """åˆå§‹åŒ–åµŒå…¥æ¨¡å‹"""
        print(f"åŠ è½½åµŒå…¥æ¨¡å‹: {self.config.EMBEDDING_MODEL}")
        self.embedding_model = SentenceTransformer(self.config.EMBEDDING_MODEL)
        print("âœ“ åµŒå…¥æ¨¡å‹å·²åŠ è½½")

    def _init_vector_store(self):
        """åˆå§‹åŒ–å‘é‡æ•°æ®åº“"""
        print("åˆå§‹åŒ–å‘é‡æ•°æ®åº“...")
        self.chroma_client = chromadb.Client(Settings())
        self.collection = self.chroma_client.get_or_create_collection(
            name="intelikb_v2"
        )
        print("âœ“ å‘é‡æ•°æ®åº“å·²åˆå§‹åŒ–")

    def _init_reranker(self):
        """åˆå§‹åŒ–é‡æ’åºæ¨¡å‹"""
        print(f"åŠ è½½é‡æ’åºæ¨¡å‹: {self.config.RERANKER_MODEL}")
        self.reranker = CrossEncoder(self.config.RERANKER_MODEL)
        print("âœ“ é‡æ’åºæ¨¡å‹å·²åŠ è½½")

    def _init_cache(self):
        """åˆå§‹åŒ–ç¼“å­˜"""
        print("åˆå§‹åŒ–ç¼“å­˜...")
        from cache_strategies import MemoryCache

        self.l1_cache = MemoryCache(
            max_size=self.config.L1_CACHE_SIZE,
            ttl=self.config.L1_CACHE_TTL
        )

        if self.config.ENABLE_L2_CACHE:
            try:
                from cache_strategies import RedisCache
                self.l2_cache = RedisCache(
                    host=self.config.REDIS_HOST,
                    port=self.config.REDIS_PORT,
                    ttl=self.config.L2_CACHE_TTL
                )
                print("âœ“ L2ç¼“å­˜å·²å¯ç”¨")
            except Exception as e:
                print(f"âš  L2ç¼“å­˜åˆå§‹åŒ–å¤±è´¥: {e}")
                self.l2_cache = None
        else:
            self.l2_cache = None

        print("âœ“ L1ç¼“å­˜å·²åˆå§‹åŒ–")

    def _init_bm25(self):
        """åˆå§‹åŒ–BM25ç´¢å¼•"""
        self.bm25_index = None
        self.tokenized_docs = []

    def add_documents(self, documents: List[str],
                     doc_ids: List[str] = None,
                     metadata: List[Dict] = None):
        """
        æ·»åŠ æ–‡æ¡£

        Args:
            documents: æ–‡æ¡£æ–‡æœ¬åˆ—è¡¨
            doc_ids: æ–‡æ¡£IDåˆ—è¡¨
            metadata: å…ƒæ•°æ®åˆ—è¡¨
        """
        if doc_ids is None:
            doc_ids = [f"doc_{i}" for i in range(len(documents))]

        if metadata is None:
            metadata = [{}] * len(documents)

        self.documents = documents
        self.doc_ids = doc_ids

        print(f"\næ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£...")

        # æ­¥éª¤1ï¼šåµŒå…¥æ–‡æ¡£
        print("æ­¥éª¤1: åµŒå…¥æ–‡æ¡£...")
        embeddings = self.embedding_model.encode(
            documents,
            batch_size=self.config.EMBEDDING_BATCH_SIZE,
            show_progress_bar=True
        )

        # æ­¥éª¤2ï¼šå­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
        print("æ­¥éª¤2: å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“...")
        self.collection.add(
            embeddings=embeddings.tolist(),
            documents=documents,
            ids=doc_ids,
            metadatas=metadata
        )

        # æ­¥éª¤3ï¼šæ„å»ºBM25ç´¢å¼•
        print("æ­¥éª¤3: æ„å»ºBM25ç´¢å¼•...")
        self.tokenized_docs = [doc.split() for doc in documents]
        self.bm25_index = BM25Okapi(self.tokenized_docs)

        print(f"âœ“ å·²æ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£")

    def _vector_retrieve(self, query: str, top_k: int = 20) -> List[Tuple[str, float]]:
        """
        å‘é‡æ£€ç´¢
        """
        query_embedding = self.embedding_model.encode([query]).tolist()
        results = self.collection.query(
            query_embeddings=query_embedding,
            n_results=top_k
        )

        vector_results = []
        for i, doc_id in enumerate(results['ids'][0]):
            score = 1 - results['distances'][0][i]  # è·ç¦»è½¬ç›¸ä¼¼åº¦
            vector_results.append((doc_id, score))

        return vector_results

    def _bm25_retrieve(self, query: str, top_k: int = 20) -> List[Tuple[str, float]]:
        """
        BM25æ£€ç´¢
        """
        if self.bm25_index is None:
            return []

        tokenized_query = query.split()
        scores = self.bm25_index.get_scores(tokenized_query)
        top_indices = np.argsort(scores)[::-1][:top_k]

        bm25_results = []
        for idx in top_indices:
            if scores[idx] > 0:
                doc_id = self.doc_ids[idx]
                bm25_results.append((doc_id, scores[idx]))

        return bm25_results

    def _rrf_fusion(self,
                   vector_results: List[Tuple[str, float]],
                   bm25_results: List[Tuple[str, float]]) -> List[Tuple[str, float]]:
        """
        RRFèåˆ
        """
        k = self.config.RRF_K
        rrf_scores = {}

        # å‘é‡æ£€ç´¢ç»“æœ
        for rank, (doc_id, _) in enumerate(vector_results, start=1):
            rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + 1.0 / (k + rank)

        # BM25æ£€ç´¢ç»“æœ
        for rank, (doc_id, _) in enumerate(bm25_results, start=1):
            rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + 1.0 / (k + rank)

        # æ’åº
        fused = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)
        return fused

    def _rerank(self,
                query: str,
                candidates: List[Tuple[str, float]],
                top_k: int = None) -> List[Tuple[str, float]]:
        """
        é‡æ’åº
        """
        if top_k is None:
            top_k = self.config.RERANK_TOP_K

        # å‡†å¤‡å€™é€‰æ–‡æ¡£
        candidate_docs = []
        for doc_id, _ in candidates:
            doc_idx = self.doc_ids.index(doc_id)
            candidate_docs.append((doc_id, self.documents[doc_idx]))

        # å‡†å¤‡æŸ¥è¯¢-æ–‡æ¡£å¯¹
        pairs = [(query, doc_text) for _, doc_text in candidate_docs]

        # æ‰¹é‡æ‰“åˆ†
        scores = self.reranker.predict(pairs)

        # ç»„åˆç»“æœ
        reranked = [
            (doc_id, float(score))
            for (doc_id, _), score in zip(candidate_docs, scores)
        ]

        # æ’åºå¹¶è¿”å›top-k
        reranked.sort(key=lambda x: x[1], reverse=True)
        return reranked[:top_k]

    def _generate_answer(self, query: str, context_docs: List[Dict]) -> str:
        """
        ç”Ÿæˆç­”æ¡ˆï¼ˆå ä½ç¬¦ï¼‰
        """
        # å®é™…ä½¿ç”¨æ—¶è°ƒç”¨LLM
        context = "\n\n".join([doc['text'] for doc in context_docs[:3]])

        # ç®€åŒ–ç¤ºä¾‹
        return f"åŸºäº{len(context_docs)}ä¸ªç›¸å…³æ–‡æ¡£ç”Ÿæˆçš„ç­”æ¡ˆ...\n\nä¸Šä¸‹æ–‡:\n{context[:500]}..."

    def query(self, query: str, use_cache: bool = True) -> Dict:
        """
        æŸ¥è¯¢ï¼ˆå®Œæ•´æµç¨‹ï¼‰

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜

        Returns:
            {
                'answer': str,
                'sources': List[str],
                'cache': str,
                'response_time_ms': float
            }
        """
        start_time = time.time()
        self.stats['total_queries'] += 1

        # æ£€æŸ¥ç¼“å­˜
        if use_cache:
            cached = self.l1_cache.get(query)
            if cached is None and self.l2_cache:
                cached = self.l2_cache.get(query)

            if cached is not None:
                self.stats['cache_hits'] += 1
                response_time = (time.time() - start_time) * 1000
                return {
                    'answer': cached['answer'],
                    'sources': cached['sources'],
                    'cache': 'L1' if self.l1_cache.get(query) else 'L2',
                    'response_time_ms': response_time
                }

        # æ­¥éª¤1ï¼šå‘é‡æ£€ç´¢
        vector_results = self._vector_retrieve(
            query,
            top_k=self.config.INITIAL_TOP_K
        )

        # æ­¥éª¤2ï¼šBM25æ£€ç´¢
        bm25_results = self._bm25_retrieve(
            query,
            top_k=self.config.INITIAL_TOP_K
        )

        # æ­¥éª¤3ï¼šRRFèåˆ
        fused_results = self._rrf_fusion(vector_results, bm25_results)

        # æ­¥éª¤4ï¼šé‡æ’åº
        reranked = self._rerank(query, fused_results)

        # æ­¥éª¤5ï¼šç”Ÿæˆç­”æ¡ˆ
        context_docs = [
            {'id': doc_id, 'text': self.documents[self.doc_ids.index(doc_id)]}
            for doc_id, _ in reranked
        ]

        answer = self._generate_answer(query, context_docs)

        # å­˜å‚¨åˆ°ç¼“å­˜
        cache_data = {
            'answer': answer,
            'sources': [doc_id for doc_id, _ in reranked]
        }

        self.l1_cache.set(query, cache_data)
        if self.l2_cache:
            self.l2_cache.set(query, cache_data)

        response_time = (time.time() - start_time) * 1000

        # æ›´æ–°ç»Ÿè®¡
        self.stats['avg_response_time_ms'] = (
            (self.stats['avg_response_time_ms'] * (self.stats['total_queries'] - 1) + response_time)
            / self.stats['total_queries']
        )

        return {
            'answer': answer,
            'sources': [doc_id for doc_id, _ in reranked],
            'cache': 'None',
            'response_time_ms': response_time
        }

    def get_stats(self) -> Dict:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯
        """
        total = self.stats['total_queries']
        hits = self.stats['cache_hits']

        return {
            'total_queries': total,
            'cache_hits': hits,
            'cache_hit_rate': hits / total if total > 0 else 0,
            'avg_response_time_ms': self.stats['avg_response_time_ms'],
            'total_documents': len(self.documents)
        }


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    from config import Config

    # åˆ›å»ºå¼•æ“
    config = Config()
    engine = IntelikBEngine(config)

    # å‡†å¤‡æµ‹è¯•æ–‡æ¡£
    documents = [
        "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶ç®€æ´çš„è¯­æ³•å’Œå¼ºå¤§çš„åŠŸèƒ½è‘—ç§°ã€‚",
        "JavaScriptæ˜¯Webå¼€å‘çš„æ ‡é…è¯­è¨€ï¼Œä¸»è¦ç”¨äºå‰ç«¯å¼€å‘ã€‚",
        "Pythonæ€§èƒ½ä¼˜åŒ–å¯ä»¥é€šè¿‡ä½¿ç”¨PyPyã€Cythonæˆ–ä¼˜åŒ–ç®—æ³•å®ç°ã€‚",
        "JavaScriptçš„æ€§èƒ½ä¼˜åŒ–åŒ…æ‹¬å‡å°‘DOMæ“ä½œã€ä½¿ç”¨äº‹ä»¶å§”æ‰˜ç­‰æŠ€æœ¯ã€‚",
        "Pythonçš„GILé™åˆ¶äº†å¤šçº¿ç¨‹æ€§èƒ½ï¼Œä½†multiprocessingæ¨¡å—æä¾›äº†æ›¿ä»£æ–¹æ¡ˆã€‚",
        "V8å¼•æ“ä½¿å¾—JavaScriptæ‰§è¡Œé€Ÿåº¦å¤§å¹…æå‡ï¼Œæ¥è¿‘ç¼–è¯‘å‹è¯­è¨€ã€‚",
    ]

    # æ·»åŠ æ–‡æ¡£
    engine.add_documents(documents)

    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "å¦‚ä½•ä¼˜åŒ–Pythonä»£ç æ€§èƒ½ï¼Ÿ",
        "JavaScriptçš„V8å¼•æ“æ˜¯ä»€ä¹ˆï¼Ÿ",
        "å¯¹æ¯”Pythonå’ŒJavaScriptçš„æ€§èƒ½"
    ]

    print("\n" + "="*80)
    print("InteliKB v2.0 æµ‹è¯•")
    print("="*80 + "\n")

    for query in test_queries:
        print(f"æŸ¥è¯¢: {query}")
        result = engine.query(query)

        print(f"  ç¼“å­˜: {result['cache']}")
        print(f"  å“åº”æ—¶é—´: {result['response_time_ms']:.2f} ms")
        print(f"  æ¥æºæ–‡æ¡£: {', '.join(result['sources'])}")
        print(f"  ç­”æ¡ˆ:\n{result['answer'][:200]}...\n")

    # ç»Ÿè®¡ä¿¡æ¯
    stats = engine.get_stats()

    print("="*80)
    print("ç³»ç»Ÿç»Ÿè®¡")
    print("="*80)
    print(f"æ€»æŸ¥è¯¢æ•°: {stats['total_queries']}")
    print(f"ç¼“å­˜å‘½ä¸­: {stats['cache_hits']} ({stats['cache_hit_rate']*100:.1f}%)")
    print(f"å¹³å‡å“åº”æ—¶é—´: {stats['avg_response_time_ms']:.2f} ms")
    print(f"æ–‡æ¡£æ€»æ•°: {stats['total_documents']}")
```

---

## 12.4 A/Bæµ‹è¯•

### 12.4.1 æµ‹è¯•è®¾è®¡

```
A/Bæµ‹è¯•è®¾è®¡

ç›®æ ‡ï¼šéªŒè¯ä¼˜åŒ–æ•ˆæœ

åˆ†ç»„ï¼š
  - Aç»„ï¼ˆå¯¹ç…§ç»„ï¼‰ï¼šv1.0 åŸºç¡€RAG
  - Bç»„ï¼ˆå®éªŒç»„ï¼‰ï¼šv2.0 ä¼˜åŒ–RAG

æŒ‡æ ‡ï¼š
  - Hit Rate
  - MRR
  - å“åº”æ—¶é—´
  - ç”¨æˆ·æ»¡æ„åº¦

æµ‹è¯•æ•°æ®ï¼š
  - 100ä¸ªæµ‹è¯•æŸ¥è¯¢
  - æ¶µç›–ä¸åŒç±»å‹å’Œéš¾åº¦

æ˜¾è‘—æ€§æ£€éªŒï¼š
  - t-test
  - ç½®ä¿¡åŒºé—´95%
```

### 12.4.2 æµ‹è¯•å®ç°

```python
# æ–‡ä»¶åï¼šab_test.py
"""
A/Bæµ‹è¯•æ¡†æ¶
"""

from typing import List, Dict, Callable
import numpy as np
from scipy import stats


class ABTestFramework:
    """
    A/Bæµ‹è¯•æ¡†æ¶

    Args:
        system_a: å¯¹ç…§ç»„ç³»ç»Ÿ
        system_b: å®éªŒç»„ç³»ç»Ÿ
        test_queries: æµ‹è¯•æŸ¥è¯¢åˆ—è¡¨

    Example:
        >>> ab_test = ABTestFramework(system_v1, system_v2, test_queries)
        >>> results = ab_test.run_test()
        >>> ab_test.print_report(results)
    """

    def __init__(self,
                 system_a: Callable,
                 system_b: Callable,
                 test_queries: List[Dict]):

        self.system_a = system_a
        self.system_b = system_b
        self.test_queries = test_queries

    def run_test(self) -> Dict:
        """
        è¿è¡ŒA/Bæµ‹è¯•

        Returns:
            {
                'system_a': metrics,
                'system_b': metrics,
                'comparison': comparison_results,
                'significance': statistical_tests
            }
        """
        print("\n" + "="*80)
        print("è¿è¡ŒA/Bæµ‹è¯•")
        print("="*80 + "\n")

        # æµ‹è¯•ç³»ç»ŸA
        print("æµ‹è¯•ç³»ç»ŸAï¼ˆå¯¹ç…§ç»„ï¼‰...")
        results_a = self._test_system(self.system_a, "A")

        # æµ‹è¯•ç³»ç»ŸB
        print("\næµ‹è¯•ç³»ç»ŸBï¼ˆå®éªŒç»„ï¼‰...")
        results_b = self._test_system(self.system_b, "B")

        # å¯¹æ¯”åˆ†æ
        comparison = self._compare_systems(results_a, results_b)

        # æ˜¾è‘—æ€§æ£€éªŒ
        significance = self._statistical_tests(results_a, results_b)

        return {
            'system_a': results_a,
            'system_b': results_b,
            'comparison': comparison,
            'significance': significance
        }

    def _test_system(self, system: Callable, system_name: str) -> Dict:
        """
        æµ‹è¯•å•ä¸ªç³»ç»Ÿ
        """
        hit_rates = []
        mrrs = []
        response_times = []

        for item in self.test_queries:
            query = item['query']
            relevant_docs = item['relevant_docs']

            # æŸ¥è¯¢
            result = system(query)
            retrieved_docs = result.get('sources', [])

            # è®¡ç®—æŒ‡æ ‡
            hit_rate = 1.0 if any(doc in relevant_docs for doc in retrieved_docs) else 0.0
            hit_rates.append(hit_rate)

            # MRR
            mrr = self._calculate_mrr(retrieved_docs, relevant_docs)
            mrrs.append(mrr)

            # å“åº”æ—¶é—´
            response_time = result.get('response_time_ms', 0)
            response_times.append(response_time)

        return {
            'hit_rates': hit_rates,
            'mrrs': mrrs,
            'response_times': response_times,
            'avg_hit_rate': np.mean(hit_rates),
            'avg_mrr': np.mean(mrrs),
            'avg_response_time': np.mean(response_times)
        }

    def _calculate_mrr(self, retrieved: List[str], relevant: List[str]) -> float:
        """è®¡ç®—MRR"""
        for rank, doc in enumerate(retrieved, start=1):
            if doc in relevant:
                return 1.0 / rank
        return 0.0

    def _compare_systems(self, results_a: Dict, results_b: Dict) -> Dict:
        """
        å¯¹æ¯”ä¸¤ä¸ªç³»ç»Ÿ
        """
        comparison = {}

        # Hit Rateå¯¹æ¯”
        hit_rate_improvement = (
            (results_b['avg_hit_rate'] - results_a['avg_hit_rate'])
            / results_a['avg_hit_rate'] * 100
        )
        comparison['hit_rate_improvement_pct'] = hit_rate_improvement

        # MRRå¯¹æ¯”
        mrr_improvement = (
            (results_b['avg_mrr'] - results_a['avg_mrr'])
            / results_a['avg_mrr'] * 100
        )
        comparison['mrr_improvement_pct'] = mrr_improvement

        # å“åº”æ—¶é—´å¯¹æ¯”
        response_time_change = (
            (results_b['avg_response_time'] - results_a['avg_response_time'])
            / results_a['avg_response_time'] * 100
        )
        comparison['response_time_change_pct'] = response_time_change

        return comparison

    def _statistical_tests(self, results_a: Dict, results_b: Dict) -> Dict:
        """
        ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
        """
        significance = {}

        # Hit Rate t-test
        t_stat_hr, p_value_hr = stats.ttest_ind(
            results_a['hit_rates'],
            results_b['hit_rates']
        )
        significance['hit_rate'] = {
            't_statistic': t_stat_hr,
            'p_value': p_value_hr,
            'significant': p_value_hr < 0.05
        }

        # MRR t-test
        t_stat_mrr, p_value_mrr = stats.ttest_ind(
            results_a['mrrs'],
            results_b['mrrs']
        )
        significance['mrr'] = {
            't_statistic': t_stat_mrr,
            'p_value': p_value_mrr,
            'significant': p_value_mrr < 0.05
        }

        # å“åº”æ—¶é—´ t-test
        t_stat_rt, p_value_rt = stats.ttest_ind(
            results_a['response_times'],
            results_b['response_times']
        )
        significance['response_time'] = {
            't_statistic': t_stat_rt,
            'p_value': p_value_rt,
            'significant': p_value_rt < 0.05
        }

        return significance

    def print_report(self, test_results: Dict):
        """
        æ‰“å°æµ‹è¯•æŠ¥å‘Š
        """
        print("\n" + "="*80)
        print("A/Bæµ‹è¯•æŠ¥å‘Š")
        print("="*80 + "\n")

        # ç³»ç»ŸAç»“æœ
        results_a = test_results['system_a']
        print("ç³»ç»ŸAï¼ˆå¯¹ç…§ç»„ï¼‰:")
        print(f"  Hit Rate:   {results_a['avg_hit_rate']:.4f}")
        print(f"  MRR:        {results_a['avg_mrr']:.4f}")
        print(f"  å“åº”æ—¶é—´:   {results_a['avg_response_time']:.2f} ms\n")

        # ç³»ç»ŸBç»“æœ
        results_b = test_results['system_b']
        print("ç³»ç»ŸBï¼ˆå®éªŒç»„ï¼‰:")
        print(f"  Hit Rate:   {results_b['avg_hit_rate']:.4f}")
        print(f"  MRR:        {results_b['avg_mrr']:.4f}")
        print(f"  å“åº”æ—¶é—´:   {results_b['avg_response_time']:.2f} ms\n")

        # å¯¹æ¯”
        comparison = test_results['comparison']
        print("æ”¹è¿›æ•ˆæœ:")
        print(f"  Hit Rate:   {comparison['hit_rate_improvement_pct']:+.2f}%")
        print(f"  MRR:        {comparison['mrr_improvement_pct']:+.2f}%")
        print(f"  å“åº”æ—¶é—´:   {comparison['response_time_change_pct']:+.2f}%\n")

        # æ˜¾è‘—æ€§æ£€éªŒ
        significance = test_results['significance']
        print("ç»Ÿè®¡æ˜¾è‘—æ€§ (p < 0.05):")
        for metric, result in significance.items():
            sig_marker = "***" if result['significant'] else "ns"
            print(f"  {metric}:   p={result['p_value']:.4f} {sig_marker}")

        print("\n" + "="*80)


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # å‡†å¤‡æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        {
            'query': 'Pythonæ€§èƒ½ä¼˜åŒ–',
            'relevant_docs': ['doc_2', 'doc_4', 'doc_10']
        },
        {
            'query': 'JavaScript V8å¼•æ“',
            'relevant_docs': ['doc_6']
        },
        # ... æ›´å¤šæµ‹è¯•æŸ¥è¯¢
    ]

    # æ¨¡æ‹Ÿç³»ç»Ÿ
    def system_v1(query):
        """v1.0ç³»ç»Ÿ"""
        import random
        import time
        time.sleep(random.uniform(0.1, 0.3))  # æ¨¡æ‹Ÿå¤„ç†

        return {
            'sources': ['doc_1', 'doc_2', 'doc_3'],  # å‡è®¾ç»“æœ
            'response_time_ms': random.uniform(200, 300)
        }

    def system_v2(query):
        """v2.0ç³»ç»Ÿï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        import random
        import time
        time.sleep(random.uniform(0.05, 0.15))  # æ›´å¿«

        return {
            'sources': ['doc_2', 'doc_4', 'doc_10'],  # æ›´ç²¾ç¡®çš„ç»“æœ
            'response_time_ms': random.uniform(100, 150)
        }

    # è¿è¡ŒA/Bæµ‹è¯•
    ab_test = ABTestFramework(system_v1, system_v2, test_queries)
    results = ab_test.run_test()
    ab_test.print_report(results)
```

---

## 12.5 æ€§èƒ½ç›‘æ§

### 12.5.1 ç›‘æ§æŒ‡æ ‡

```python
# æ–‡ä»¶åï¼šmonitoring.py
"""
æ€§èƒ½ç›‘æ§ç³»ç»Ÿ
"""

from typing import Dict, List
import time
from collections import deque
import json


class PerformanceMonitor:
    """
    æ€§èƒ½ç›‘æ§å™¨

    è·Ÿè¸ªç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡

    Args:
        window_size: æ»‘åŠ¨çª—å£å¤§å°ï¼ˆç”¨äºè®¡ç®—ç§»åŠ¨å¹³å‡ï¼‰

    Example:
        >>> monitor = PerformanceMonitor(window_size=100)
        >>> monitor.log_query(query, result)
        >>> metrics = monitor.get_metrics()
    """

    def __init__(self, window_size: int = 100):
        self.window_size = window_size

        # æ»‘åŠ¨çª—å£
        self.response_times = deque(maxlen=window_size)
        self.cache_hits = deque(maxlen=window_size)
        self.query_types = deque(maxlen=window_size)

        # ç»Ÿè®¡
        self.total_queries = 0
        self.total_errors = 0

    def log_query(self, query: str, result: Dict):
        """
        è®°å½•æŸ¥è¯¢
        """
        self.total_queries += 1

        # å“åº”æ—¶é—´
        response_time = result.get('response_time_ms', 0)
        self.response_times.append(response_time)

        # ç¼“å­˜å‘½ä¸­
        cache_hit = 1 if result.get('cache') != 'None' else 0
        self.cache_hits.append(cache_hit)

        # æŸ¥è¯¢ç±»å‹ï¼ˆç®€å•åˆ†ç±»ï¼‰
        query_type = self._classify_query(query)
        self.query_types.append(query_type)

        # é”™è¯¯
        if 'error' in result:
            self.total_errors += 1

    def _classify_query(self, query: str) -> str:
        """
        åˆ†ç±»æŸ¥è¯¢ç±»å‹
        """
        if '?' in query or 'ï¼Ÿ' in query:
            return 'question'
        elif 'å¦‚ä½•' in query or 'æ€ä¹ˆ' in query:
            return 'how_to'
        elif 'å¯¹æ¯”' in query or 'åŒºåˆ«' in query:
            return 'comparison'
        else:
            return 'other'

    def get_metrics(self) -> Dict:
        """
        è·å–æŒ‡æ ‡
        """
        if len(self.response_times) == 0:
            return {}

        import numpy as np

        response_times_list = list(self.response_times)

        return {
            'total_queries': self.total_queries,
            'total_errors': self.total_errors,
            'error_rate': self.total_errors / self.total_queries if self.total_queries > 0 else 0,

            # å“åº”æ—¶é—´
            'avg_response_time_ms': np.mean(response_times_list),
            'p50_response_time_ms': np.percentile(response_times_list, 50),
            'p95_response_time_ms': np.percentile(response_times_list, 95),
            'p99_response_time_ms': np.percentile(response_times_list, 99),

            # ç¼“å­˜
            'cache_hit_rate': np.mean(list(self.cache_hits)),

            # QPS
            'qps': len(self.response_times) / max(response_times_list[-1] - response_times_list[0], 1) * 1000
        }

    def print_metrics(self):
        """
        æ‰“å°æŒ‡æ ‡
        """
        metrics = self.get_metrics()

        print("\n" + "="*80)
        print("æ€§èƒ½æŒ‡æ ‡")
        print("="*80)

        print(f"\næŸ¥è¯¢ç»Ÿè®¡:")
        print(f"  æ€»æŸ¥è¯¢æ•°:  {metrics['total_queries']}")
        print(f"  é”™è¯¯æ•°:    {metrics['total_errors']}")
        print(f"  é”™è¯¯ç‡:    {metrics['error_rate']*100:.2f}%")

        print(f"\nå“åº”æ—¶é—´:")
        print(f"  å¹³å‡:      {metrics['avg_response_time_ms']:.2f} ms")
        print(f"  P50:       {metrics['p50_response_time_ms']:.2f} ms")
        print(f"  P95:       {metrics['p95_response_time_ms']:.2f} ms")
        print(f"  P99:       {metrics['p99_response_time_ms']:.2f} ms")

        print(f"\nç¼“å­˜:")
        print(f"  å‘½ä¸­ç‡:    {metrics['cache_hit_rate']*100:.2f}%")

        print(f"\nååé‡:")
        print(f"  QPS:       {metrics['qps']:.2f}")

        print("\n" + "="*80)
```

---

## 12.6 æœ€ä½³å®è·µæ€»ç»“

### 12.6.1 ä¼˜åŒ–æ£€æŸ¥æ¸…å•

```
âœ… æ•°æ®å±‚ä¼˜åŒ–
  â˜‘ ä½¿ç”¨é«˜è´¨é‡çš„åµŒå…¥æ¨¡å‹
  â˜‘ åº”ç”¨è¯­ä¹‰åˆ†å—
  â˜‘ æ·»åŠ æ–‡æ¡£å…ƒæ•°æ®

âœ… æ£€ç´¢å±‚ä¼˜åŒ–
  â˜‘ å®ç°æ··åˆæ£€ç´¢ï¼ˆå‘é‡+BM25ï¼‰
  â˜‘ ä½¿ç”¨RRFèåˆç»“æœ
  â˜‘ åº”ç”¨é‡æ’åºç²¾ç‚¼

âœ… æŸ¥è¯¢å±‚ä¼˜åŒ–
  â˜‘ å®ç°æŸ¥è¯¢å¢å¼ºï¼ˆHyDEï¼‰
  â˜‘ æ”¯æŒè¿­ä»£æ£€ç´¢
  â˜‘ è‡ªé€‚åº”ç­–ç•¥é€‰æ‹©

âœ… æ€§èƒ½ä¼˜åŒ–
  â˜‘ å¤šå±‚ç¼“å­˜ï¼ˆL1+L2ï¼‰
  â˜‘ æ‰¹å¤„ç†æ¥å£
  â˜‘ å¹¶å‘å¤„ç†

âœ… ç›‘æ§ä¸è¯„ä¼°
  â˜‘ æ€§èƒ½ç›‘æ§
  â˜‘ A/Bæµ‹è¯•
  â˜‘ æŒç»­ä¼˜åŒ–
```

### 12.6.2 å¸¸è§é™·é˜±

```
âŒ é™·é˜±1ï¼šè¿‡åº¦ä¼˜åŒ–
  é—®é¢˜ï¼šä¼˜åŒ–äº†ä¸éœ€è¦ä¼˜åŒ–çš„éƒ¨åˆ†
  è§£å†³ï¼šå…ˆprofilingï¼Œæ‰¾åˆ°çœŸæ­£çš„ç“¶é¢ˆ

âŒ é™·é˜±2ï¼šå¿½ç•¥åŸºçº¿
  é—®é¢˜ï¼šä¸çŸ¥é“ä¼˜åŒ–æå‡äº†å¤šå°‘
  è§£å†³ï¼šå§‹ç»ˆå»ºç«‹è¯„ä¼°åŸºçº¿

âŒ é™·é˜±3ï¼šè¿‡æ—©ä¼˜åŒ–
  é—®é¢˜ï¼šåŠŸèƒ½æœªå®Œå–„å°±å¼€å§‹ä¼˜åŒ–
  è§£å†³ï¼šå…ˆç¡®ä¿æ­£ç¡®æ€§ï¼Œå†ä¼˜åŒ–æ€§èƒ½

âŒ é™·é˜±4ï¼šå•ä¸€æŒ‡æ ‡
  é—®é¢˜ï¼šåªå…³æ³¨Hit Rate
  è§£å†³ï¼šç»¼åˆè€ƒè™‘å¤šä¸ªæŒ‡æ ‡

âŒ é™·é˜±5ï¼šç¼ºä¹ç›‘æ§
  é—®é¢˜ï¼šä¸çŸ¥é“ç”Ÿäº§ç¯å¢ƒè¡¨ç°
  è§£å†³ï¼šå»ºç«‹å®Œå–„çš„ç›‘æ§ä½“ç³»
```

---

## ç»ƒä¹ é¢˜

### ç»ƒä¹ 1ï¼šç»¼åˆé¡¹ç›® - InteliKB v2.0

**é¡¹ç›®æè¿°**ï¼šå®Œæ•´å®ç°InteliKB v2.0

**åŠŸèƒ½éœ€æ±‚**ï¼š
1. âœ… æ··åˆæ£€ç´¢ï¼ˆå‘é‡+BM25+RRFï¼‰
2. âœ… é‡æ’åº
3. âœ… å¤šå±‚ç¼“å­˜
4. âœ… æ€§èƒ½ç›‘æ§
5. âœ… A/Bæµ‹è¯•

**æ€§èƒ½ç›®æ ‡**ï¼š
- Hit Rate > 0.80
- MRR > 0.70
- P95å»¶è¿Ÿ < 1000ms

**äº¤ä»˜æ ‡å‡†**ï¼š
- âœ… å®Œæ•´çš„ä»£ç å®ç°
- âœ… å•å…ƒæµ‹è¯•
- âœ… æ€§èƒ½æŠ¥å‘Š
- âœ… ä½¿ç”¨æ–‡æ¡£

---

### ç»ƒä¹ 2ï¼šè¿›é˜¶æŒ‘æˆ˜ - æŒç»­ä¼˜åŒ–

**æŒ‘æˆ˜æè¿°**ï¼šåœ¨è¾¾åˆ°ç›®æ ‡åæŒç»­ä¼˜åŒ–

**æŒ‘æˆ˜ç›®æ ‡**ï¼š
1. Hit Rateè¾¾åˆ°0.90+
2. å“åº”æ—¶é—´é™ä½åˆ°500msä»¥ä¸‹
3. å®ç°è‡ªåŠ¨åŒ–ä¼˜åŒ–æµç¨‹

**æç¤º**ï¼š
- å°è¯•ä¸åŒçš„åµŒå…¥æ¨¡å‹
- è°ƒä¼˜èåˆæƒé‡
- å®ç°æ¨¡å‹å¾®è°ƒ

---

### ç»ƒä¹ 3ï¼šå®æˆ˜é¡¹ç›® - ç”Ÿäº§éƒ¨ç½²

**é¡¹ç›®æè¿°**ï¼šå°†InteliKB v2.0éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ

**éœ€æ±‚**ï¼š
1. Dockerå®¹å™¨åŒ–
2. è´Ÿè½½å‡è¡¡
3. è‡ªåŠ¨æ‰©ç¼©å®¹
4. ç›‘æ§å‘Šè­¦
5. æ—¥å¿—æ”¶é›†

**æç¤º**ï¼š
- ä½¿ç”¨Docker Compose
- é…ç½®Nginxè´Ÿè½½å‡è¡¡
- é›†æˆPrometheusç›‘æ§

---

## æ€»ç»“

### æ¨¡å—2è¦ç‚¹å›é¡¾

**ç¬¬6ç« ï¼šåµŒå…¥æ¨¡å‹æ·±å…¥**
- ç†è§£Transformeræ¶æ„
- é€‰æ‹©åˆé€‚çš„åµŒå…¥æ¨¡å‹
- æ¨¡å‹å¾®è°ƒæå‡æ€§èƒ½

**ç¬¬7ç« ï¼šé«˜çº§åˆ†å—ç­–ç•¥**
- è¯­ä¹‰åˆ†å—ä¼˜äºå›ºå®šåˆ†å—
- ä¸Šä¸‹æ–‡åˆ†å—å¤´æå‡è´¨é‡
- çˆ¶æ–‡æ¡£æ£€ç´¢å¹³è¡¡ç²¾åº¦å’Œä¸Šä¸‹æ–‡

**ç¬¬8ç« ï¼šæŸ¥è¯¢å¢å¼ºæŠ€æœ¯**
- HyDEå°†æŸ¥è¯¢è½¬æ¢ä¸ºå‡è®¾ç­”æ¡ˆ
- æŸ¥è¯¢é‡å†™æå‡æ¸…æ™°åº¦
- å¤šæŸ¥è¯¢ç­–ç•¥è¦†ç›–æ›´å…¨é¢

**ç¬¬9ç« ï¼šæ··åˆæ£€ç´¢ä¸é‡æ’åº**
- å‘é‡+BM25äº’è¡¥ä¼˜åŠ¿
- RRFèåˆé²æ£’æ€§å¼º
- é‡æ’åºæ˜¾è‘—æå‡ç²¾åº¦

**ç¬¬10ç« ï¼šé«˜çº§RAGæ¨¡å¼**
- è¿­ä»£æ£€ç´¢å¤„ç†å¤šè·³é—®é¢˜
- è‡ªé€‚åº”æ£€ç´¢å¹³è¡¡é€Ÿåº¦å’Œè´¨é‡
- å…ƒæ•°æ®è¿‡æ»¤ç²¾ç¡®æ§åˆ¶èŒƒå›´

**ç¬¬11ç« ï¼šæ€§èƒ½ä¼˜åŒ–**
- ç¼“å­˜å‡å°‘é‡å¤è®¡ç®—
- æ‰¹å¤„ç†æå‡ååé‡
- å¹¶å‘å¤„ç†åŠ é€ŸI/Oæ“ä½œ

**ç¬¬12ç« ï¼šç»¼åˆé¡¹ç›®ä¼˜åŒ–**
- æ•´åˆæ‰€æœ‰ä¼˜åŒ–æŠ€æœ¯
- A/Bæµ‹è¯•éªŒè¯æ•ˆæœ
- æŒç»­ç›‘æ§å’Œä¼˜åŒ–

### å­¦ä¹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£æ‰€æœ‰ä¼˜åŒ–æŠ€æœ¯
- [ ] èƒ½å¤Ÿç‹¬ç«‹å®ç°ä¼˜åŒ–çš„RAGç³»ç»Ÿ
- [ ] æŒæ¡æ€§èƒ½åˆ†ææ–¹æ³•
- [ ] èƒ½å¤Ÿè¿›è¡ŒA/Bæµ‹è¯•
- [ ] å®ŒæˆInteliKB v2.0é¡¹ç›®
- [ ] è¾¾åˆ°æ€§èƒ½æå‡ç›®æ ‡

### ä¸‹ä¸€æ­¥å­¦ä¹ 

- **ä¸‹ä¸€æ¨¡å—**ï¼š[æ¨¡å—3ï¼šé«˜çº§æ¶æ„æ¨¡å¼](../03-é«˜çº§æ¶æ„/README.md)
- **ç›¸å…³é¡¹ç›®**ï¼š
  - éƒ¨ç½²InteliKBåˆ°ç”Ÿäº§ç¯å¢ƒ
  - æ„å»ºå¤šç§Ÿæˆ·RAGç³»ç»Ÿ
  - å®ç°RAG APIæœåŠ¡
- **æ‰©å±•é˜…è¯»**ï¼š
  - LlamaIndex Production: https://docs.llamaindex.ai/en/stable/
  - RAG in Production: https://arxiv.org/abs/2312.10997

---

## æ­å–œå®Œæˆæ¨¡å—2ï¼

ä½ å·²ç»æŒæ¡äº†RAGç³»ç»Ÿçš„æ‰€æœ‰æ ¸å¿ƒä¼˜åŒ–æŠ€æœ¯ï¼Œèƒ½å¤Ÿå°†æ£€ç´¢è´¨é‡æå‡40%ä»¥ä¸Šï¼Œå“åº”æ—¶é—´é™ä½50%ï¼

**ç»§ç»­ä¿æŒï¼Œè¿›å…¥æ¨¡å—3ï¼šé«˜çº§æ¶æ„æ¨¡å¼ï¼** ğŸš€

---

**è¿”å›ç›®å½•** | **ä¸Šä¸€ç« ** | **æ¨¡å—3**

---

**æ¨¡å—2å®Œæˆ** ğŸ‰

> æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Ÿæ¬¢è¿æäº¤Issueæˆ–PRåˆ°æ•™ç¨‹ä»“åº“ï¼
