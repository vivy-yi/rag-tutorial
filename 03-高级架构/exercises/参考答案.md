# æ¨¡å—3ç»ƒä¹ å‚è€ƒç­”æ¡ˆ

> è¯¦ç»†å®ç°æŒ‡å¯¼å’Œä»£ç ç¤ºä¾‹

---

## ğŸ“‹ ä½¿ç”¨è¯´æ˜

æœ¬æ–‡æ¡£æä¾›æ¨¡å—3ç»ƒä¹ é¢˜çš„å‚è€ƒç­”æ¡ˆå’Œå®ç°æŒ‡å¯¼ã€‚

**è¯„åˆ†æ ‡å‡†å‚è€ƒ**ï¼š
- â­â­â­â­â­ï¼šå®Œæ•´å®ç°+å¼‚å¸¸å¤„ç†+æµ‹è¯•+æ–‡æ¡£
- â­â­â­â­ï¼šå®Œæ•´å®ç°+åŸºæœ¬æ–‡æ¡£
- â­â­â­ï¼šåŸºæœ¬æ¡†æ¶

---

## ç¬¬13ç« ï¼šAgentic RAGç»ƒä¹ ç­”æ¡ˆ

### ç»ƒä¹ 13.1ï¼šå®ç°ReAct Agentï¼ˆåŸºç¡€ï¼‰

#### å‚è€ƒå®ç°

```python
"""
å®Œæ•´ReAct Agentå®ç°
"""

import re
import json
from typing import Dict, List, Tuple, Callable, Optional, Any
from dataclasses import dataclass


@dataclass
class Tool:
    """Agentå·¥å…·"""
    name: str
    description: str
    func: Callable

    def __call__(self, *args, **kwargs) -> str:
        try:
            result = self.func(*args, **kwargs)
            return str(result)
        except Exception as e:
            return f"Error: {str(e)}"


class ReActAgent:
    """
    ReAct Agentå®Œæ•´å®ç°

    æ”¯æŒåŠŸèƒ½ï¼š
    - Thought-Action-Observationå¾ªç¯
    - å·¥å…·è°ƒç”¨
    - é”™è¯¯å¤„ç†
    - æ‰§è¡Œè½¨è¿¹è®°å½•
    """

    def __init__(self,
                 tools: List[Tool],
                 llm_client: Any = None,
                 max_iterations: int = 5):
        """
        åˆå§‹åŒ–Agent

        Args:
            tools: å·¥å…·åˆ—è¡¨
            llm_client: LLMå®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼‰
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        """
        self.tools = {tool.name: tool for tool in tools}
        self.llm_client = llm_client
        self.max_iterations = max_iterations
        self.history = []  # æ‰§è¡Œå†å²

    def run(self, query: str, verbose: bool = True) -> Dict:
        """
        è¿è¡ŒAgent

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†è¿‡ç¨‹

        Returns:
            {
                'answer': str,
                'steps': List[Dict],
                'iterations': int,
                'success': bool
            }
        """
        steps = []
        thought = ""

        for iteration in range(self.max_iterations):
            step_num = len(steps) + 1
            step = {'step_num': step_num}

            # æ„å»ºæç¤º
            prompt = self._build_prompt(query, steps)

            # LLMç”Ÿæˆ
            if self.llm_client:
                response = self.llm_client.generate(prompt)
                thought, action, action_input = self._parse_response(response)
            else:
                # ä½¿ç”¨è§„åˆ™ï¼ˆæ¨¡æ‹Ÿï¼‰
                thought, action, action_input = self._simulate_thought(
                    query, steps, step_num
                )

            step['thought'] = thought
            step['action'] = f"{action}[{action_input}]"

            if verbose:
                print(f"\n--- æ­¥éª¤ {step_num} ---")
                print(f"ğŸ’­ Thought: {thought}")
                print(f"âš¡ Action: {action}[{action_input}]")

            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if action == "Finish":
                if verbose:
                    print(f"\nâœ… å®Œæˆ")
                return {
                    'answer': action_input,
                    'steps': steps,
                    'iterations': iteration + 1,
                    'success': True
                }

            # æ‰§è¡Œå·¥å…·
            tool = self.tools.get(action)
            if not tool:
                observation = f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°å·¥å…· '{action}'"
                step['error'] = True
            else:
                observation = tool(action_input)
                step['error'] = False

            step['observation'] = observation
            steps.append(step)

            if verbose:
                obs_preview = observation[:200] + "..." if len(observation) > 200 else observation
                print(f"ğŸ‘ï¸ Observation: {obs_preview}")

            # æ›´æ–°æ€è€ƒ
            thought = f"Observation: {observation}"

        # æœªå®Œæˆ
        return {
            'answer': "æœªèƒ½åœ¨é™åˆ¶æ­¥éª¤å†…å®Œæˆ",
            'steps': steps,
            'iterations': self.max_iterations,
            'success': False
        }

    def _build_prompt(self, query: str, steps: List[Dict]) -> str:
        """æ„å»ºæç¤ºè¯"""
        tool_desc = self._get_tool_descriptions()

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨å·¥å…·æ¥å›ç­”é—®é¢˜ã€‚

å¯ç”¨å·¥å…·:
{tool_desc}

ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š
Thought: ä½ çš„æ€è€ƒè¿‡ç¨‹
Action: å·¥å…·åç§°[è¾“å…¥]

å½“ä½ çŸ¥é“ç­”æ¡ˆæ—¶ï¼Œä½¿ç”¨ï¼š
Action: Finish[ç­”æ¡ˆ]

é—®é¢˜: {query}
"""

        # æ·»åŠ å†å²æ­¥éª¤
        for step in steps:
            if 'thought' in step:
                prompt += f"\nThought {step['step_num']}: {step['thought']}"
            if 'action' in step:
                prompt += f"\nAction {step['step_num']}: {step['action']}"
            if 'observation' in step:
                prompt += f"\nObservation {step['step_num']}: {step['observation']}"

        prompt += "\n\nThought:"
        return prompt

    def _parse_response(self, response: str) -> Tuple[str, str, str]:
        """è§£æLLMå“åº”"""
        # æå–Thought
        thought_match = re.search(r'Thought:\s*(.+?)(?=\nAction:|$)', response, re.DOTALL)
        thought = thought_match.group(1).strip() if thought_match else ""

        # æå–Action
        action_match = re.search(r'Action:\s*(\w+)\[(.*)\]', response)
        if action_match:
            action = action_match.group(1)
            action_input = action_match.group(2).strip()
        else:
            action = "Finish"
            action_input = response.strip()

        return thought, action, action_input

    def _simulate_thought(self, query: str, steps: List[Dict], step_num: int) -> Tuple[str, str, str]:
        """æ¨¡æ‹ŸLLMæ€è€ƒï¼ˆç”¨äºæ¼”ç¤ºï¼‰"""
        if "æœç´¢" in query or "æ€§èƒ½" in query or "æ¯”è¾ƒ" in query:
            if step_num == 1:
                return "æˆ‘éœ€è¦æœç´¢ç›¸å…³ä¿¡æ¯", "Search", query
            else:
                return "æˆ‘æœ‰è¶³å¤Ÿä¿¡æ¯äº†", "Finish", "åŸºäºæœç´¢ç»“æœï¼Œè¿™æ˜¯ç­”æ¡ˆ"
        elif "è®¡ç®—" in query or any(op in query for op in ['+', '-', '*', '/', '**']):
            return "è¿™æ˜¯ä¸€ä¸ªè®¡ç®—é—®é¢˜", "Calculator", query
        else:
            if step_num == 1:
                return "æˆ‘éœ€è¦æ£€ç´¢ç›¸å…³æ–‡æ¡£", "RAG", query
            else:
                return "æˆ‘å¯ä»¥å›ç­”äº†", "Finish", "åŸºäºæ£€ç´¢ç»“æœï¼Œè¿™æ˜¯ç­”æ¡ˆ"

    def _get_tool_descriptions(self) -> str:
        """è·å–å·¥å…·æè¿°"""
        descriptions = []
        for tool in self.tools.values():
            descriptions.append(f"- {tool.name}: {tool.description}")
        return "\n".join(descriptions)


# ç¤ºä¾‹å·¥å…·
def search_tool(query: str) -> str:
    """æœç´¢å·¥å…·"""
    knowledge = {
        "Python": "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œé€‚åˆæ•°æ®ç§‘å­¦å’Œæœºå™¨å­¦ä¹ ",
        "JavaScript": "JavaScriptæ˜¯Webå¼€å‘çš„ä¸»è¦è¯­è¨€"
    }
    for key, value in knowledge.items():
        if key in query:
            return value
    return f"æœªæ‰¾åˆ°å…³äº'{query}'çš„ä¿¡æ¯"


def calculator_tool(expression: str) -> str:
    """è®¡ç®—å™¨å·¥å…·"""
    try:
        result = eval(expression, {"__builtins__": {}}, {})
        return f"ç»“æœ: {result}"
    except:
        return f"æ— æ³•è®¡ç®—: {expression}"


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºå·¥å…·
    tools = [
        Tool("Search", "æœç´¢ä¿¡æ¯", search_tool),
        Tool("Calculator", "æ‰§è¡Œè®¡ç®—", calculator_tool)
    ]

    # åˆ›å»ºAgent
    agent = ReActAgent(tools, max_iterations=5)

    # è¿è¡ŒæŸ¥è¯¢
    result = agent.run("Pythonæ€§èƒ½å¦‚ä½•", verbose=True)

    print(f"\næœ€ç»ˆç­”æ¡ˆ: {result['answer']}")
    print(f"è¿­ä»£æ¬¡æ•°: {result['iterations']}")
    print(f"æ˜¯å¦æˆåŠŸ: {result['success']}")
```

#### è¯„åˆ†æ ‡å‡†

- â­â­â­â­â­ï¼š
  - å®Œæ•´å®ç°æ‰€æœ‰åŠŸèƒ½
  - å¼‚å¸¸å¤„ç†å®Œå–„
  - è¯¦ç»†çš„æ‰§è¡Œæ—¥å¿—
  - å•å…ƒæµ‹è¯•è¦†ç›–

- â­â­â­â­ï¼š
  - å®Œæ•´å®ç°æ ¸å¿ƒåŠŸèƒ½
  - åŸºæœ¬é”™è¯¯å¤„ç†
  - æ¸…æ™°çš„ä»£ç ç»“æ„

- â­â­â­ï¼š
  - å®ç°åŸºæœ¬æ¡†æ¶
  - èƒ½å¤Ÿè¿è¡Œç®€å•æŸ¥è¯¢

---

### ç»ƒä¹ 13.2ï¼šå·¥å…·å®šä¹‰ä¸ä½¿ç”¨ï¼ˆè¿›é˜¶ï¼‰

#### å‚è€ƒå®ç°ï¼šæŠ€æœ¯æ–‡æ¡£åŠ©æ‰‹å·¥å…·é›†

```python
"""
æŠ€æœ¯æ–‡æ¡£åŠ©æ‰‹å·¥å…·é›†
"""

import re
import requests
from typing import List, Dict


def code_search_tool(query: str) -> str:
    """ä»£ç æœç´¢å·¥å…·"""
    # æ¨¡æ‹Ÿæœç´¢ä»£ç ç¤ºä¾‹
    code_examples = {
        "Pythonå¼‚æ­¥": "import asyncio\n\nasync def fetch_data():\n    await asyncio.sleep(1)",
        "JavaScript Promise": "fetch('/api/data')\n  .then(response => response.json())",
        "RAGå®ç°": "vector_store.similarity_search(query, k=5)"
    }

    for key, code in code_examples.items():
        if query.lower() in key.lower() or key.lower() in query.lower():
            return f"æ‰¾åˆ°ä»£ç ç¤ºä¾‹:\n```\n{code}\n```"

    return "æœªæ‰¾åˆ°ç›¸å…³ä»£ç ç¤ºä¾‹"


def doc_search_tool(query: str) -> str:
    """æ–‡æ¡£æœç´¢å·¥å…·"""
    docs = {
        "RAG": "RAG (Retrieval-Augmented Generation) ç»“åˆæ£€ç´¢å’Œç”ŸæˆæŠ€æœ¯",
        "Transformer": "Transformeræ˜¯ä¸€ç§åŸºäºè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ç¥ç»ç½‘ç»œæ¶æ„",
        "çŸ¥è¯†å›¾è°±": "çŸ¥è¯†å›¾è°±æ˜¯ç”¨å›¾ç»“æ„è¡¨ç¤ºçŸ¥è¯†çš„ç½‘ç»œ"
    }

    for key, doc in docs.items():
        if key.lower() in query.lower():
            return f"{key}: {doc}"

    return "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£"


def api_search_tool(api_name: str) -> str:
    """APIå‚è€ƒæœç´¢"""
    api_refs = {
        "OpenAI": "OpenAI API: https://platform.openai.com/docs/api-reference",
        "LangChain": "LangChain Docs: https://python.langchain.com/",
        "LlamaIndex": "LlamaIndex: https://docs.llamaindex.ai/"
    }

    return api_refs.get(api_name, f"æœªæ‰¾åˆ°API: {api_name}")


def version_compare_tool(versions: str) -> str:
    """ç‰ˆæœ¬å¯¹æ¯”"""
    # è§£æè¾“å…¥: "version1, version2"
    try:
        v1, v2 = [v.strip() for v in versions.split(',')]
        comparison = f"{v1} vs {v2}:\n"
        comparison += f"- ä¸»è¦ç‰¹æ€§å¯¹æ¯”\n- æ€§èƒ½å·®å¼‚\n- å…¼å®¹æ€§è¯´æ˜"
        return comparison
    except:
        return "æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨: 'version1, version2'"


def concept_explain_tool(concept: str) -> str:
    """æ¦‚å¿µè§£é‡Š"""
    explanations = {
        "Attention": "æ³¨æ„åŠ›æœºåˆ¶å…è®¸æ¨¡å‹åœ¨å¤„ç†åºåˆ—æ—¶å…³æ³¨ä¸åŒéƒ¨åˆ†",
        "Embedding": "åµŒå…¥æ˜¯å°†ç¦»æ•£å¯¹è±¡æ˜ å°„åˆ°è¿ç»­å‘é‡ç©ºé—´çš„æŠ€æœ¯",
        "Fine-tuning": "å¾®è°ƒæ˜¯åœ¨é¢„è®­ç»ƒæ¨¡å‹åŸºç¡€ä¸Šè¿›è¡Œä»»åŠ¡ç‰¹å®šè®­ç»ƒçš„è¿‡ç¨‹"
    }

    return explanations.get(
        concept,
        f"å…³äº'{concept}'çš„è§£é‡Šæ­£åœ¨ç”Ÿæˆä¸­..."
    )


# åˆ›å»ºå·¥å…·é›†
tech_doc_tools = [
    Tool("CodeSearch", "æœç´¢ä»£ç ç¤ºä¾‹", code_search_tool),
    Tool("DocSearch", "æœç´¢æŠ€æœ¯æ–‡æ¡£", doc_search_tool),
    Tool("APISearch", "æœç´¢APIå‚è€ƒ", api_search_tool),
    Tool("VersionCompare", "å¯¹æ¯”ç‰ˆæœ¬å·®å¼‚", version_compare_tool),
    Tool("ConceptExplain", "è§£é‡ŠæŠ€æœ¯æ¦‚å¿µ", concept_explain_tool)
]

# ä½¿ç”¨
agent = ReActAgent(tech_doc_tools)
result = agent.run("è§£é‡ŠAttentionæœºåˆ¶å¹¶æä¾›ä»£ç ç¤ºä¾‹")
```

---

### ç»ƒä¹ 14.1ï¼šPlan-and-Executeå®ç°ï¼ˆè¿›é˜¶ï¼‰

#### å‚è€ƒå®ç°

```python
"""
Plan-and-Execute Agent
"""

from typing import List, Dict, Any


class PlanAndExecuteAgent:
    """
    Plan-and-Execute Agent

    ä¸¤é˜¶æ®µæ‰§è¡Œï¼š
    1. è§„åˆ’é˜¶æ®µï¼šç”Ÿæˆè¯¦ç»†æ‰§è¡Œè®¡åˆ’
    2. æ‰§è¡Œé˜¶æ®µï¼šé€æ­¥æ‰§è¡Œè®¡åˆ’
    """

    def __init__(self, tools: Dict[str, Callable], llm_client: Any = None):
        self.tools = tools
        self.llm_client = llm_client

    def run(self, query: str) -> Dict:
        """è¿è¡ŒPlan-and-Execute"""
        # é˜¶æ®µ1ï¼šè§„åˆ’
        plan = self._planning_phase(query)
        print("ğŸ“‹ ç”Ÿæˆçš„æ‰§è¡Œè®¡åˆ’:")
        for i, step in enumerate(plan, 1):
            print(f"  {i}. {step}")

        # é˜¶æ®µ2ï¼šæ‰§è¡Œ
        results = self._execution_phase(plan)

        return {
            'query': query,
            'plan': plan,
            'results': results
        }

    def _planning_phase(self, query: str) -> List[Dict]:
        """è§„åˆ’é˜¶æ®µï¼šç”Ÿæˆæ‰§è¡Œè®¡åˆ’"""
        # ä½¿ç”¨LLMç”Ÿæˆè®¡åˆ’
        if self.llm_client:
            prompt = f"""ä¸ºä»¥ä¸‹æŸ¥è¯¢ç”Ÿæˆè¯¦ç»†çš„æ‰§è¡Œè®¡åˆ’ï¼ˆ3-7æ­¥ï¼‰ï¼š
æŸ¥è¯¢: {query}

æ¯æ­¥åº”åŒ…æ‹¬ï¼š
- æè¿°
- éœ€è¦ä½¿ç”¨çš„å·¥å…·
- è¾“å…¥å‚æ•°

è¿”å›JSONæ ¼å¼çš„è®¡åˆ’åˆ—è¡¨ã€‚"""
            response = self.llm_client.generate(prompt)
            # è§£æLLMå“åº”
            plan = self._parse_plan(response)
        else:
            # ä½¿ç”¨è§„åˆ™ç”Ÿæˆè®¡åˆ’
            plan = self._rule_based_planning(query)

        return plan

    def _rule_based_planning(self, query: str) -> List[Dict]:
        """åŸºäºè§„åˆ™çš„è§„åˆ’"""
        plan = []

        if "æ¯”è¾ƒ" in query or "vs" in query.lower():
            plan = [
                {'step': 'æœç´¢ç¬¬ä¸€ä¸ªä¸»é¢˜çš„ä¿¡æ¯', 'tool': 'Search', 'input': query.split('æ¯”è¾ƒ')[0].strip()},
                {'step': 'æœç´¢ç¬¬äºŒä¸ªä¸»é¢˜çš„ä¿¡æ¯', 'tool': 'Search', 'input': query.split('æ¯”è¾ƒ')[-1].strip()},
                {'step': 'æ€»ç»“å¯¹æ¯”ç»“æœ', 'tool': 'Finish', 'input': 'ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š'}
            ]
        elif "å¦‚ä½•" in query or "æ€ä¹ˆ" in query:
            plan = [
                {'step': 'æœç´¢ç›¸å…³æ•™ç¨‹', 'tool': 'Search', 'input': query},
                {'step': 'æŸ¥æ‰¾ä»£ç ç¤ºä¾‹', 'tool': 'CodeSearch', 'input': query},
                {'step': 'ç”Ÿæˆè¯¦ç»†è§£ç­”', 'tool': 'Finish', 'input': 'æ•´åˆä¿¡æ¯å¹¶ç”Ÿæˆç­”æ¡ˆ'}
            ]
        else:
            plan = [
                {'step': 'æœç´¢ç›¸å…³ä¿¡æ¯', 'tool': 'Search', 'input': query},
                {'step': 'ç”Ÿæˆç­”æ¡ˆ', 'tool': 'Finish', 'input': 'åŸºäºæœç´¢ç»“æœå›ç­”'}
            ]

        return plan

    def _execution_phase(self, plan: List[Dict]) -> List[Dict]:
        """æ‰§è¡Œé˜¶æ®µï¼šé€æ­¥æ‰§è¡Œè®¡åˆ’"""
        results = []

        for i, step in enumerate(plan, 1):
            print(f"\nâš¡ æ‰§è¡Œæ­¥éª¤ {i}: {step['step']}")

            tool_name = step['tool']
            tool_input = step['input']

            if tool_name == 'Finish':
                result = {
                    'step': i,
                    'tool': tool_name,
                    'input': tool_input,
                    'output': tool_input,
                    'status': 'completed'
                }
            else:
                tool = self.tools.get(tool_name)
                if tool:
                    output = tool(tool_input)
                    result = {
                        'step': i,
                        'tool': tool_name,
                        'input': tool_input,
                        'output': output,
                        'status': 'completed'
                    }
                else:
                    result = {
                        'step': i,
                        'tool': tool_name,
                        'input': tool_input,
                        'output': f"å·¥å…· {tool_name} ä¸å­˜åœ¨",
                        'status': 'failed'
                    }

            results.append(result)
            print(f"âœ“ {result['output'][:100]}")

        return results

    def _parse_plan(self, llm_response: str) -> List[Dict]:
        """è§£æLLMç”Ÿæˆçš„è®¡åˆ’"""
        try:
            import json
            plan_data = json.loads(llm_response)
            return plan_data if isinstance(plan_data, list) else []
        except:
            return []


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    tools = {
        'Search': lambda q: f"æœç´¢'{q}'çš„ç»“æœ...",
        'CodeSearch': lambda q: f"ä»£ç ç¤ºä¾‹: {q}",
        'RAG': lambda q: f"æ£€ç´¢'{q}'ç›¸å…³æ–‡æ¡£"
    }

    agent = PlanAndExecuteAgent(tools)

    result = agent.run("æ¯”è¾ƒPythonå’ŒJavaScriptçš„æ€§èƒ½")
```

---

### ç»ƒä¹ 14.2ï¼šå¤šAgentåä½œç³»ç»Ÿï¼ˆæŒ‘æˆ˜ï¼‰

#### å‚è€ƒå®ç°

```python
"""
å¤šAgentåä½œç³»ç»Ÿ
"""

from abc import ABC, abstractmethod
from typing import Dict, List
import threading
import queue


class BaseAgent(ABC):
    """AgentåŸºç±»"""

    def __init__(self, name: str):
        self.name = name
        self.message_queue = queue.Queue()

    @abstractmethod
    def process(self, task: Dict) -> Dict:
        """å¤„ç†ä»»åŠ¡"""
        pass

    def send_message(self, recipient: 'BaseAgent', message: Dict):
        """å‘é€æ¶ˆæ¯ç»™å…¶ä»–Agent"""
        recipient.message_queue.put(message)


class ResearchAgent(BaseAgent):
    """ç ”ç©¶Agentï¼šè´Ÿè´£æ–‡çŒ®æœç´¢"""

    def process(self, task: Dict) -> Dict:
        query = task.get('query', '')

        # æ¨¡æ‹Ÿæ–‡çŒ®æœç´¢
        papers = [
            f"è®ºæ–‡1: å…³äº'{query}'çš„ç ”ç©¶",
            f"è®ºæ–‡2: '{query}'çš„æœ€æ–°è¿›å±•"
        ]

        return {
            'agent': self.name,
            'type': 'research',
            'papers': papers
        }


class AnalysisAgent(BaseAgent):
    """åˆ†æAgentï¼šè´Ÿè´£æ•°æ®åˆ†æ"""

    def process(self, task: Dict) -> Dict:
        data = task.get('data', [])

        # æ¨¡æ‹Ÿæ•°æ®åˆ†æ
        analysis = {
            'summary': f"åˆ†æäº†{len(data)}æ¡æ•°æ®",
            'insights': ['æ´å¯Ÿ1', 'æ´å¯Ÿ2', 'æ´å¯Ÿ3']
        }

        return {
            'agent': self.name,
            'type': 'analysis',
            'analysis': analysis
        }


class ReportAgent(BaseAgent):
    """æŠ¥å‘ŠAgentï¼šè´Ÿè´£ç”ŸæˆæŠ¥å‘Š"""

    def process(self, task: Dict) -> Dict:
        research = task.get('research', {})
        analysis = task.get('analysis', {})

        # ç”ŸæˆæŠ¥å‘Š
        report = f"""
ç ”ç©¶æ‘˜è¦
{'='*40}

æ–‡çŒ®ç ”ç©¶:
{chr(10).join(research.get('papers', []))}

æ•°æ®åˆ†æ:
{analysis.get('analysis', {}).get('summary', '')}

ä¸»è¦æ´å¯Ÿ:
{chr(10).join(analysis.get('analysis', {}).get('insights', []))}
        """

        return {
            'agent': self.name,
            'type': 'report',
            'content': report.strip()
        }


class ManagerAgent:
    """Manager Agentï¼šåè°ƒå…¶ä»–Agent"""

    def __init__(self):
        self.agents = {}
        self.register_agents()

    def register_agents(self):
        """æ³¨å†ŒAgent"""
        self.agents['research'] = ResearchAgent('ResearchAgent')
        self.agents['analysis'] = AnalysisAgent('AnalysisAgent')
        self.agents['report'] = ReportAgent('ReportAgent')

    def coordinate(self, query: str) -> Dict:
        """åè°ƒä»»åŠ¡æ‰§è¡Œ"""
        print(f"ğŸ¯ Managerå¼€å§‹åè°ƒä»»åŠ¡: {query}\n")

        # æ­¥éª¤1ï¼šç ”ç©¶
        print("ğŸ“š æ­¥éª¤1: æ–‡çŒ®ç ”ç©¶")
        research_task = {'query': query}
        research_result = self.agents['research'].process(research_task)
        print(f"âœ“ æ‰¾åˆ°{len(research_result['papers'])}ç¯‡è®ºæ–‡\n")

        # æ­¥éª¤2ï¼šåˆ†æ
        print("ğŸ“Š æ­¥éª¤2: æ•°æ®åˆ†æ")
        analysis_task = {'data': research_result['papers']}
        analysis_result = self.agents['analysis'].process(analysis_task)
        print(f"âœ“ å®Œæˆåˆ†æ\n")

        # æ­¥éª¤3ï¼šç”ŸæˆæŠ¥å‘Š
        print("ğŸ“ æ­¥éª¤3: ç”ŸæˆæŠ¥å‘Š")
        report_task = {
            'research': research_result,
            'analysis': analysis_result
        }
        report_result = self.agents['report'].process(report_task)
        print(f"âœ“ æŠ¥å‘Šç”Ÿæˆå®Œæˆ\n")

        return {
            'query': query,
            'report': report_result['content']
        }


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    manager = ManagerAgent()
    result = manager.coordinate("RAGæŠ€æœ¯çš„å‘å±•")

    print("\n" + "="*50)
    print("æœ€ç»ˆæŠ¥å‘Š:")
    print(result['report'])
```

---

## ç¬¬15ç« ï¼šçŸ¥è¯†å›¾è°±RAGç»ƒä¹ ç­”æ¡ˆ

### ç»ƒä¹ 15.1ï¼šæ„å»ºçŸ¥è¯†å›¾è°±ï¼ˆåŸºç¡€ï¼‰

#### å‚è€ƒå®ç°

```python
"""
æ„å»ºé¢†åŸŸçŸ¥è¯†å›¾è°±
"""

import networkx as nx
import matplotlib.pyplot as plt
from typing import List, Dict, Tuple


class KnowledgeGraphBuilder:
    """çŸ¥è¯†å›¾è°±æ„å»ºå™¨"""

    def __init__(self):
        self.graph = nx.MultiDiGraph()
        self.entities = {}
        self.relations = []

    def add_entity(self, entity_id: str, name: str,
                   entity_type: str, description: str = ""):
        """æ·»åŠ å®ä½“"""
        self.entities[entity_id] = {
            'id': entity_id,
            'name': name,
            'type': entity_type,
            'description': description
        }
        self.graph.add_node(entity_id, name=name, type=entity_type)

    def add_relation(self, source_id: str, target_id: str,
                    relation_type: str, weight: float = 1.0):
        """æ·»åŠ å…³ç³»"""
        if source_id not in self.entities:
            raise ValueError(f"æºå®ä½“ {source_id} ä¸å­˜åœ¨")
        if target_id not in self.entities:
            raise ValueError(f"ç›®æ ‡å®ä½“ {target_id} ä¸å­˜åœ¨")

        self.relations.append({
            'source': source_id,
            'target': target_id,
            'type': relation_type,
            'weight': weight
        })
        self.graph.add_edge(source_id, target_id,
                           relation_type=relation_type,
                           weight=weight)

    def visualize(self, figsize=(12, 8)):
        """å¯è§†åŒ–å›¾è°±"""
        plt.figure(figsize=figsize)

        pos = nx.spring_layout(self.graph, k=2, iterations=50, seed=42)

        # æŒ‰ç±»å‹ç€è‰²
        color_map = {
            'Person': '#FF6B6B',
            'Technology': '#4ECDC4',
            'Concept': '#45B7D1',
            'Organization': '#96CEB4'
        }

        node_colors = [color_map.get(
            self.entities[n]['type'],
            '#CCCCCC'
        ) for n in self.graph.nodes()]

        nx.draw(self.graph, pos,
               node_color=node_colors,
               with_labels=True,
               labels={n: self.entities[n]['name'] for n in self.graph.nodes()},
               node_size=1500,
               font_size=10,
               font_weight='bold',
               arrows=True,
               arrowsize=20)

        plt.title("çŸ¥è¯†å›¾è°±å¯è§†åŒ–")
        plt.show()

    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'entities': len(self.entities),
            'relations': len(self.relations),
            'density': nx.density(self.graph),
            'components': nx.number_weakly_connected_components(self.graph)
        }


# ç¤ºä¾‹ï¼šæ„å»ºç¼–ç¨‹è¯­è¨€çŸ¥è¯†å›¾è°±
if __name__ == "__main__":
    builder = KnowledgeGraphBuilder()

    # æ·»åŠ å®ä½“
    entities = [
        ('E1', 'Python', 'Technology', 'é«˜çº§ç¼–ç¨‹è¯­è¨€'),
        ('E2', 'JavaScript', 'Technology', 'Webå¼€å‘è¯­è¨€'),
        ('E3', 'Guido van Rossum', 'Person', 'Pythonåˆ›é€ è€…'),
        ('E4', 'Brendan Eich', 'Person', 'JavaScriptåˆ›é€ è€…'),
        ('E5', 'Data Science', 'Field', 'æ•°æ®ç§‘å­¦é¢†åŸŸ'),
        ('E6', 'Web Development', 'Field', 'Webå¼€å‘é¢†åŸŸ'),
    ]

    for eid, name, etype, desc in entities:
        builder.add_entity(eid, name, etype, desc)

    # æ·»åŠ å…³ç³»
    relations = [
        ('E3', 'E1', 'åˆ›é€ è€…'),
        ('E4', 'E2', 'åˆ›é€ è€…'),
        ('E1', 'E5', 'åº”ç”¨äº'),
        ('E2', 'E6', 'åº”ç”¨äº'),
        ('E1', 'E2', 'ç«äº‰è€…'),
    ]

    for source, target, rtype in relations:
        builder.add_relation(source, target, rtype)

    # å¯è§†åŒ–
    builder.visualize()

    # ç»Ÿè®¡
    print("å›¾è°±ç»Ÿè®¡:", builder.get_stats())
```

---

### ç»ƒä¹ 15.3ï¼šGraphRAGå®Œæ•´å®ç°ï¼ˆæŒ‘æˆ˜ï¼‰

#### æ ¸å¿ƒå®ç°

```python
"""
å®Œæ•´GraphRAGç³»ç»Ÿ
"""

class GraphRAGSystem:
    """
    GraphRAGç³»ç»Ÿ

    1. å®ä½“è¯†åˆ«
    2. å›¾è°±æ£€ç´¢
    3. å­å›¾åµŒå…¥
    4. ä¸å‘é‡æ£€ç´¢èåˆ
    5. ç”Ÿæˆç­”æ¡ˆ
    """

    def __init__(self, knowledge_graph, vector_store=None):
        self.kg = knowledge_graph
        self.vector_store = vector_store
        self.entity_extractor = EntityExtractor(knowledge_graph)

    def query(self, query: str, use_graph: bool = True,
             use_vector: bool = True, top_k: int = 5) -> Dict:
        """æŸ¥è¯¢"""
        results = {}

        # å›¾è°±æ£€ç´¢
        if use_graph:
            graph_results = self._graph_retrieve(query, top_k)
            results['graph'] = graph_results

        # å‘é‡æ£€ç´¢
        if use_vector and self.vector_store:
            vector_results = self._vector_retrieve(query, top_k)
            results['vector'] = vector_results

        # èåˆç»“æœ
        if use_graph and use_vector:
            fused_results = self._fuse_results(
                graph_results, vector_results, top_k
            )
            results['fused'] = fused_results

        # ç”Ÿæˆç­”æ¡ˆ
        answer = self._generate_answer(query, results)
        results['answer'] = answer

        return results

    def _graph_retrieve(self, query: str, top_k: int) -> Dict:
        """å›¾è°±æ£€ç´¢"""
        # è¯†åˆ«å®ä½“
        entities = self.entity_extractor.extract(query)

        # å¤šè·³æ£€ç´¢
        paths = []
        for entity_id in entities:
            paths.extend(self._multi_hop_search(entity_id, max_hops=2))

        # æ’åº
        ranked_paths = self._rank_paths(paths, query)

        return {
            'entities': entities,
            'paths': ranked_paths[:top_k]
        }

    def _vector_retrieve(self, query: str, top_k: int) -> Dict:
        """å‘é‡æ£€ç´¢"""
        # ä½¿ç”¨å‘é‡å­˜å‚¨æ£€ç´¢
        docs = self.vector_store.search(query, k=top_k)
        return {'documents': docs}

    def _fuse_results(self, graph_results: Dict,
                     vector_results: Dict, top_k: int) -> Dict:
        """èåˆå›¾è°±å’Œå‘é‡æ£€ç´¢ç»“æœ"""
        # RRFèåˆ
        fused_scores = {}

        # å›¾è°±å¾—åˆ†
        for i, path in enumerate(graph_results['paths']):
            doc_id = path[0]  # ä½¿ç”¨è·¯å¾„èµ·ç‚¹ä½œä¸ºID
            score = 1.0 / (60 + i + 1)
            fused_scores[doc_id] = fused_scores.get(doc_id, 0) + score

        # å‘é‡å¾—åˆ†
        for i, doc in enumerate(vector_results['documents']):
            doc_id = doc['id']
            score = 1.0 / (60 + i + 1)
            fused_scores[doc_id] = fused_scores.get(doc_id, 0) + score

        # æ’åº
        ranked = sorted(fused_scores.items(),
                       key=lambda x: x[1],
                       reverse=True)[:top_k]

        return {'ranked': ranked}

    def _multi_hop_search(self, start_entity: str,
                         max_hops: int = 2) -> List[List]:
        """å¤šè·³æœç´¢"""
        paths = []

        for target in self.kg.entities.keys():
            if target == start_entity:
                continue

            try:
                path = nx.shortest_path(
                    self.kg.graph,
                    start_entity,
                    target
                )

                if len(path) <= max_hops + 1:
                    paths.append(path)
            except nx.NetworkXNoPath:
                continue

        return paths

    def _rank_paths(self, paths: List[List], query: str) -> List:
        """å¯¹è·¯å¾„æ’åº"""
        scored = []

        for path in paths:
            score = 0.0

            # é•¿åº¦æƒ©ç½š
            score += 10.0 / len(path)

            # å®ä½“ç±»å‹æƒé‡
            for node_id in path:
                entity = self.kg.entities[node_id]
                if entity['type'] == 'Technology':
                    score += 2
                elif entity['type'] == 'Concept':
                    score += 1.5

            scored.append((path, score))

        scored.sort(key=lambda x: x[1], reverse=True)
        return [p[0] for p in scored]

    def _generate_answer(self, query: str, results: Dict) -> str:
        """ç”Ÿæˆç­”æ¡ˆ"""
        # è¿™é‡Œå¯ä»¥è°ƒç”¨LLMç”Ÿæˆæ›´ä¸°å¯Œçš„ç­”æ¡ˆ
        context = self._build_context(results)
        return f"åŸºäºæ£€ç´¢ç»“æœï¼Œå…³äº'{query}'çš„ç­”æ¡ˆæ˜¯ï¼š\n{context}"

    def _build_context(self, results: Dict) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡"""
        parts = []

        if 'graph' in results:
            parts.append("å›¾è°±æ£€ç´¢ç»“æœ:\n" +
                        str(results['graph'][:3]))

        if 'vector' in results:
            parts.append("å‘é‡æ£€ç´¢ç»“æœ:\n" +
                        str(results['vector'][:3]))

        return "\n\n".join(parts)
```

---

## ç¬¬16ç« ï¼šå¤šæ¨¡æ€RAGç»ƒä¹ ç­”æ¡ˆ

### ç»ƒä¹ 16.1ï¼šCLIPå›¾åƒæ£€ç´¢ï¼ˆåŸºç¡€ï¼‰

#### å‚è€ƒå®ç°

```python
"""
CLIPå›¾åƒæ£€ç´¢ç³»ç»Ÿ
"""

from sentence_transformers import SentenceTransformer, util
from PIL import Image
from typing import List, Dict, Tuple
import torch


class CLIPImageRetriever:
    """CLIPå›¾åƒæ£€ç´¢å™¨"""

    def __init__(self):
        print("åŠ è½½CLIPæ¨¡å‹...")
        self.model = SentenceTransformer('clip-ViT-B-32')
        self.image_embeddings = None
        self.image_paths = []

    def index_images(self, image_paths: List[str]):
        """ç´¢å¼•å›¾åƒ"""
        print(f"åµŒå…¥{len(image_paths)}å¼ å›¾åƒ...")
        self.image_paths = image_paths

        # æ‰¹é‡åµŒå…¥
        images = [Image.open(p) for p in image_paths]
        self.image_embeddings = self.model.encode(images)

        print("âœ… å›¾åƒç´¢å¼•å®Œæˆ")

    def retrieve_by_image(self, query_image_path: str,
                         top_k: int = 5) -> List[Dict]:
        """ç”¨å›¾åƒæ£€ç´¢ç›¸ä¼¼å›¾åƒ"""
        # åµŒå…¥æŸ¥è¯¢å›¾åƒ
        query_img = Image.open(query_image_path)
        query_emb = self.model.encode([query_img])

        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = util.cos_sim(
            query_emb,
            self.image_embeddings
        )[0]

        # Top-K
        top_k_indices = similarities.argsort(descending=True)[:top_k]

        results = []
        for idx in top_k_indices:
            results.append({
                'image_path': self.image_paths[idx],
                'similarity': float(similarities[idx])
            })

        return results

    def retrieve_by_text(self, query_text: str,
                        top_k: int = 5) -> List[Dict]:
        """ç”¨æ–‡æœ¬æ£€ç´¢å›¾åƒ"""
        # åµŒå…¥æŸ¥è¯¢æ–‡æœ¬
        query_emb = self.model.encode([query_text])

        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = util.cos_sim(
            query_emb,
            self.image_embeddings
        )[0]

        # Top-K
        top_k_indices = similarities.argsort(descending=True)[:top_k]

        results = []
        for idx in top_k_indices:
            results.append({
                'image_path': self.image_paths[idx],
                'similarity': float(similarities[idx])
            })

        return results


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    retriever = CLIPImageRetriever()

    # ç´¢å¼•å›¾åƒ
    image_paths = [
        "data/images/img1.jpg",
        "data/images/img2.jpg",
        # ... æ›´å¤šå›¾åƒ
    ]
    retriever.index_images(image_paths)

    # æ–‡æœ¬æ£€ç´¢
    results = retriever.retrieve_by_text("ä¸€åªçŒ«åœ¨æ²™å‘ä¸Š")

    for r in results:
        print(f"{r['image_path']}: {r['similarity']:.3f}")
```

---

### ç»ƒä¹ 16.2ï¼šå›¾æ–‡RAGå®ç°ï¼ˆè¿›é˜¶ï¼‰

#### æ ¸å¿ƒå®ç°

```python
"""
å›¾æ–‡æ··åˆRAGç³»ç»Ÿ
"""

class MultiModalRAG:
    """
    å¤šæ¨¡æ€RAGç³»ç»Ÿ

    æ”¯æŒå›¾åƒ+æ–‡æœ¬æ··åˆæ£€ç´¢å’Œç”Ÿæˆ
    """

    def __init__(self, image_db: List[str], text_db: List[str]):
        self.clip_model = SentenceTransformer('clip-ViT-B-32')

        # é¢„åµŒå…¥å›¾åƒ
        self.image_paths = image_db
        self.image_embeddings = self.clip_model.encode(
            [Image.open(p) for p in image_db]
        )

        # é¢„åµŒå…¥æ–‡æœ¬
        self.text_db = text_db
        self.text_embeddings = self.clip_model.encode(text_db)

    def retrieve_multimodal(self,
                          query_text: str,
                          query_image: str = None,
                          top_k: int = 10) -> List[Dict]:
        """å¤šæ¨¡æ€æ£€ç´¢"""
        results = []

        # æ–‡æœ¬æ£€ç´¢
        text_emb = self.clip_model.encode([query_text])
        text_sim = util.cos_sim(text_emb, self.text_embeddings)[0]

        for i, sim in enumerate(text_sim):
            results.append({
                'type': 'text',
                'content': self.text_db[i],
                'similarity': float(sim)
            })

        # å›¾åƒæ£€ç´¢ï¼ˆå¦‚æœæä¾›ï¼‰
        if query_image:
            query_img = Image.open(query_image)
            img_emb = self.clip_model.encode([query_img])
            img_sim = util.cos_sim(img_emb, self.image_embeddings)[0]

            for i, sim in enumerate(img_sim):
                results.append({
                    'type': 'image',
                    'content': self.image_paths[i],
                    'similarity': float(sim)
                })

        # æ’åºå¹¶è¿”å›Top-K
        results.sort(key=lambda x: x['similarity'], reverse=True)
        return results[:top_k]

    def fuse_results_rrf(self,
                        text_results: List[Dict],
                        image_results: List[Dict],
                        k: int = 60) -> List[Dict]:
        """ä½¿ç”¨RRFèåˆç»“æœ"""
        rrf_scores = {}

        # æ–‡æœ¬ç»“æœ
        for rank, item in enumerate(text_results, 1):
            doc_id = f"text_{item['content']}"
            score = 1.0 / (k + rank)
            rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + score

        # å›¾åƒç»“æœ
        for rank, item in enumerate(image_results, 1):
            doc_id = f"image_{item['content']}"
            score = 1.0 / (k + rank)
            rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + score

        # æ’åº
        ranked = sorted(rrf_scores.items(),
                       key=lambda x: x[1],
                       reverse=True)

        return ranked
```

---

## è¯„åˆ†æ ‡å‡†æ€»ç»“

### â­â­â­â­â­ (ä¼˜ç§€)

- å®Œæ•´å®ç°æ‰€æœ‰åŠŸèƒ½
- å¼‚å¸¸å¤„ç†å®Œå–„
- å•å…ƒæµ‹è¯•è¦†ç›– > 80%
- è¯¦ç»†çš„æ–‡æ¡£æ³¨é‡Š
- æ€§èƒ½ä¼˜åŒ–
- å¯æ‰©å±•çš„æ¶æ„

### â­â­â­â­ (è‰¯å¥½)

- å®Œæ•´å®ç°æ ¸å¿ƒåŠŸèƒ½
- åŸºæœ¬é”™è¯¯å¤„ç†
- æ¸…æ™°çš„ä»£ç ç»“æ„
- åŸºæœ¬æ–‡æ¡£
- å¯è¿è¡Œçš„ä»£ç 

### â­â­â­ (åŠæ ¼)

- å®ç°åŸºæœ¬æ¡†æ¶
- èƒ½å¤Ÿå®Œæˆä¸»è¦ä»»åŠ¡
- ä»£ç å¯è¿è¡Œ
- æœ€å°åŒ–æ–‡æ¡£

---

## ğŸ“š å­¦ä¹ èµ„æº

### æ¨èé˜…è¯»

- "ReAct: Synergizing Reasoning and Acting in Language Models"
- "GraphRAG: Boosting RAG with Knowledge Graphs"
- "Learning Transferable Visual Models From Natural Language Supervision"

### å‚è€ƒä»£ç 

- LangChain Agents: https://python.langchain.com/docs/modules/agents/
- LlamaIndex Graph RAG: https://docs.llamaindex.ai/en/stable/examples/query_engine/knowledge_graph_rag_query_engine.html
- Sentence-Transformers: https://www.sbert.net/

---

**ç¥ä½ å­¦ä¹ é¡ºåˆ©ï¼** ğŸš€

å¦‚æœ‰ç–‘é—®ï¼Œè¯·å‚è€ƒç›¸å…³ç« èŠ‚æˆ–æŸ¥é˜…å®˜æ–¹æ–‡æ¡£ã€‚
