{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬15ç« ï¼šçŸ¥è¯†å›¾è°±RAGå®è·µ\n",
    "\n",
    "> æ„å»ºåŸºäºçŸ¥è¯†å›¾è°±çš„å¢å¼ºæ£€ç´¢ç³»ç»Ÿï¼Œå®ç°å¤šè·³æ¨ç†å’Œç²¾å‡†é—®ç­”\n",
    "\n",
    "## ğŸ“š å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "æœ¬Notebookå°†å¸¦ä½ ï¼š\n",
    "- âœ… ç†è§£çŸ¥è¯†å›¾è°±çš„åŸºæœ¬æ¦‚å¿µ\n",
    "- âœ… ä»æ–‡æœ¬ä¸­æŠ½å–å®ä½“å’Œå…³ç³»\n",
    "- âœ… æ„å»ºå’Œéå†çŸ¥è¯†å›¾è°±\n",
    "- âœ… å®ç°GraphRAGå®Œæ•´æµç¨‹\n",
    "- âœ… è¿›è¡Œå¤šè·³æ¨ç†æŸ¥è¯¢\n",
    "\n",
    "## é¢„è®¡æ—¶é—´\n",
    "- å›¾è°±æ„å»ºï¼š40åˆ†é’Ÿ\n",
    "- GraphRAGå®ç°ï¼š50åˆ†é’Ÿ\n",
    "- å®éªŒä¸è¯„ä¼°ï¼š20åˆ†é’Ÿ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒå‡†å¤‡\n",
    "\n",
    "å¯¼å…¥å¿…è¦çš„åº“å¹¶è®¾ç½®ç¯å¢ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…ä¾èµ–\n",
    "!pip install networkx matplotlib sentence-transformers spacy -q\n",
    "# !python -m spacy download zh_core_web_sm  # ä¸­æ–‡NER\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, Set, Optional, Any\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import json\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒå‡†å¤‡å®Œæˆ\")\n",
    "print(f\"ğŸ“¦ NetworkXç‰ˆæœ¬: {nx.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. çŸ¥è¯†å›¾è°±åŸºç¡€\n",
    "\n",
    "### 2.1 ä»€ä¹ˆæ˜¯çŸ¥è¯†å›¾è°±ï¼Ÿ\n",
    "\n",
    "**çŸ¥è¯†å›¾è°±** = **å®ä½“**ï¼ˆEntityï¼‰+ **å…³ç³»**ï¼ˆRelationï¼‰\n",
    "\n",
    "```\n",
    "ç¤ºä¾‹ï¼šæŠ€æœ¯é¢†åŸŸçŸ¥è¯†å›¾è°±\n",
    "\n",
    "å®ä½“ï¼š\n",
    "  - Pythonï¼ˆç¼–ç¨‹è¯­è¨€ï¼‰\n",
    "  - JavaScriptï¼ˆç¼–ç¨‹è¯­è¨€ï¼‰\n",
    "  - Guido van Rossumï¼ˆäººç‰©ï¼‰\n",
    "  - Brendan Eichï¼ˆäººç‰©ï¼‰\n",
    "  - Data Scienceï¼ˆé¢†åŸŸï¼‰\n",
    "\n",
    "å…³ç³»ï¼š\n",
    "  - Guido van Rossum --[åˆ›é€ è€…]--> Python\n",
    "  - Brendan Eich --[åˆ›é€ è€…]--> JavaScript\n",
    "  - Python --[åº”ç”¨äº]--> Data Science\n",
    "  - Python --[ç«äº‰è€…]--> JavaScript\n",
    "```\n",
    "\n",
    "### 2.2 GraphRAGçš„ä¼˜åŠ¿\n",
    "\n",
    "**ä¼ ç»ŸRAG**ï¼š\n",
    "- åŸºäºå‘é‡ç›¸ä¼¼åº¦\n",
    "- æ— æ³•æ•è·ç»“æ„å…³ç³»\n",
    "- éš¾ä»¥å¤„ç†å¤šè·³æ¨ç†\n",
    "\n",
    "**GraphRAG**ï¼š\n",
    "- âœ… æ•è·å®ä½“é—´å…³ç³»\n",
    "- âœ… æ”¯æŒå¤šè·³æ¨ç†\n",
    "- âœ… æä¾›ç»“æ„åŒ–ä¸Šä¸‹æ–‡\n",
    "- âœ… è§£é‡Šæ¨ç†è·¯å¾„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. çŸ¥è¯†å›¾è°±æ•°æ®ç»“æ„\n",
    "\n",
    "### 3.1 å®šä¹‰å›¾è°±ç±»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Entity:\n",
    "    \"\"\"å®ä½“\"\"\"\n",
    "    id: str\n",
    "    name: str\n",
    "    type: str  # Person, Technology, Company, Conceptç­‰\n",
    "    description: str = \"\"\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.id)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, Entity):\n",
    "            return False\n",
    "        return self.id == other.id\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Relation:\n",
    "    \"\"\"å…³ç³»\"\"\"\n",
    "    source: str  # æºå®ä½“ID\n",
    "    target: str  # ç›®æ ‡å®ä½“ID\n",
    "    relation_type: str  # å…³ç³»ç±»å‹\n",
    "    weight: float = 1.0  # å…³ç³»æƒé‡\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash((self.source, self.target, self.relation_type))\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, Relation):\n",
    "            return False\n",
    "        return (self.source == other.source and \n",
    "                self.target == other.target and \n",
    "                self.relation_type == other.relation_type)\n",
    "\n",
    "\n",
    "class KnowledgeGraph:\n",
    "    \"\"\"çŸ¥è¯†å›¾è°±\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # ä½¿ç”¨NetworkXå­˜å‚¨å›¾è°±\n",
    "        self.graph = nx.MultiDiGraph()\n",
    "        \n",
    "        # å®ä½“å’Œå…³ç³»çš„ç´¢å¼•\n",
    "        self.entities: Dict[str, Entity] = {}\n",
    "        self.relations: List[Relation] = []\n",
    "    \n",
    "    def add_entity(self, entity: Entity):\n",
    "        \"\"\"æ·»åŠ å®ä½“\"\"\"\n",
    "        self.entities[entity.id] = entity\n",
    "        self.graph.add_node(\n",
    "            entity.id,\n",
    "            name=entity.name,\n",
    "            type=entity.type,\n",
    "            description=entity.description\n",
    "        )\n",
    "    \n",
    "    def add_relation(self, relation: Relation):\n",
    "        \"\"\"æ·»åŠ å…³ç³»\"\"\"\n",
    "        if relation.source not in self.entities:\n",
    "            raise ValueError(f\"æºå®ä½“ {relation.source} ä¸å­˜åœ¨\")\n",
    "        if relation.target not in self.entities:\n",
    "            raise ValueError(f\"ç›®æ ‡å®ä½“ {relation.target} ä¸å­˜åœ¨\")\n",
    "        \n",
    "        self.relations.append(relation)\n",
    "        self.graph.add_edge(\n",
    "            relation.source,\n",
    "            relation.target,\n",
    "            relation_type=relation.relation_type,\n",
    "            weight=relation.weight\n",
    "        )\n",
    "    \n",
    "    def get_entity(self, entity_id: str) -> Optional[Entity]:\n",
    "        \"\"\"è·å–å®ä½“\"\"\"\n",
    "        return self.entities.get(entity_id)\n",
    "    \n",
    "    def get_neighbors(self, entity_id: str, \n",
    "                      relation_type: str = None) -> List[Entity]:\n",
    "        \"\"\"è·å–é‚»å±…å®ä½“\"\"\"\n",
    "        if entity_id not in self.graph:\n",
    "            return []\n",
    "        \n",
    "        neighbors = []\n",
    "        for neighbor in self.graph.neighbors(entity_id):\n",
    "            # æ£€æŸ¥å…³ç³»ç±»å‹\n",
    "            if relation_type:\n",
    "                edge_data = self.graph.get_edge_data(entity_id, neighbor)\n",
    "                if edge_data and edge_data.get('relation_type') == relation_type:\n",
    "                    neighbors.append(self.entities[neighbor])\n",
    "            else:\n",
    "                neighbors.append(self.entities[neighbor])\n",
    "        \n",
    "        return neighbors\n",
    "    \n",
    "    def find_path(self, source_id: str, target_id: str) -> List[str]:\n",
    "        \"\"\"æŸ¥æ‰¾ä¸¤ä¸ªå®ä½“é—´çš„æœ€çŸ­è·¯å¾„\"\"\"\n",
    "        try:\n",
    "            path = nx.shortest_path(self.graph, source_id, target_id)\n",
    "            return path\n",
    "        except nx.NetworkXNoPath:\n",
    "            return []\n",
    "    \n",
    "    def get_subgraph(self, entity_ids: List[str], \n",
    "                     hops: int = 1) -> 'KnowledgeGraph':\n",
    "        \"\"\"æå–å­å›¾\n",
    "        \n",
    "        Args:\n",
    "            entity_ids: ä¸­å¿ƒå®ä½“IDåˆ—è¡¨\n",
    "            hops: è·³æ•°\n",
    "        \n",
    "        Returns:\n",
    "            å­å›¾\n",
    "        \"\"\"\n",
    "        subgraph = KnowledgeGraph()\n",
    "        \n",
    "        # æ”¶é›†æ‰€æœ‰ç›¸å…³èŠ‚ç‚¹\n",
    "        nodes_to_include = set(entity_ids)\n",
    "        \n",
    "        for hop in range(hops):\n",
    "            new_nodes = set()\n",
    "            for node_id in nodes_to_include:\n",
    "                if node_id in self.graph:\n",
    "                    new_nodes.update(self.graph.neighbors(node_id))\n",
    "            nodes_to_include.update(new_nodes)\n",
    "        \n",
    "        # å¤åˆ¶èŠ‚ç‚¹å’Œè¾¹\n",
    "        for node_id in nodes_to_include:\n",
    "            if node_id in self.entities:\n",
    "                subgraph.add_entity(self.entities[node_id])\n",
    "        \n",
    "        for relation in self.relations:\n",
    "            if (relation.source in nodes_to_include and \n",
    "                relation.target in nodes_to_include):\n",
    "                subgraph.add_relation(relation)\n",
    "        \n",
    "        return subgraph\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"è·å–å›¾è°±ç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
    "        return {\n",
    "            'å®ä½“æ•°': len(self.entities),\n",
    "            'å…³ç³»æ•°': len(self.relations),\n",
    "            'èŠ‚ç‚¹æ•°': self.graph.number_of_nodes(),\n",
    "            'è¾¹æ•°': self.graph.number_of_edges(),\n",
    "            'å¯†åº¦': nx.density(self.graph),\n",
    "            'è¿é€šåˆ†é‡': nx.number_weakly_connected_components(self.graph)\n",
    "        }\n",
    "\n",
    "print(\"âœ… çŸ¥è¯†å›¾è°±ç±»å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 æ„å»ºç¤ºä¾‹çŸ¥è¯†å›¾è°±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºæŠ€æœ¯é¢†åŸŸçŸ¥è¯†å›¾è°±\n",
    "kg = KnowledgeGraph()\n",
    "\n",
    "# æ·»åŠ å®ä½“\n",
    "entities_data = [\n",
    "    Entity(\"E1\", \"Python\", \"Technology\", \"ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€\"),\n",
    "    Entity(\"E2\", \"JavaScript\", \"Technology\", \"Webå¼€å‘è„šæœ¬è¯­è¨€\"),\n",
    "    Entity(\"E3\", \"Java\", \"Technology\", \"é€šç”¨ç¼–ç¨‹è¯­è¨€\"),\n",
    "    Entity(\"E4\", \"Guido van Rossum\", \"Person\", \"Pythonåˆ›é€ è€…\"),\n",
    "    Entity(\"E5\", \"Brendan Eich\", \"Person\", \"JavaScriptåˆ›é€ è€…\"),\n",
    "    Entity(\"E6\", \"James Gosling\", \"Person\", \"Javaåˆ›é€ è€…\"),\n",
    "    Entity(\"E7\", \"Data Science\", \"Field\", \"æ•°æ®ç§‘å­¦\"),\n",
    "    Entity(\"E8\", \"Web Development\", \"Field\", \"Webå¼€å‘\"),\n",
    "    Entity(\"E9\", \"Machine Learning\", \"Field\", \"æœºå™¨å­¦ä¹ \"),\n",
    "    Entity(\"E10\", \"Backend\", \"Field\", \"åç«¯å¼€å‘\"),\n",
    "    Entity(\"E11\", \"RAG\", \"Concept\", \"æ£€ç´¢å¢å¼ºç”Ÿæˆ\"),\n",
    "    Entity(\"E12\", \"Vector DB\", \"Concept\", \"å‘é‡æ•°æ®åº“\"),\n",
    "    Entity(\"E13\", \"LLM\", \"Concept\", \"å¤§è¯­è¨€æ¨¡å‹\"),\n",
    "    Entity(\"E14\", \"Transformer\", \"Concept\", \"Transformeræ¶æ„\"),\n",
    "    Entity(\"E15\", \"Attention\", \"Concept\", \"æ³¨æ„åŠ›æœºåˆ¶\"),\n",
    "]\n",
    "\n",
    "for entity in entities_data:\n",
    "    kg.add_entity(entity)\n",
    "\n",
    "# æ·»åŠ å…³ç³»\n",
    "relations_data = [\n",
    "    # åˆ›é€ è€…å…³ç³»\n",
    "    Relation(\"E4\", \"E1\", \"åˆ›é€ è€…\"),\n",
    "    Relation(\"E5\", \"E2\", \"åˆ›é€ è€…\"),\n",
    "    Relation(\"E6\", \"E3\", \"åˆ›é€ è€…\"),\n",
    "    \n",
    "    # åº”ç”¨é¢†åŸŸ\n",
    "    Relation(\"E1\", \"E7\", \"åº”ç”¨äº\"),\n",
    "    Relation(\"E1\", \"E9\", \"åº”ç”¨äº\"),\n",
    "    Relation(\"E2\", \"E8\", \"åº”ç”¨äº\"),\n",
    "    Relation(\"E3\", \"E10\", \"åº”ç”¨äº\"),\n",
    "    \n",
    "    # æŠ€æœ¯å…³ç³»\n",
    "    Relation(\"E11\", \"E12\", \"ä¾èµ–\"),\n",
    "    Relation(\"E11\", \"E13\", \"ä¾èµ–\"),\n",
    "    Relation(\"E13\", \"E14\", \"åŸºäº\"),\n",
    "    Relation(\"E14\", \"E15\", \"åŒ…å«\"),\n",
    "    \n",
    "    # ç«äº‰å…³ç³»\n",
    "    Relation(\"E1\", \"E2\", \"ç«äº‰è€…\"),\n",
    "    Relation(\"E1\", \"E3\", \"ç«äº‰è€…\"),\n",
    "    Relation(\"E2\", \"E3\", \"ç«äº‰è€…\"),\n",
    "    \n",
    "    # è¯­è¨€ç‰¹ç‚¹\n",
    "    Relation(\"E1\", \"E7\", \"é€‚åˆ\"),\n",
    "    Relation(\"E2\", \"E8\", \"é€‚åˆ\"),\n",
    "]\n",
    "\n",
    "for relation in relations_data:\n",
    "    kg.add_relation(relation)\n",
    "\n",
    "print(\"âœ… çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ\")\n",
    "print(f\"ğŸ“Š å›¾è°±ç»Ÿè®¡: {kg.get_stats()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 å¯è§†åŒ–çŸ¥è¯†å›¾è°±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_graph(kg: KnowledgeGraph, \n",
    "                   figsize=(14, 10),\n",
    "                   highlight_nodes: List[str] = None):\n",
    "    \"\"\"å¯è§†åŒ–çŸ¥è¯†å›¾è°±\"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # ä½¿ç”¨spring layout\n",
    "    pos = nx.spring_layout(kg.graph, k=2, iterations=50, seed=42)\n",
    "    \n",
    "    # æŒ‰ç±»å‹è®¾ç½®é¢œè‰²\n",
    "    node_colors = []\n",
    "    color_map = {\n",
    "        'Technology': '#FF6B6B',\n",
    "        'Person': '#4ECDC4',\n",
    "        'Field': '#45B7D1',\n",
    "        'Concept': '#96CEB4'\n",
    "    }\n",
    "    \n",
    "    for node_id in kg.graph.nodes():\n",
    "        entity = kg.entities[node_id]\n",
    "        node_colors.append(color_map.get(entity.type, '#CCCCCC'))\n",
    "    \n",
    "    # ç»˜åˆ¶èŠ‚ç‚¹\n",
    "    nx.draw_networkx_nodes(kg.graph, pos,\n",
    "                           node_color=node_colors,\n",
    "                           node_size=1500,\n",
    "                           alpha=0.8)\n",
    "    \n",
    "    # é«˜äº®èŠ‚ç‚¹\n",
    "    if highlight_nodes:\n",
    "        nx.draw_networkx_nodes(kg.graph,\n",
    "                               pos={n: pos[n] for n in highlight_nodes},\n",
    "                               node_color='yellow',\n",
    "                               node_size=2000,\n",
    "                               alpha=0.5)\n",
    "    \n",
    "    # ç»˜åˆ¶è¾¹\n",
    "    nx.draw_networkx_edges(kg.graph, pos,\n",
    "                           edge_color='gray',\n",
    "                           arrows=True,\n",
    "                           arrowsize=20,\n",
    "                           width=1.5,\n",
    "                           alpha=0.6)\n",
    "    \n",
    "    # ç»˜åˆ¶æ ‡ç­¾\n",
    "    labels = {node_id: kg.entities[node_id].name \n",
    "              for node_id in kg.graph.nodes()}\n",
    "    nx.draw_networkx_labels(kg.graph, pos,\n",
    "                            labels=labels,\n",
    "                            font_size=10,\n",
    "                            font_weight='bold')\n",
    "    \n",
    "    # ç»˜åˆ¶è¾¹æ ‡ç­¾ï¼ˆå…³ç³»ç±»å‹ï¼‰\n",
    "    edge_labels = {}\n",
    "    for source, target, data in kg.graph.edges(data=True):\n",
    "        edge_labels[(source, target)] = data.get('relation_type', '')\n",
    "    \n",
    "    nx.draw_networkx_edge_labels(kg.graph, pos,\n",
    "                                  edge_labels=edge_labels,\n",
    "                                  font_size=8)\n",
    "    \n",
    "    # å›¾ä¾‹\n",
    "    legend_elements = [plt.Line2D([0], [0], marker='o', color='w',\n",
    "                                 label=entity_type,\n",
    "                                 markersize=15,\n",
    "                                 markerfacecolor=color)\n",
    "                      for entity_type, color in color_map.items()]\n",
    "    plt.legend(handles=legend_elements, loc='upper left')\n",
    "    \n",
    "    plt.title(\"çŸ¥è¯†å›¾è°±å¯è§†åŒ–\", fontsize=16, weight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# å¯è§†åŒ–å®Œæ•´å›¾è°±\n",
    "visualize_graph(kg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. å®ä½“è¯†åˆ«ä¸å…³ç³»æŠ½å–\n",
    "\n",
    "### 4.1 ç®€å•çš„è§„åˆ™å®ä½“è¯†åˆ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityExtractor:\n",
    "    \"\"\"å®ä½“æå–å™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰\"\"\"\n",
    "    \n",
    "    def __init__(self, knowledge_graph: KnowledgeGraph):\n",
    "        self.kg = knowledge_graph\n",
    "        self.entity_names = {e.name.lower(): e.id \n",
    "                            for e in knowledge_graph.entities.values()}\n",
    "    \n",
    "    def extract_entities(self, text: str) -> List[Tuple[str, str]]:\n",
    "        \"\"\"ä»æ–‡æœ¬ä¸­æå–å®ä½“\n",
    "        \n",
    "        Returns:\n",
    "            [(å®ä½“åç§°, å®ä½“ID)]\n",
    "        \"\"\"\n",
    "        found_entities = []\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # ç®€å•çš„å­—ç¬¦ä¸²åŒ¹é…\n",
    "        for entity_name, entity_id in self.entity_names.items():\n",
    "            if entity_name in text_lower:\n",
    "                entity = self.kg.entities[entity_id]\n",
    "                found_entities.append((entity.name, entity_id))\n",
    "        \n",
    "        return found_entities\n",
    "\n",
    "# æµ‹è¯•å®ä½“æå–\n",
    "extractor = EntityExtractor(kg)\n",
    "\n",
    "test_queries = [\n",
    "    \"Pythonå’ŒJavaScriptæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ\",\n",
    "    \"RAGä½¿ç”¨äº†å“ªäº›æŠ€æœ¯ï¼Ÿ\",\n",
    "    \"Transformeræ¶æ„åŒ…å«ä»€ä¹ˆï¼Ÿ\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ” å®ä½“è¯†åˆ«æµ‹è¯•:\\n\")\n",
    "for query in test_queries:\n",
    "    entities = extractor.extract_entities(query)\n",
    "    print(f\"æŸ¥è¯¢: {query}\")\n",
    "    print(f\"è¯†åˆ«å®ä½“: {[e[0] for e in entities]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å›¾è°±æ£€ç´¢\n",
    "\n",
    "### 5.1 å¤šè·³æ¨ç†æ£€ç´¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphRetriever:\n",
    "    \"\"\"å›¾è°±æ£€ç´¢å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, knowledge_graph: KnowledgeGraph):\n",
    "        self.kg = knowledge_graph\n",
    "        self.entity_extractor = EntityExtractor(knowledge_graph)\n",
    "    \n",
    "    def retrieve_by_entity(self, entity_id: str, \n",
    "                          max_hops: int = 2) -> Dict:\n",
    "        \"\"\"åŸºäºå®ä½“çš„å¤šè·³æ£€ç´¢\n",
    "        \n",
    "        Args:\n",
    "            entity_id: å®ä½“ID\n",
    "            max_hops: æœ€å¤§è·³æ•°\n",
    "        \n",
    "        Returns:\n",
    "            {'entities': List[Entity], 'relations': List[Relation], 'paths': List}\n",
    "        \"\"\"\n",
    "        if entity_id not in self.kg.entities:\n",
    "            return {'entities': [], 'relations': [], 'paths': []}\n",
    "        \n",
    "        # æå–å­å›¾\n",
    "        subgraph = self.kg.get_subgraph([entity_id], hops=max_hops)\n",
    "        \n",
    "        # æ”¶é›†è·¯å¾„\n",
    "        paths = self._find_paths(entity_id, subgraph, max_hops)\n",
    "        \n",
    "        return {\n",
    "            'entities': list(subgraph.entities.values()),\n",
    "            'relations': subgraph.relations,\n",
    "            'paths': paths,\n",
    "            'subgraph': subgraph\n",
    "        }\n",
    "    \n",
    "    def retrieve_by_query(self, query: str, \n",
    "                          max_hops: int = 2) -> Dict:\n",
    "        \"\"\"åŸºäºæŸ¥è¯¢çš„æ£€ç´¢\"\"\"\n",
    "        # æå–å®ä½“\n",
    "        entities = self.entity_extractor.extract_entities(query)\n",
    "        \n",
    "        if not entities:\n",
    "            return {'entities': [], 'relations': [], 'paths': []}\n",
    "        \n",
    "        # åˆå¹¶æ‰€æœ‰å®ä½“çš„æ£€ç´¢ç»“æœ\n",
    "        all_entities = set()\n",
    "        all_relations = []\n",
    "        all_paths = []\n",
    "        \n",
    "        for _, entity_id in entities:\n",
    "            result = self.retrieve_by_entity(entity_id, max_hops)\n",
    "            all_entities.update(e.id for e in result['entities'])\n",
    "            all_relations.extend(result['relations'])\n",
    "            all_paths.extend(result['paths'])\n",
    "        \n",
    "        return {\n",
    "            'entities': [self.kg.entities[eid] for eid in all_entities],\n",
    "            'relations': all_relations,\n",
    "            'paths': all_paths[:10],  # é™åˆ¶è·¯å¾„æ•°é‡\n",
    "            'matched_entities': entities\n",
    "        }\n",
    "    \n",
    "    def _find_paths(self, source_id: str, \n",
    "                   subgraph: KnowledgeGraph,\n",
    "                   max_length: int) -> List[List[str]]:\n",
    "        \"\"\"æŸ¥æ‰¾ä»æºå®ä½“å‡ºå‘çš„æ‰€æœ‰è·¯å¾„\"\"\"\n",
    "        paths = []\n",
    "        \n",
    "        for target_id in subgraph.entities.keys():\n",
    "            if target_id == source_id:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                path = nx.shortest_path(\n",
    "                    subgraph.graph,\n",
    "                    source_id,\n",
    "                    target_id\n",
    "                )\n",
    "                \n",
    "                if len(path) <= max_length + 1:\n",
    "                    paths.append(path)\n",
    "            except nx.NetworkXNoPath:\n",
    "                continue\n",
    "        \n",
    "        # æŒ‰é•¿åº¦æ’åº\n",
    "        paths.sort(key=len)\n",
    "        return paths\n",
    "\n",
    "# åˆ›å»ºæ£€ç´¢å™¨\n",
    "retriever = GraphRetriever(kg)\n",
    "\n",
    "print(\"âœ… å›¾è°±æ£€ç´¢å™¨åˆ›å»ºå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 æµ‹è¯•å›¾è°±æ£€ç´¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•1ï¼šåŸºäºå®ä½“çš„æ£€ç´¢\n",
    "print(\"ğŸ” æµ‹è¯•1: æŸ¥æ‰¾Pythonç›¸å…³ä¿¡æ¯ (2è·³)\\n\")\n",
    "result1 = retriever.retrieve_by_entity(\"E1\", max_hops=2)\n",
    "\n",
    "print(f\"æ‰¾åˆ°å®ä½“æ•°: {len(result1['entities'])}\")\n",
    "print(f\"æ‰¾åˆ°å…³ç³»æ•°: {len(result1['relations'])}\")\n",
    "print(f\"æ¨ç†è·¯å¾„æ•°: {len(result1['paths'])}\")\n",
    "\n",
    "print(\"\\næ¨ç†è·¯å¾„ç¤ºä¾‹:\")\n",
    "for i, path in enumerate(result1['paths'][:5], 1):\n",
    "    path_str = \" â†’ \".join([kg.entities[eid].name for eid in path])\n",
    "    print(f\"  {i}. {path_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•2ï¼šåŸºäºæŸ¥è¯¢çš„æ£€ç´¢\n",
    "print(\"ğŸ” æµ‹è¯•2: æŸ¥è¯¢ 'RAGä¾èµ–å“ªäº›æŠ€æœ¯'\\n\")\n",
    "result2 = retriever.retrieve_by_query(\"RAGä¾èµ–å“ªäº›æŠ€æœ¯\", max_hops=2)\n",
    "\n",
    "print(f\"åŒ¹é…å®ä½“: {[e[0] for e in result2['matched_entities']]}\")\n",
    "print(f\"\\nç›¸å…³å®ä½“:\")\n",
    "for entity in result2['entities']:\n",
    "    print(f\"  - {entity.name} ({entity.type})\")\n",
    "\n",
    "print(f\"\\næ¨ç†è·¯å¾„:\")\n",
    "for i, path in enumerate(result2['paths'][:5], 1):\n",
    "    path_str = \" â†’ \".join([kg.entities[eid].name for eid in path])\n",
    "    print(f\"  {i}. {path_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. GraphRAGå®Œæ•´å®ç°\n",
    "\n",
    "### 6.1 GraphRAGç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphRAG:\n",
    "    \"\"\"\n",
    "    GraphRAGç³»ç»Ÿ\n",
    "    \n",
    "    ç»“åˆçŸ¥è¯†å›¾è°±æ£€ç´¢å’Œå‘é‡æ£€ç´¢\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 knowledge_graph: KnowledgeGraph,\n",
    "                 use_graph: bool = True,\n",
    "                 graph_weight: float = 0.5):\n",
    "        self.kg = knowledge_graph\n",
    "        self.graph_retriever = GraphRetriever(knowledge_graph)\n",
    "        self.use_graph = use_graph\n",
    "        self.graph_weight = graph_weight\n",
    "    \n",
    "    def query(self, \n",
    "             query: str,\n",
    "             max_hops: int = 2,\n",
    "             verbose: bool = False) -> Dict:\n",
    "        \"\"\"æŸ¥è¯¢\n",
    "        \n",
    "        Args:\n",
    "            query: æŸ¥è¯¢æ–‡æœ¬\n",
    "            max_hops: æœ€å¤§è·³æ•°\n",
    "            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯\n",
    "        \n",
    "        Returns:\n",
    "            {'answer': str, 'graph_context': ..., 'paths': ...}\n",
    "        \"\"\"\n",
    "        # å›¾è°±æ£€ç´¢\n",
    "        graph_result = self.graph_retriever.retrieve_by_query(\n",
    "            query, max_hops=max_hops\n",
    "        )\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n=== GraphRAGæŸ¥è¯¢ ===\")\n",
    "            print(f\"æŸ¥è¯¢: {query}\")\n",
    "            print(f\"\\nåŒ¹é…å®ä½“: {[e[0] for e in graph_result['matched_entities']]}\")\n",
    "            print(f\"æ‰¾åˆ°å®ä½“æ•°: {len(graph_result['entities'])}\")\n",
    "            print(f\"æ¨ç†è·¯å¾„æ•°: {len(graph_result['paths'])}\")\n",
    "        \n",
    "        # æ„å»ºå›¾è°±ä¸Šä¸‹æ–‡\n",
    "        graph_context = self._build_graph_context(graph_result)\n",
    "        \n",
    "        # ç”Ÿæˆç­”æ¡ˆï¼ˆè¿™é‡Œä½¿ç”¨ç®€å•çš„æ¨¡æ¿ï¼‰\n",
    "        answer = self._generate_answer(query, graph_context, graph_result)\n",
    "        \n",
    "        return {\n",
    "            'answer': answer,\n",
    "            'graph_context': graph_context,\n",
    "            'entities': graph_result['entities'],\n",
    "            'relations': graph_result['relations'],\n",
    "            'paths': graph_result['paths'],\n",
    "            'matched_entities': graph_result['matched_entities']\n",
    "        }\n",
    "    \n",
    "    def _build_graph_context(self, graph_result: Dict) -> str:\n",
    "        \"\"\"æ„å»ºå›¾è°±ä¸Šä¸‹æ–‡æ–‡æœ¬\"\"\"\n",
    "        if not graph_result['entities']:\n",
    "            return \"æœªæ‰¾åˆ°ç›¸å…³çŸ¥è¯†å›¾è°±ä¿¡æ¯\"\n",
    "        \n",
    "        context_parts = []\n",
    "        \n",
    "        # å®ä½“ä¿¡æ¯\n",
    "        entities_info = []\n",
    "        for entity in graph_result['entities'][:10]:\n",
    "            entities_info.append(f\"- {entity.name}: {entity.description}\")\n",
    "        \n",
    "        if entities_info:\n",
    "            context_parts.append(\"ç›¸å…³å®ä½“:\\n\" + \"\\n\".join(entities_info))\n",
    "        \n",
    "        # å…³ç³»ä¿¡æ¯\n",
    "        if graph_result['relations']:\n",
    "            relations_info = []\n",
    "            for rel in graph_result['relations'][:15]:\n",
    "                source = self.kg.entities[rel.source].name\n",
    "                target = self.kg.entities[rel.target].name\n",
    "                relations_info.append(f\"- {source} --[{rel.relation_type}]--> {target}\")\n",
    "            \n",
    "            context_parts.append(\"å…³ç³»:\\n\" + \"\\n\".join(relations_info))\n",
    "        \n",
    "        # æ¨ç†è·¯å¾„\n",
    "        if graph_result['paths']:\n",
    "            paths_info = []\n",
    "            for i, path in enumerate(graph_result['paths'][:5], 1):\n",
    "                path_str = \" â†’ \".join([self.kg.entities[eid].name for eid in path])\n",
    "                paths_info.append(f\"{i}. {path_str}\")\n",
    "            \n",
    "            context_parts.append(\"æ¨ç†è·¯å¾„:\\n\" + \"\\n\".join(paths_info))\n",
    "        \n",
    "        return \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    def _generate_answer(self, \n",
    "                       query: str,\n",
    "                       graph_context: str,\n",
    "                       graph_result: Dict) -> str:\n",
    "        \"\"\"ç”Ÿæˆç­”æ¡ˆï¼ˆç®€åŒ–ç‰ˆï¼‰\"\"\"\n",
    "        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨LLM\n",
    "        matched = [e[0] for e in graph_result['matched_entities']]\n",
    "        \n",
    "        if not matched:\n",
    "            return \"æŠ±æ­‰ï¼Œæˆ‘æ— æ³•åœ¨çŸ¥è¯†å›¾è°±ä¸­æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚\"\n",
    "        \n",
    "        # æ„å»ºç®€å•ç­”æ¡ˆ\n",
    "        answer_parts = [f\"åŸºäºçŸ¥è¯†å›¾è°±ï¼Œæˆ‘æ‰¾åˆ°äº†å…³äº {', '.join(matched)} çš„ä¿¡æ¯:\"]\n",
    "        \n",
    "        # æ·»åŠ è·¯å¾„ä¿¡æ¯\n",
    "        if graph_result['paths']:\n",
    "            answer_parts.append(\"\\n\\nå…³é”®å‘ç°:\")\n",
    "            for path in graph_result['paths'][:3]:\n",
    "                path_str = \" â†’ \".join([self.kg.entities[eid].name for eid in path])\n",
    "                answer_parts.append(f\"- {path_str}\")\n",
    "        \n",
    "        return \"\\n\".join(answer_parts)\n",
    "\n",
    "# åˆ›å»ºGraphRAGç³»ç»Ÿ\n",
    "graph_rag = GraphRAG(kg, use_graph=True, graph_weight=0.5)\n",
    "\n",
    "print(\"âœ… GraphRAGç³»ç»Ÿåˆ›å»ºå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 GraphRAGæŸ¥è¯¢æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥è¯¢1ï¼šRAGç›¸å…³æŠ€æœ¯\n",
    "result1 = graph_rag.query(\n",
    "    \"RAGä½¿ç”¨äº†å“ªäº›æŠ€æœ¯ï¼Ÿ\",\n",
    "    max_hops=2,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“ ç­”æ¡ˆ:\")\n",
    "print(result1['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥è¯¢2ï¼šPythonçš„åº”ç”¨é¢†åŸŸ\n",
    "result2 = graph_rag.query(\n",
    "    \"Pythoné€‚åˆä»€ä¹ˆé¢†åŸŸï¼Ÿ\",\n",
    "    max_hops=2,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“ ç­”æ¡ˆ:\")\n",
    "print(result2['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥è¯¢3ï¼šå¤æ‚æ¨ç†\n",
    "result3 = graph_rag.query(\n",
    "    \"Transformerå’ŒRAGæœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ\",\n",
    "    max_hops=3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“ ç­”æ¡ˆ:\")\n",
    "print(result3['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ç»“æœå¯è§†åŒ–\n",
    "\n",
    "### 7.1 æ¨ç†è·¯å¾„å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_reasoning_path(kg: KnowledgeGraph, \n",
    "                            path: List[str],\n",
    "                            figsize=(12, 6)):\n",
    "    \"\"\"å¯è§†åŒ–æ¨ç†è·¯å¾„\"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # æå–è·¯å¾„å­å›¾\n",
    "    subgraph_nodes = set(path)\n",
    "    \n",
    "    # åˆ›å»ºå­å›¾\n",
    "    path_graph = nx.DiGraph()\n",
    "    \n",
    "    # æ·»åŠ èŠ‚ç‚¹\n",
    "    for i, node_id in enumerate(path):\n",
    "        entity = kg.entities[node_id]\n",
    "        path_graph.add_node(\n",
    "            node_id,\n",
    "            name=entity.name,\n",
    "            type=entity.type,\n",
    "            pos=(i, 0)\n",
    "        )\n",
    "    \n",
    "    # æ·»åŠ è¾¹\n",
    "    for i in range(len(path) - 1):\n",
    "        source, target = path[i], path[i+1]\n",
    "        # æ‰¾åˆ°å…³ç³»ç±»å‹\n",
    "        edge_data = kg.graph.get_edge_data(source, target)\n",
    "        if edge_data:\n",
    "            rel_type = edge_data[0].get('relation_type', 'related')\n",
    "            path_graph.add_edge(source, target, relation_type=rel_type)\n",
    "    \n",
    "    # ç»˜åˆ¶\n",
    "    pos = nx.get_node_attributes(path_graph, 'pos')\n",
    "    \n",
    "    # èŠ‚ç‚¹\n",
    "    nx.draw_networkx_nodes(path_graph, pos,\n",
    "                           node_color='lightblue',\n",
    "                           node_size=2000,\n",
    "                           alpha=0.8)\n",
    "    \n",
    "    # è¾¹\n",
    "    nx.draw_networkx_edges(path_graph, pos,\n",
    "                           edge_color='gray',\n",
    "                           arrows=True,\n",
    "                           arrowsize=30,\n",
    "                           width=2)\n",
    "    \n",
    "    # èŠ‚ç‚¹æ ‡ç­¾\n",
    "    labels = nx.get_node_attributes(path_graph, 'name')\n",
    "    nx.draw_networkx_labels(path_graph, pos,\n",
    "                            labels=labels,\n",
    "                            font_size=10,\n",
    "                            font_weight='bold')\n",
    "    \n",
    "    # è¾¹æ ‡ç­¾\n",
    "    edge_labels = nx.get_edge_attributes(path_graph, 'relation_type')\n",
    "    nx.draw_networkx_edge_labels(path_graph, pos,\n",
    "                                  edge_labels=edge_labels,\n",
    "                                  font_size=9)\n",
    "    \n",
    "    plt.title(\"æ¨ç†è·¯å¾„å¯è§†åŒ–\", fontsize=14, weight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# å¯è§†åŒ–æ¨ç†è·¯å¾„\n",
    "if result3['paths']:\n",
    "    visualize_reasoning_path(kg, result3['paths'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 å­å›¾å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–æŸ¥è¯¢ç›¸å…³çš„å­å›¾\n",
    "if result3['matched_entities']:\n",
    "    # è·å–åŒ¹é…å®ä½“çš„ID\n",
    "    entity_ids = [e[1] for e in result3['matched_entities']]\n",
    "    \n",
    "    # æå–å­å›¾\n",
    "    subgraph = kg.get_subgraph(entity_ids, hops=2)\n",
    "    \n",
    "    # å¯è§†åŒ–\n",
    "    visualize_graph(subgraph, figsize=(12, 8), highlight_nodes=entity_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. æ€§èƒ½è¯„ä¼°\n",
    "\n",
    "### 8.1 å¯¹æ¯”ä¸åŒè·³æ•°çš„æ•ˆæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•ä¸åŒè·³æ•°çš„æ£€ç´¢æ•ˆæœ\n",
    "test_queries = [\n",
    "    \"RAGä¾èµ–ä»€ä¹ˆï¼Ÿ\",\n",
    "    \"Pythonçš„åº”ç”¨é¢†åŸŸï¼Ÿ\",\n",
    "    \"TransformeråŒ…å«ä»€ä¹ˆï¼Ÿ\"\n",
    "]\n",
    "\n",
    "hop_counts = [1, 2, 3]\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "for query in test_queries:\n",
    "    for hops in hop_counts:\n",
    "        result = graph_rag.query(query, max_hops=hops, verbose=False)\n",
    "        \n",
    "        results_summary.append({\n",
    "            'æŸ¥è¯¢': query,\n",
    "            'è·³æ•°': hops,\n",
    "            'å®ä½“æ•°': len(result['entities']),\n",
    "            'å…³ç³»æ•°': len(result['relations']),\n",
    "            'è·¯å¾„æ•°': len(result['paths'])\n",
    "        })\n",
    "\n",
    "# æ˜¾ç¤ºç»“æœ\n",
    "print(\"\\nğŸ“Š ä¸åŒè·³æ•°çš„æ£€ç´¢æ•ˆæœå¯¹æ¯”:\\n\")\n",
    "print(f\"{'æŸ¥è¯¢':<25} {'è·³æ•°':<6} {'å®ä½“æ•°':<8} {'å…³ç³»æ•°':<8} {'è·¯å¾„æ•°':<8}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for r in results_summary:\n",
    "    print(f\"{r['æŸ¥è¯¢']:<25} {r['è·³æ•°']:<6} {r['å®ä½“æ•°']:<8} {r['å…³ç³»æ•°']:<8} {r['è·¯å¾„æ•°']:<8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 å›¾è°±ç»Ÿè®¡ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è·å–è¯¦ç»†ç»Ÿè®¡\n",
    "stats = kg.get_stats()\n",
    "\n",
    "print(\"\\nğŸ“Š çŸ¥è¯†å›¾è°±ç»Ÿè®¡ä¿¡æ¯:\\n\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# æŒ‰ç±»å‹ç»Ÿè®¡å®ä½“\n",
    "print(\"\\nğŸ“¦ å®ä½“ç±»å‹åˆ†å¸ƒ:\")\n",
    "entity_types = defaultdict(int)\n",
    "for entity in kg.entities.values():\n",
    "    entity_types[entity.type] += 1\n",
    "\n",
    "for entity_type, count in sorted(entity_types.items()):\n",
    "    print(f\"  {entity_type}: {count}\")\n",
    "\n",
    "# å…³ç³»ç±»å‹ç»Ÿè®¡\n",
    "print(\"\\nğŸ”— å…³ç³»ç±»å‹åˆ†å¸ƒ:\")\n",
    "relation_types = defaultdict(int)\n",
    "for relation in kg.relations:\n",
    "    relation_types[relation.relation_type] += 1\n",
    "\n",
    "for rel_type, count in sorted(relation_types.items()):\n",
    "    print(f\"  {rel_type}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. é«˜çº§åŠŸèƒ½\n",
    "\n",
    "### 9.1 è·¯å¾„æ’åºä¸è¯„åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_paths(kg: KnowledgeGraph, \n",
    "              paths: List[List[str]],\n",
    "              query: str = \"\") -> List[Tuple[List[str], float]]:\n",
    "    \"\"\"å¯¹æ¨ç†è·¯å¾„è¿›è¡Œæ’åº\n",
    "    \n",
    "    è¯„åˆ†å› ç´ ï¼š\n",
    "    1. è·¯å¾„é•¿åº¦ï¼ˆè¶ŠçŸ­è¶Šå¥½ï¼‰\n",
    "    2. å…³ç³»æƒé‡ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰\n",
    "    3. å®ä½“é‡è¦æ€§\n",
    "    \"\"\"\n",
    "    scored_paths = []\n",
    "    \n",
    "    for path in paths:\n",
    "        score = 0.0\n",
    "        \n",
    "        # 1. è·¯å¾„é•¿åº¦ï¼ˆçŸ­è·¯å¾„å¾—åˆ†æ›´é«˜ï¼‰\n",
    "        score += 10.0 / len(path)\n",
    "        \n",
    "        # 2. å…³ç³»æƒé‡\n",
    "        for i in range(len(path) - 1):\n",
    "            edge_data = kg.graph.get_edge_data(path[i], path[i+1])\n",
    "            if edge_data:\n",
    "                weight = edge_data[0].get('weight', 1.0)\n",
    "                score += weight\n",
    "        \n",
    "        # 3. å®ä½“ç±»å‹é‡è¦æ€§\n",
    "        type_importance = {\n",
    "            'Technology': 3,\n",
    "            'Concept': 2,\n",
    "            'Field': 1.5,\n",
    "            'Person': 1\n",
    "        }\n",
    "        \n",
    "        for node_id in path:\n",
    "            entity = kg.entities.get(node_id)\n",
    "            if entity:\n",
    "                score += type_importance.get(entity.type, 0.5)\n",
    "        \n",
    "        scored_paths.append((path, score))\n",
    "    \n",
    "    # æŒ‰å¾—åˆ†æ’åº\n",
    "    scored_paths.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scored_paths\n",
    "\n",
    "# æµ‹è¯•è·¯å¾„æ’åº\n",
    "if result3['paths']:\n",
    "    ranked = rank_paths(kg, result3['paths'])\n",
    "    \n",
    "    print(\"\\nğŸ† æ¨ç†è·¯å¾„æ’åº:\\n\")\n",
    "    for i, (path, score) in enumerate(ranked[:5], 1):\n",
    "        path_str = \" â†’ \".join([kg.entities[eid].name for eid in path])\n",
    "        print(f\"{i}. (å¾—åˆ†: {score:.2f}) {path_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. æ€»ç»“\n",
    "\n",
    "### ä½ å·²ç»å­¦ä¼šï¼š\n",
    "\n",
    "âœ… **çŸ¥è¯†å›¾è°±åŸºç¡€**\n",
    "   - å®ä½“å’Œå…³ç³»çš„å®šä¹‰\n",
    "   - NetworkXå›¾è°±æ„å»º\n",
    "   - å›¾è°±å¯è§†åŒ–\n",
    "\n",
    "âœ… **å®ä½“è¯†åˆ«**\n",
    "   - è§„åˆ™åŒ¹é…æ–¹æ³•\n",
    "   - å®ä½“é“¾æ¥\n",
    "   - æ­§ä¹‰å¤„ç†\n",
    "\n",
    "âœ… **å›¾è°±æ£€ç´¢**\n",
    "   - å¤šè·³æ¨ç†\n",
    "   - å­å›¾æå–\n",
    "   - è·¯å¾„æŸ¥æ‰¾\n",
    "\n",
    "âœ… **GraphRAGç³»ç»Ÿ**\n",
    "   - å›¾è°±ä¸Šä¸‹æ–‡æ„å»º\n",
    "   - æ¨ç†è·¯å¾„ç”Ÿæˆ\n",
    "   - ç­”æ¡ˆç”Ÿæˆ\n",
    "\n",
    "âœ… **å¯è§†åŒ–ä¸è¯„ä¼°**\n",
    "   - æ¨ç†è·¯å¾„å¯è§†åŒ–\n",
    "   - å­å›¾å¯è§†åŒ–\n",
    "   - æ€§èƒ½è¯„ä¼°\n",
    "\n",
    "### ä¸‹ä¸€æ­¥ï¼š\n",
    "\n",
    "- ğŸš€ ä½¿ç”¨çœŸå®NERæ¨¡å‹ï¼ˆspaCyï¼‰\n",
    "- ğŸ“Š é›†æˆå‘é‡æ£€ç´¢\n",
    "- ğŸ¯ ä¼˜åŒ–è·¯å¾„è¯„åˆ†ç®—æ³•\n",
    "- ğŸ”— æ·»åŠ æ›´å¤šå®ä½“å’Œå…³ç³»\n",
    "- ğŸŒ“ æ„å»ºæ›´å¤§è§„æ¨¡çš„çŸ¥è¯†å›¾è°±\n",
    "\n",
    "### ç»ƒä¹ ï¼š\n",
    "\n",
    "1. ä¸ºä½ çš„é¢†åŸŸæ„å»ºä¸€ä¸ªå°å‹çŸ¥è¯†å›¾è°±\n",
    "2. å®ç°åŸºäºLLMçš„å®ä½“å’Œå…³ç³»æŠ½å–\n",
    "3. æ·»åŠ å®ä½“æ¶ˆæ­§åŠŸèƒ½\n",
    "4. å®ç°æ›´å¤æ‚çš„è·¯å¾„æ’åºç®—æ³•\n",
    "5. å°†å›¾è°±æ£€ç´¢ä¸å‘é‡æ£€ç´¢èåˆ\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ‰ æ­å–œå®ŒæˆçŸ¥è¯†å›¾è°±RAGå®è·µï¼**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
