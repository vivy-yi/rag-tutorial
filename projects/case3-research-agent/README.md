# æ¡ˆä¾‹3ï¼šAIç ”ç©¶åŠ©æ‰‹Agent

> ä½¿ç”¨ReAct Agentæ„å»ºèƒ½å¤Ÿè‡ªä¸»æœç´¢ã€åˆ†æå’Œæ€»ç»“çš„AIç ”ç©¶åŠ©æ‰‹

---

## ğŸ“‹ æ¡ˆä¾‹æ¦‚è¿°

### ä¸šåŠ¡åœºæ™¯

ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…é¢ä¸´ä¿¡æ¯è¿‡è½½ï¼š
- âœ— è®ºæ–‡æ•°é‡çˆ†ç‚¸å¼å¢é•¿
- âœ— æŠ€æœ¯æ›´æ–°è¿­ä»£å¿«
- âœ— è·¨é¢†åŸŸçŸ¥è¯†æ•´åˆå›°éš¾
- âœ— ä»£ç å®ç°è€—æ—¶

### Agentè§£å†³æ–¹æ¡ˆ

æ„å»ºè‡ªä¸»ç ”ç©¶åŠ©æ‰‹Agentï¼š
- âœ… è‡ªåŠ¨æ–‡çŒ®æ£€ç´¢
- âœ… æŠ€æœ¯å¯¹æ¯”åˆ†æ
- âœ… ä»£ç ç¤ºä¾‹ç”Ÿæˆ
- âœ… ç ”ç©¶æŠ¥å‘Šæ’°å†™
- âœ… å¤šæ­¥æ¨ç†è§„åˆ’

---

## ğŸ¯ åŠŸèƒ½éœ€æ±‚

### æ ¸å¿ƒåŠŸèƒ½

1. **æ–‡çŒ®æœç´¢**
   - ArXivè®ºæ–‡æ£€ç´¢
   - Google Scholaræœç´¢
   - GitHubä»£ç ä»“åº“
   - Stack Overflowé—®ç­”

2. **å†…å®¹åˆ†æ**
   - è®ºæ–‡æ‘˜è¦æå–
   - æ ¸å¿ƒæ–¹æ³•æ€»ç»“
   - å®éªŒç»“æœåˆ†æ
   - ä»£ç å®ç°ç†è§£

3. **å¯¹æ¯”ç ”ç©¶**
   - å¤šæ¨¡å‹æ€§èƒ½å¯¹æ¯”
   - ä¼˜ç¼ºç‚¹åˆ†æ
   - é€‚ç”¨åœºæ™¯è¯„ä¼°
   - å‘å±•è¶‹åŠ¿é¢„æµ‹

4. **æŠ¥å‘Šç”Ÿæˆ**
   - ç»“æ„åŒ–ç ”ç©¶æŠ¥å‘Š
   - Markdownæ ¼å¼
   - åŒ…å«å¼•ç”¨é“¾æ¥
   - ä»£ç ç¤ºä¾‹

### Agentèƒ½åŠ›

- **è‡ªä¸»è§„åˆ’**ï¼šåˆ†è§£å¤æ‚ä»»åŠ¡
- **å·¥å…·è°ƒç”¨**ï¼šä½¿ç”¨å¤šç§API
- **å¤šæ­¥æ¨ç†**ï¼šé“¾å¼æ€è€ƒ
- **è‡ªæˆ‘åæ€**ï¼šéªŒè¯å’Œæ”¹è¿›
- **è®°å¿†ç®¡ç†**ï¼šä¿æŒä¸Šä¸‹æ–‡

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### Agentæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ç ”ç©¶åŠ©æ‰‹Agent                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚      Planner (è§„åˆ’å™¨)              â”‚  â”‚
â”‚  â”‚  - ä»»åŠ¡åˆ†è§£                         â”‚  â”‚
â”‚  â”‚  - æ­¥éª¤è§„åˆ’                         â”‚  â”‚
â”‚  â”‚  - åŠ¨æ€è°ƒæ•´                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚      ReAct Loop (æ¨ç†å¾ªç¯)         â”‚  â”‚
â”‚  â”‚  - Thought                         â”‚  â”‚
â”‚  â”‚  - Action                          â”‚  â”‚
â”‚  â”‚  - Observation                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚      Tools (å·¥å…·é›†)                â”‚  â”‚
â”‚  â”‚  - ArXivSearch                    â”‚  â”‚
â”‚  â”‚  - GitHubSearch                   â”‚  â”‚
â”‚  â”‚  - PaperAnalysis                  â”‚  â”‚
â”‚  â”‚  - CodeGeneration                 â”‚  â”‚
â”‚  â”‚  - ReportWriting                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚      Memory (è®°å¿†)                 â”‚  â”‚
â”‚  â”‚  - çŸ­æœŸè®°å¿† (å½“å‰ä¼šè¯)             â”‚  â”‚
â”‚  â”‚  - é•¿æœŸè®°å¿† (å‘é‡å­˜å‚¨)             â”‚  â”‚
â”‚  â”‚  - çŸ¥è¯†åº“ (é‡è¦å‘ç°)               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æŠ€æœ¯æ ˆ

**Agentæ¡†æ¶**ï¼š
- LangChain Agents
- LangGraph (å·¥ä½œæµ)

**å·¥å…·**ï¼š
- ArXiv API
- GitHub API
- Google Scholar (çˆ¬è™«)
- OpenAI GPT-4

**å­˜å‚¨**ï¼š
- ChromaDB (è®°å¿†)
- PostgreSQL (ä¼šè¯)

**å‰ç«¯**ï¼š
- Streamlit

---

## ğŸ’» æ ¸å¿ƒå®ç°

### 1. å·¥å…·å®šä¹‰

```python
# tools/research_tools.py
import requests
import arxiv
from typing import List, Dict
import re

class ArXivSearchTool:
    """ArXivè®ºæ–‡æœç´¢å·¥å…·"""

    def __init__(self):
        self.base_url = "http://export.arxiv.org/api/query?"

    def search(self, query: str, max_results: int = 10) -> List[Dict]:
        """
        æœç´¢ArXivè®ºæ–‡

        Args:
            query: æœç´¢æŸ¥è¯¢
            max_results: æœ€å¤§ç»“æœæ•°

        Returns:
            è®ºæ–‡åˆ—è¡¨
        """
        # ä½¿ç”¨arxivåº“
        search = arxiv.Search(
            query=query,
            max_results=max_results,
            sort_by=arxiv.SortCriterion.Relevance
        )

        results = []
        for result in search.results():
            paper = {
                'title': result.title,
                'authors': [a.name for a in result.authors],
                'summary': result.summary.replace('\n', ' '),
                'published': result.published.strftime('%Y-%m-%d'),
                'url': result.entry_id,
                'pdf_url': result.pdf_url,
                'primary_category': result.primary_category
            }
            results.append(paper)

        return results

    def get_paper_details(self, paper_id: str) -> Dict:
        """è·å–è®ºæ–‡è¯¦æƒ…"""
        search = arxiv.Search(id_list=[paper_id])
        result = next(search.results())

        return {
            'title': result.title,
            'abstract': result.summary,
            'authors': [a.name for a in result.authors],
            'categories': result.categories,
            'pdf_url': result.pdf_url
        }


class GitHubSearchTool:
    """GitHubä»£ç æœç´¢å·¥å…·"""

    def __init__(self, token: str = None):
        self.token = token
        self.base_url = "https://api.github.com"

    def search_repositories(self,
                           query: str,
                           sort: str = "stars",
                           per_page: int = 10) -> List[Dict]:
        """
        æœç´¢GitHubä»“åº“

        Args:
            query: æœç´¢æŸ¥è¯¢
            sort: æ’åºæ–¹å¼ (stars, forks, updated)
            per_page: æ¯é¡µç»“æœæ•°

        Returns:
            ä»“åº“åˆ—è¡¨
        """
        url = f"{self.base_url}/search/repositories"
        params = {
            'q': query,
            'sort': sort,
            'per_page': per_page
        }

        headers = {}
        if self.token:
            headers['Authorization'] = f"token {self.token}"

        response = requests.get(url, params=params, headers=headers)
        response.raise_for_status()

        data = response.json()
        results = []

        for item in data['items']:
            repo = {
                'name': item['name'],
                'full_name': item['full_name'],
                'description': item['description'],
                'url': item['html_url'],
                'stars': item['stargazers_count'],
                'language': item['language'],
                'updated_at': item['updated_at']
            }
            results.append(repo)

        return results

    def search_code(self,
                   query: str,
                   language: str = None) -> List[Dict]:
        """
        æœç´¢ä»£ç 

        Args:
            query: ä»£ç æŸ¥è¯¢
            language: ç¼–ç¨‹è¯­è¨€

        Returns:
            ä»£ç ç‰‡æ®µåˆ—è¡¨
        """
        url = f"{self.base_url}/search/code"
        q = query
        if language:
            q += f" language:{language}"

        params = {'q': q, 'per_page': 10}
        headers = {}
        if self.token:
            headers['Authorization'] = f"token {self.token}"

        response = requests.get(url, params=params, headers=headers)
        response.raise_for_status()

        data = response.json()
        return data.get('items', [])


class PaperAnalysisTool:
    """è®ºæ–‡åˆ†æå·¥å…·"""

    def __init__(self, llm_client):
        self.llm = llm_client

    def extract_key_points(self, paper: Dict) -> Dict:
        """
        æå–è®ºæ–‡å…³é”®ç‚¹

        Args:
            paper: è®ºæ–‡ä¿¡æ¯

        Returns:
            å…³é”®ç‚¹æå–ç»“æœ
        """
        prompt = f"""åˆ†æä»¥ä¸‹è®ºæ–‡ï¼Œæå–å…³é”®ä¿¡æ¯ï¼š

æ ‡é¢˜: {paper['title']}
æ‘˜è¦: {paper['summary']}

è¯·æå–ï¼š
1. ç ”ç©¶é—®é¢˜
2. æ ¸å¿ƒæ–¹æ³•
3. ä¸»è¦è´¡çŒ®
4. å®éªŒç»“æœ

ä»¥JSONæ ¼å¼è¿”å›ã€‚"""

        response = self.llm.generate(prompt)

        # è§£æLLMå“åº”ï¼ˆå®é™…éœ€è¦æ›´robustçš„è§£æï¼‰
        try:
            import json
            return json.loads(response)
        except:
            return {
                'research_question': 'å¾…æå–',
                'core_method': 'å¾…æå–',
                'contributions': 'å¾…æå–',
                'results': 'å¾…æå–'
            }

    def compare_papers(self,
                      papers: List[Dict]) -> str:
        """
        å¯¹æ¯”å¤šç¯‡è®ºæ–‡

        Args:
            papers: è®ºæ–‡åˆ—è¡¨

        Returns:
            å¯¹æ¯”åˆ†ææ–‡æœ¬
        """
        prompt = f"""å¯¹æ¯”ä»¥ä¸‹{len(papers)}ç¯‡è®ºæ–‡ï¼š

"""
        for i, paper in enumerate(papers, 1):
            prompt += f"\nè®ºæ–‡{i}: {paper['title']}\n"
            prompt += f"æ‘˜è¦: {paper['summary'][:200]}...\n"

        prompt += """
è¯·ä»ä»¥ä¸‹æ–¹é¢è¿›è¡Œå¯¹æ¯”ï¼š
1. æ–¹æ³•å¯¹æ¯”
2. æ€§èƒ½å¯¹æ¯”
3. ä¼˜ç¼ºç‚¹åˆ†æ
4. é€‚ç”¨åœºæ™¯

ç”Ÿæˆç»“æ„åŒ–çš„å¯¹æ¯”åˆ†æã€‚"""

        return self.llm.generate(prompt)


class CodeGenerationTool:
    """ä»£ç ç”Ÿæˆå·¥å…·"""

    def __init__(self, llm_client):
        self.llm = llm_client

    def implement_paper(self,
                       paper: Dict,
                       language: str = "Python") -> str:
        """
        æ ¹æ®è®ºæ–‡å®ç°ä»£ç 

        Args:
            paper: è®ºæ–‡ä¿¡æ¯
            language: ç¼–ç¨‹è¯­è¨€

        Returns:
            ç”Ÿæˆçš„ä»£ç 
        """
        prompt = f"""åŸºäºä»¥ä¸‹è®ºæ–‡ç”Ÿæˆ{language}ä»£ç å®ç°ï¼š

è®ºæ–‡æ ‡é¢˜: {paper['title']}
æ ¸å¿ƒæ–¹æ³•: {paper['summary'][:500]}

è¦æ±‚ï¼š
1. å®ç°æ ¸å¿ƒç®—æ³•
2. æ·»åŠ è¯¦ç»†æ³¨é‡Š
3. åŒ…å«ä½¿ç”¨ç¤ºä¾‹
4. è€ƒè™‘è¾¹ç•Œæƒ…å†µ

ç”Ÿæˆå®Œæ•´å¯è¿è¡Œçš„ä»£ç ã€‚"""

        return self.llm.generate(prompt)

    def explain_code(self,
                    code: str,
                    language: str = "Python") -> str:
        """
        è§£é‡Šä»£ç 

        Args:
            code: ä»£ç ç‰‡æ®µ
            language: ç¼–ç¨‹è¯­è¨€

        Returns:
            ä»£ç è§£é‡Š
        """
        prompt = f"""è¯¦ç»†è§£é‡Šä»¥ä¸‹{language}ä»£ç ï¼š

```{language}
{code}
```

è¯·è¯´æ˜ï¼š
1. ä»£ç åŠŸèƒ½
2. ç®—æ³•åŸç†
3. å…³é”®æ­¥éª¤
4. æ—¶é—´å¤æ‚åº¦
5. å¯èƒ½çš„ä¼˜åŒ–"""

        return self.llm.generate(prompt)
```

### 2. ReAct Agentå®ç°

```python
# agent/research_agent.py
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_openai import ChatOpenAI
from langchain.tools import Tool
from langchain import hub
from typing import List, Dict, Optional
import json

class ResearchAgent:
    """
    AIç ”ç©¶åŠ©æ‰‹Agent

    ä½¿ç”¨ReActæ¨¡å¼è‡ªä¸»å®Œæˆç ”ç©¶ä»»åŠ¡
    """

    def __init__(self,
                 openai_api_key: str,
                 github_token: str = None):
        # åˆå§‹åŒ–LLM
        self.llm = ChatOpenAI(
            model="gpt-4",
            temperature=0.3,
            openai_api_key=openai_api_key
        )

        # åˆå§‹åŒ–å·¥å…·
        self.tools = self._create_tools(github_token)

        # åˆ›å»ºAgent
        self.agent = self._create_agent()

        # è®°å¿†
        self.memory = []

    def _create_tools(self, github_token: str) -> List[Tool]:
        """åˆ›å»ºå·¥å…·é›†"""

        # ArXivæœç´¢
        arxiv_tool = ArXivSearchTool()

        # GitHubæœç´¢
        github_tool = GitHubSearchTool(token=github_token)

        # è®ºæ–‡åˆ†æ
        paper_analysis = PaperAnalysisTool(self.llm)

        # ä»£ç ç”Ÿæˆ
        code_gen = CodeGenerationTool(self.llm)

        tools = [
            Tool(
                name="ArXivSearch",
                func=lambda q: json.dumps(
                    arxiv_tool.search(q, max_results=5),
                    ensure_ascii=False,
                    indent=2
                ),
                description="""æœç´¢ArXivå­¦æœ¯è®ºæ–‡ã€‚
                è¾“å…¥ï¼šæœç´¢æŸ¥è¯¢ï¼Œä¾‹å¦‚'transformer architecture'
                è¾“å‡ºï¼šç›¸å…³è®ºæ–‡åˆ—è¡¨ï¼ˆåŒ…å«æ ‡é¢˜ã€ä½œè€…ã€æ‘˜è¦ã€é“¾æ¥ï¼‰"""
            ),
            Tool(
                name="GitHubSearch",
                func=lambda q: json.dumps(
                    github_tool.search_repositories(q),
                    ensure_ascii=False,
                    indent=2
                ),
                description="""æœç´¢GitHubä»£ç ä»“åº“ã€‚
                è¾“å…¥ï¼šæœç´¢æŸ¥è¯¢ï¼Œä¾‹å¦‚'RAG implementation'
                è¾“å‡ºï¼šç›¸å…³ä»“åº“åˆ—è¡¨ï¼ˆåŒ…å«åç§°ã€æè¿°ã€æ˜Ÿæ ‡æ•°ã€é“¾æ¥ï¼‰"""
            ),
            Tool(
                name="AnalyzePaper",
                func=lambda p: json.dumps(
                    paper_analysis.extract_key_points(json.loads(p)),
                    ensure_ascii=False
                ),
                description="""åˆ†æè®ºæ–‡å…³é”®ç‚¹ã€‚
                è¾“å…¥ï¼šè®ºæ–‡ä¿¡æ¯JSONï¼ˆåŒ…å«æ ‡é¢˜å’Œæ‘˜è¦ï¼‰
                è¾“å‡ºï¼šå…³é”®ç‚¹æå–ï¼ˆç ”ç©¶é—®é¢˜ã€æ ¸å¿ƒæ–¹æ³•ã€ä¸»è¦è´¡çŒ®ã€å®éªŒç»“æœï¼‰"""
            ),
            Tool(
                name="GenerateCode",
                func=lambda x: code_gen.implement_paper(json.loads(x)),
                description="""æ ¹æ®è®ºæ–‡ç”Ÿæˆä»£ç å®ç°ã€‚
                è¾“å…¥ï¼šè®ºæ–‡ä¿¡æ¯JSON
                è¾“å‡ºï¼šå®Œæ•´ä»£ç å®ç°ï¼ˆå¸¦æ³¨é‡Šï¼‰"""
            ),
            Tool(
                name="ComparePapers",
                func=lambda p: paper_analysis.compare_papers(json.loads(p)),
                description="""å¯¹æ¯”å¤šç¯‡è®ºæ–‡ã€‚
                è¾“å…¥ï¼šè®ºæ–‡åˆ—è¡¨JSON
                è¾“å‡ºï¼šç»“æ„åŒ–å¯¹æ¯”åˆ†æ"""
            )
        ]

        return tools

    def _create_agent(self) -> AgentExecutor:
        """åˆ›å»ºAgent"""

        # è·å–promptæ¨¡æ¿
        prompt = hub.pull("hwchase17/openai-tools-agent")

        # åˆ›å»ºagent
        agent = create_openai_tools_agent(
            self.llm,
            self.tools,
            prompt
        )

        # åˆ›å»ºexecutor
        executor = AgentExecutor(
            agent=agent,
            tools=self.tools,
            verbose=True,
            max_iterations=10,
            handle_parsing_errors=True
        )

        return executor

    def research(self,
                query: str,
                save_report: bool = True) -> Dict:
        """
        æ‰§è¡Œç ”ç©¶ä»»åŠ¡

        Args:
            query: ç ”ç©¶æŸ¥è¯¢
            save_report: æ˜¯å¦ä¿å­˜æŠ¥å‘Š

        Returns:
            ç ”ç©¶ç»“æœ
        """
        print(f"ğŸ”¬ å¼€å§‹ç ”ç©¶ä»»åŠ¡: {query}\n")

        # æ‰§è¡Œagent
        try:
            result = self.agent.invoke({"input": query})

            # ä¿å­˜åˆ°è®°å¿†
            self.memory.append({
                'query': query,
                'result': result['output'],
                'steps': len(result.get('intermediate_steps', []))
            })

            # ç”ŸæˆæŠ¥å‘Š
            if save_report:
                report = self._generate_report(query, result)
                return {
                    'answer': result['output'],
                    'report': report,
                    'steps': result.get('intermediate_steps', [])
                }

            return {
                'answer': result['output'],
                'steps': result.get('intermediate_steps', [])
            }

        except Exception as e:
            return {
                'error': str(e),
                'answer': f"ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            }

    def _generate_report(self,
                        query: str,
                        result: Dict) -> str:
        """ç”Ÿæˆç ”ç©¶æŠ¥å‘Š"""

        report = f"""# ç ”ç©¶æŠ¥å‘Š

## ç ”ç©¶é—®é¢˜
{query}

## ç ”ç©¶è¿‡ç¨‹
"""

        # æ·»åŠ æ­¥éª¤
        steps = result.get('intermediate_steps', [])
        for i, step in enumerate(steps, 1):
            action, observation = step
            report += f"\n### æ­¥éª¤{i}: {action.tool}\n"
            report += f"{action.tool_input}\n\n"
            report += f"**ç»“æœ**: {observation[:200]}...\n\n"

        # æ·»åŠ ç»“è®º
        report += f"\n## ç»“è®º\n\n{result['output']}\n"

        return report
```

### 3. Streamlitç•Œé¢

```python
# app.py
import streamlit as st
from agent.research_agent import ResearchAgent
import json

st.set_page_config(
    page_title="AIç ”ç©¶åŠ©æ‰‹",
    page_icon="ğŸ”¬",
    layout="wide"
)

st.title("ğŸ”¬ AIç ”ç©¶åŠ©æ‰‹Agent")
st.markdown("è‡ªä¸»æœç´¢ã€åˆ†æå’Œæ€»ç»“æŠ€æœ¯æ–‡çŒ®")

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("é…ç½®")

    api_key = st.text_input("OpenAI API Key", type="password")
    github_token = st.text_input("GitHub Token (å¯é€‰)", type="password")

    st.divider()

    st.subheader("ç ”ç©¶æ¨¡æ¿")
    templates = [
        "å¯¹æ¯”ä¸åŒRAGä¼˜åŒ–æ–¹æ³•",
        "æŸ¥æ‰¾Transformeræœ€æ–°è¿›å±•",
        "åˆ†æå¤šæ¨¡æ€å­¦ä¹ æŠ€æœ¯",
        "ç ”ç©¶å›¾ç¥ç»ç½‘ç»œåº”ç”¨"
    ]

    for template in templates:
        if st.button(template, key=template):
            st.session_state.query = template

# ä¸»ç•Œé¢
col1, col2 = st.columns([2, 1])

with col1:
    query = st.text_area(
        "ç ”ç©¶é—®é¢˜",
        placeholder="ä¾‹å¦‚ï¼šå¯¹æ¯”RAGçš„ä¸åŒä¼˜åŒ–æ–¹æ³•ï¼ŒåŒ…æ‹¬æ··åˆæ£€ç´¢ã€é‡æ’åºã€æŸ¥è¯¢ä¼˜åŒ–ç­‰",
        height=100,
        key="query_input"
    )

    col_btn1, col_btn2 = st.columns(2)

    with col_btn1:
        research_button = st.button("ğŸš€ å¼€å§‹ç ”ç©¶", type="primary")

    with col_btn2:
        if st.button("ğŸ’¾ æŸ¥çœ‹å†å²"):
            st.session_state.show_history = not st.session_state.get('show_history', False)

# æ˜¾ç¤ºå†å²
if st.session_state.get('show_history', False):
    st.subheader("ğŸ“š ç ”ç©¶å†å²")
    if 'agent' in st.session_state and st.session_state.agent.memory:
        for i, item in enumerate(st.session_state.agent.memory[-5:], 1):
            with st.expander(f"{i}. {item['query']}", expanded=False):
                st.write(f"**æ­¥éª¤æ•°**: {item['steps']}")
                st.write(f"**ç»“æœ**:\n{item['answer'][:300]}...")
    else:
        st.info("æš‚æ— ç ”ç©¶å†å²")

# æ‰§è¡Œç ”ç©¶
if research_button and query:
    if not api_key:
        st.error("è¯·è¾“å…¥OpenAI API Key")
    else:
        # åˆå§‹åŒ–agent
        if 'agent' not in st.session_state or st.session_state.get('last_api_key') != api_key:
            st.session_state.agent = ResearchAgent(
                openai_api_key=api_key,
                github_token=github_token or None
            )
            st.session_state.last_api_key = api_key

        # åˆ›å»ºè¿›åº¦å®¹å™¨
        progress_container = st.container()

        with progress_container:
            st.info("ğŸ¤– Agentæ­£åœ¨ç ”ç©¶ä¸­...")

            # æ‰§è¡Œç ”ç©¶
            result = st.session_state.agent.research(query)

            # æ˜¾ç¤ºç»“æœ
            if 'error' in result:
                st.error(f"âŒ {result['error']}")
            else:
                st.success("âœ… ç ”ç©¶å®Œæˆï¼")

                # æ˜¾ç¤ºç­”æ¡ˆ
                st.subheader("ğŸ“ ç ”ç©¶ç»“è®º")
                st.write(result['answer'])

                # æ˜¾ç¤ºæ­¥éª¤
                if 'steps' in result and result['steps']:
                    with st.expander("ğŸ” æŸ¥çœ‹ç ”ç©¶æ­¥éª¤", expanded=False):
                        for i, (action, observation) in enumerate(result['steps'], 1):
                            st.markdown(f"**æ­¥éª¤{i}**: `{action.tool}`")
                            st.code(action.tool_input, language="text")
                            st.text(observation[:500] + "..." if len(observation) > 500 else observation)
                            st.divider()

                # ä¸‹è½½æŠ¥å‘Š
                if 'report' in result:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½ç ”ç©¶æŠ¥å‘Š",
                        data=result['report'],
                        file_name=f"research_report_{hash(query)}.md",
                        mime="text/markdown"
                    )
```

---

## ğŸ“Š ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šæŠ€æœ¯å¯¹æ¯”ç ”ç©¶

```python
# ç¤ºä¾‹ï¼šç ”ç©¶æŸ¥è¯¢
query = """
å¯¹æ¯”RAGçš„ä¸åŒä¼˜åŒ–æ–¹æ³•ï¼ŒåŒ…æ‹¬ï¼š
1. æ··åˆæ£€ç´¢ï¼ˆVector + BM25ï¼‰
2. é‡æ’åºï¼ˆCrossEncoderï¼‰
3. æŸ¥è¯¢ä¼˜åŒ–ï¼ˆHyDE, Query Expansionï¼‰
4. æ™ºèƒ½åˆ†å—

è¯·åˆ†ææ¯ç§æ–¹æ³•çš„åŸç†ã€ä¼˜ç¼ºç‚¹ã€é€‚ç”¨åœºæ™¯å’Œæ€§èƒ½æå‡ã€‚
"""

# æ‰§è¡Œç ”ç©¶
agent = ResearchAgent(openai_api_key="your-key")
result = agent.research(query)

print(result['answer'])
```

### ç¤ºä¾‹2ï¼šè®ºæ–‡è¿½è¸ª

```python
query = """
æŸ¥æ‰¾2024å¹´å¤§æ¨¡å‹æ¨ç†ä¼˜åŒ–æŠ€æœ¯çš„æœ€æ–°è®ºæ–‡ï¼Œé‡ç‚¹å…³æ³¨ï¼š
1. æ¨ç†åŠ é€Ÿæ–¹æ³•
2. é‡åŒ–æŠ€æœ¯
3. KV Cacheä¼˜åŒ–
4. å¹¶è¡Œç­–ç•¥

è¯·æ€»ç»“æ ¸å¿ƒæ–¹æ³•å’Œæ€§èƒ½æå‡ã€‚
"""

result = agent.research(query)
```

### ç¤ºä¾‹3ï¼šä»£ç å®ç°

```python
query = """
ç ”ç©¶GraphRAGæŠ€æœ¯ï¼Œå¹¶ï¼š
1. æŸ¥æ‰¾ç›¸å…³è®ºæ–‡
2. æœç´¢GitHubå®ç°
3. ç”ŸæˆPythonä»£ç ç¤ºä¾‹
4. åˆ†æä¸ä¼ ç»ŸRAGçš„ä¼˜åŠ£åŠ¿
"""

result = agent.research(query)
```

---

## ğŸ§ª è¯„ä¼°

### Agentæ€§èƒ½è¯„ä¼°

```python
# evaluation.py
class AgentEvaluator:
    """Agentè¯„ä¼°å™¨"""

    def __init__(self, agent):
        self.agent = agent

    def evaluate_research_quality(self,
                                 query: str,
                                 ground_truth: Dict) -> Dict:
        """
        è¯„ä¼°ç ”ç©¶è´¨é‡

        Args:
            query: ç ”ç©¶æŸ¥è¯¢
            ground_truth: æ ‡å‡†ç­”æ¡ˆ

        Returns:
            è¯„ä¼°æŒ‡æ ‡
        """
        result = self.agent.research(query, save_report=False)

        metrics = {}

        # 1. å®Œæ•´æ€§ï¼ˆæ˜¯å¦è¦†ç›–å…³é”®ç‚¹ï¼‰
        required_points = ground_truth.get('key_points', [])
        covered_points = sum(
            1 for point in required_points
            if point.lower() in result['answer'].lower()
        )
        metrics['completeness'] = covered_points / len(required_points) if required_points else 0

        # 2. å‡†ç¡®æ€§ï¼ˆä¸æ ‡å‡†ç­”æ¡ˆçš„ä¸€è‡´æ€§ï¼‰
        # è¿™é‡Œå¯ä»¥ä½¿ç”¨LLMæ¥è¯„ä¼°
        metrics['accuracy'] = self._llm_evaluate_accuracy(
            result['answer'],
            ground_truth.get('answer', '')
        )

        # 3. å·¥å…·ä½¿ç”¨æ•ˆç‡
        steps = result.get('steps', [])
        metrics['tool_efficiency'] = len(steps)

        # 4. æ¨ç†æ·±åº¦
        metrics['reasoning_depth'] = self._analyze_reasoning_depth(steps)

        return metrics

    def _llm_evaluate_accuracy(self,
                              generated: str,
                              reference: str) -> float:
        """ä½¿ç”¨LLMè¯„ä¼°å‡†ç¡®æ€§"""
        prompt = f"""è¯„ä¼°ä»¥ä¸‹ç­”æ¡ˆçš„å‡†ç¡®æ€§ï¼ˆ0-1åˆ†ï¼‰ï¼š

ç”Ÿæˆç­”æ¡ˆ: {generated}

å‚è€ƒç­”æ¡ˆ: {reference}

è¯·ç»™å‡º0-1ä¹‹é—´çš„åˆ†æ•°ï¼Œä¿ç•™ä¸¤ä½å°æ•°ã€‚åªè¿”å›åˆ†æ•°ã€‚"""

        response = self.agent.llm.predict(prompt)

        try:
            return float(response.strip())
        except:
            return 0.5  # é»˜è®¤åˆ†æ•°
```

---

## ğŸ“ å­¦ä¹ è¦ç‚¹

å®Œæˆæœ¬æ¡ˆä¾‹åï¼Œä½ å°†æŒæ¡ï¼š

### âœ… Agentå¼€å‘
- ReActæ¨¡å¼å®ç°
- å·¥å…·å®šä¹‰å’Œé›†æˆ
- å¤šæ­¥æ¨ç†è§„åˆ’
- è‡ªä¸»ä»»åŠ¡æ‰§è¡Œ

### âœ… APIé›†æˆ
- ArXiv API
- GitHub API
- LLM APIè°ƒç”¨
- é”™è¯¯å¤„ç†

### âœ… ç ”ç©¶æµç¨‹
- æ–‡çŒ®æ£€ç´¢
- å†…å®¹åˆ†æ
- å¯¹æ¯”ç ”ç©¶
- æŠ¥å‘Šç”Ÿæˆ

### âœ… ç³»ç»Ÿè®¾è®¡
- Agentæ¶æ„è®¾è®¡
- å·¥å…·æŠ½è±¡
- è®°å¿†ç®¡ç†
- æ€§èƒ½ä¼˜åŒ–

---

## ğŸš€ è¿›é˜¶æ–¹å‘

1. **é«˜çº§å·¥å…·**
   - Webçˆ¬è™«ï¼ˆGoogle Scholarï¼‰
   - PDFè§£æï¼ˆarXiv PDFï¼‰
   - ä»£ç æ‰§è¡Œï¼ˆæ²™ç®±ï¼‰
   - å¯è§†åŒ–ç”Ÿæˆ

2. **å¤šAgentåä½œ**
   - ä¸“é—¨æœç´¢Agent
   - åˆ†æAgent
   - å†™ä½œAgent
   - Manageråè°ƒ

3. **çŸ¥è¯†åº“æ„å»º**
   - å‘é‡åŒ–è®ºæ–‡
   - è¯­ä¹‰æ£€ç´¢
   - å¼•ç”¨ç½‘ç»œ
   - è¶‹åŠ¿åˆ†æ

---

## ğŸ“š å‚è€ƒèµ„æº

- [ReActè®ºæ–‡](https://arxiv.org/abs/2210.03629)
- [LangChain Agents](https://python.langchain.com/docs/modules/agents/)
- [ArXiv API](http://export.arxiv.org/api_help/)
- [GitHub API](https://docs.github.com/en/rest)

---

**å¼€å§‹æ„å»ºä½ çš„AIç ”ç©¶åŠ©æ‰‹å§ï¼** ğŸš€
