{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬6ç« ï¼šåµŒå…¥æ¨¡å‹æ·±å…¥\n",
    "\n",
    "> åµŒå…¥æ¨¡å‹æ˜¯RAGç³»ç»Ÿçš„\"ç†è§£åŸºç¡€\"ã€‚é€‰æ‹©åˆé€‚çš„åµŒå…¥æ¨¡å‹å¯ä»¥å°†æ£€ç´¢è´¨é‡æå‡10-15%ã€‚\n",
    "\n",
    "## ğŸ“š å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "æœ¬Notebookå°†å¸¦ä½ ï¼š\n",
    "- âœ… ç†è§£TransformeråµŒå…¥æ¨¡å‹çš„åŸç†\n",
    "- âœ… å¯¹æ¯”ä¸»æµåµŒå…¥æ¨¡å‹çš„æ€§èƒ½\n",
    "- âœ… æŒæ¡æ¨¡å‹é€‰æ‹©æ–¹æ³•\n",
    "- âœ… å®ç°åµŒå…¥æ¨¡å‹è¯„ä¼°\n",
    "- âœ… å®æˆ˜åº”ç”¨åœºæ™¯\n",
    "\n",
    "## é¢„è®¡æ—¶é—´\n",
    "\n",
    "- åµŒå…¥æ¨¡å‹åŸç†ï¼š40åˆ†é’Ÿ\n",
    "- ä¸»æµæ¨¡å‹å¯¹æ¯”ï¼š40åˆ†é’Ÿ\n",
    "- æ¨¡å‹è¯„ä¼°ï¼š40åˆ†é’Ÿ\n",
    "- å®æˆ˜åº”ç”¨ï¼š30åˆ†é’Ÿ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "from pathlib import Path\n",
    "\n",
    "# æ£€æŸ¥ç¯å¢ƒ\n",
    "print(\"æ£€æŸ¥ç¯å¢ƒ...\")\n",
    "print(f\"NumPyç‰ˆæœ¬: {np.__version__}\")\n",
    "\n",
    "# æ¨¡æ‹Ÿsentence-transformersï¼ˆå¦‚æœæœªå®‰è£…ï¼‰\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    print(\"âœ… sentence-transformerså·²å®‰è£…\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸  sentence-transformersæœªå®‰è£…\")\n",
    "    print(\"   è¯·è¿è¡Œ: pip install sentence-transformers\")\n",
    "    print(\"   å°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¼”ç¤º\")\n",
    "\n",
    "print(\"\\nç¯å¢ƒå‡†å¤‡å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. åµŒå…¥æ¨¡å‹åŸç†\n",
    "\n",
    "### 2.1 ä»æ–‡æœ¬åˆ°å‘é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¼”ç¤ºï¼šæ–‡æœ¬åˆ°å‘é‡çš„è½¬æ¢\n",
    "\n",
    "class SimpleEmbeddingModel:\n",
    "    \"\"\"\n",
    "    ç®€åŒ–çš„åµŒå…¥æ¨¡å‹ï¼ˆç”¨äºæ¼”ç¤ºï¼‰\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim: int = 768):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        # æ¨¡æ‹Ÿï¼šä¸ºå¸¸è§è¯é¢„è®¾å‘é‡\n",
    "        self.word_vectors = {\n",
    "            \"è‹¹æœ\": np.random.randn(embedding_dim) * 0.1 + np.array([0.5] * embedding_dim),\n",
    "            \"é¦™è•‰\": np.random.randn(embedding_dim) * 0.1 + np.array([0.5] * embedding_dim),\n",
    "            \"ç”µè„‘\": np.random.randn(embedding_dim) * 0.1 + np.array([-0.5] * embedding_dim),\n",
    "        }\n",
    "    \n",
    "    def encode(self, text: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        å°†æ–‡æœ¬ç¼–ç ä¸ºå‘é‡\n",
    "        \"\"\"\n",
    "        # ç®€åŒ–å®ç°ï¼šæŸ¥æ‰¾è¯å‘é‡ï¼Œå¦åˆ™éšæœºç”Ÿæˆ\n",
    "        for word in self.word_vectors:\n",
    "            if word in text:\n",
    "                return self.word_vectors[word]\n",
    "        \n",
    "        # é»˜è®¤è¿”å›éšæœºå‘é‡\n",
    "        return np.random.randn(self.embedding_dim)\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹\n",
    "model = SimpleEmbeddingModel(embedding_dim=128)\n",
    "\n",
    "print(\"åµŒå…¥æ¨¡å‹æ¼”ç¤ºï¼š\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# ç¼–ç ç¤ºä¾‹æ–‡æœ¬\n",
    "texts = [\"è‹¹æœ\", \"é¦™è•‰\", \"ç”µè„‘\"]\n",
    "embeddings = {text: model.encode(text) for text in texts}\n",
    "\n",
    "for text, emb in embeddings.items():\n",
    "    print(f\"\\næ–‡æœ¬: '{text}'\")\n",
    "    print(f\"å‘é‡ç»´åº¦: {emb.shape}\")\n",
    "    print(f\"å‘é‡å‰5ç»´: {emb[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 è®¡ç®—å‘é‡ç›¸ä¼¼åº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦\n",
    "    \n",
    "    Args:\n",
    "        vec1, vec2: å‘é‡\n",
    "    \n",
    "    Returns:\n",
    "        ç›¸ä¼¼åº¦åˆ†æ•° (0-1)\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "# è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ\n",
    "print(\"ç›¸ä¼¼åº¦çŸ©é˜µï¼š\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'æ–‡æœ¬':<10} {'è‹¹æœ':<10} {'é¦™è•‰':<10} {'ç”µè„‘':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for text1 in texts:\n",
    "    row = [text1]\n",
    "    for text2 in texts:\n",
    "        sim = cosine_similarity(embeddings[text1], embeddings[text2])\n",
    "        row.append(f\"{sim:.3f}\")\n",
    "    print(f\"{row[0]:<10} {row[1]:<10} {row[2]:<10} {row[3]:<10}\")\n",
    "\n",
    "print(\"\\nè§‚å¯Ÿï¼š\")\n",
    "print(\"- 'è‹¹æœ' å’Œ 'é¦™è•‰' ç›¸ä¼¼åº¦é«˜ï¼ˆéƒ½æ˜¯æ°´æœï¼‰\")\n",
    "print(\"- 'ç”µè„‘' ä¸å…¶ä»–ç›¸ä¼¼åº¦ä½ï¼ˆä¸åŒç±»åˆ«ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ä¸»æµåµŒå…¥æ¨¡å‹å¯¹æ¯”\n",
    "\n",
    "### 3.1 æ¨¡å‹æ€§èƒ½å¯¹æ¯”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸»æµåµŒå…¥æ¨¡å‹å¯¹æ¯”è¡¨\n",
    "models_comparison = [\n",
    "    {\n",
    "        \"name\": \"all-MiniLM-L6-v2\",\n",
    "        \"dim\": 384,\n",
    "        \"speed\": \"å¿«\",\n",
    "        \"quality\": \"ä¸­\",\n",
    "        \"size\": \"80MB\",\n",
    "        \"use_case\": \"å¿«é€Ÿæ£€ç´¢ã€èµ„æºå—é™\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"all-mpnet-base-v2\",\n",
    "        \"dim\": 768,\n",
    "        \"speed\": \"ä¸­\",\n",
    "        \"quality\": \"é«˜\",\n",
    "        \"size\": \"420MB\",\n",
    "        \"use_case\": \"é«˜è´¨é‡æ£€ç´¢\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"bge-large-zh-v1.5\",\n",
    "        \"dim\": 1024,\n",
    "        \"speed\": \"ä¸­\",\n",
    "        \"quality\": \"é«˜ï¼ˆä¸­æ–‡ï¼‰\",\n",
    "        \"size\": \"1.34GB\",\n",
    "        \"use_case\": \"ä¸­æ–‡é«˜è´¨é‡æ£€ç´¢\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"e5-large-v2\",\n",
    "        \"dim\": 1024,\n",
    "        \"speed\": \"ä¸­\",\n",
    "        \"quality\": \"é«˜\",\n",
    "        \"size\": \"1.34GB\",\n",
    "        \"use_case\": \"å¤šè¯­è¨€æ£€ç´¢\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"text-embedding-3-small\",\n",
    "        \"dim\": 1536,\n",
    "        \"speed\": \"APIè°ƒç”¨\",\n",
    "        \"quality\": \"å¾ˆé«˜\",\n",
    "        \"size\": \"-\",\n",
    "        \"use_case\": \"ç”Ÿäº§ç¯å¢ƒï¼ˆOpenAIï¼‰\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"ä¸»æµåµŒå…¥æ¨¡å‹å¯¹æ¯”ï¼š\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"{'æ¨¡å‹åç§°':<25} {'ç»´åº¦':<8} {'é€Ÿåº¦':<8} {'è´¨é‡':<10} {'å¤§å°':<10} {'é€‚ç”¨åœºæ™¯':<20}\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for model in models_comparison:\n",
    "    print(f\"{model['name']:<25} {model['dim']:<8} {model['speed']:<8} \"\n",
    "          f\"{model['quality']:<10} {model['size']:<10} {model['use_case']:<20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 æ¨¡å‹é€‰æ‹©å†³ç­–æ ‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_embedding_model(\n",
    "    language: str = \"zh\",\n",
    "    quality_priority: bool = False,\n",
    "    resource_limited: bool = False,\n",
    "    use_api: bool = False\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    æ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„åµŒå…¥æ¨¡å‹\n",
    "    \n",
    "    Args:\n",
    "        language: ä¸»è¦è¯­è¨€ (zh/en/multi)\n",
    "        quality_priority: æ˜¯å¦ä¼˜å…ˆè´¨é‡\n",
    "        resource_limited: èµ„æºæ˜¯å¦å—é™\n",
    "        use_api: æ˜¯å¦ä½¿ç”¨API\n",
    "    \n",
    "    Returns:\n",
    "        æ¨èçš„æ¨¡å‹åç§°\n",
    "    \"\"\"\n",
    "    if use_api:\n",
    "        return \"text-embedding-3-small (OpenAI)\"\n",
    "    \n",
    "    if language == \"zh\":\n",
    "        if resource_limited:\n",
    "            return \"bge-small-zh-v1.5\"\n",
    "        elif quality_priority:\n",
    "            return \"bge-large-zh-v1.5\"\n",
    "        else:\n",
    "            return \"bge-base-zh-v1.5\"\n",
    "    \n",
    "    elif language == \"en\":\n",
    "        if resource_limited:\n",
    "            return \"all-MiniLM-L6-v2\"\n",
    "        elif quality_priority:\n",
    "            return \"all-mpnet-base-v2\"\n",
    "        else:\n",
    "            return \"all-MiniLM-L12-v2\"\n",
    "    \n",
    "    else:  # å¤šè¯­è¨€\n",
    "        if quality_priority:\n",
    "            return \"e5-large-v2\"\n",
    "        else:\n",
    "            return \"e5-base-v2\"\n",
    "\n",
    "# æµ‹è¯•é€‰æ‹©å‡½æ•°\n",
    "print(\"æ¨¡å‹é€‰æ‹©ç¤ºä¾‹ï¼š\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "scenarios = [\n",
    "    {\"language\": \"zh\", \"quality_priority\": True, \"resource_limited\": False},\n",
    "    {\"language\": \"en\", \"quality_priority\": False, \"resource_limited\": True},\n",
    "    {\"language\": \"multi\", \"quality_priority\": True, \"resource_limited\": False},\n",
    "]\n",
    "\n",
    "for i, scenario in enumerate(scenarios, 1):\n",
    "    model = choose_embedding_model(**scenario)\n",
    "    print(f\"\\nåœºæ™¯{i}: {scenario}\")\n",
    "    print(f\"æ¨è: {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. åµŒå…¥è´¨é‡è¯„ä¼°\n",
    "\n",
    "### 4.1 è¯„ä¼°æŒ‡æ ‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingEvaluator:\n",
    "    \"\"\"\n",
    "    åµŒå…¥è´¨é‡è¯„ä¼°å™¨\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def evaluate_retrieval(\n",
    "        self,\n",
    "        queries: List[str],\n",
    "        documents: List[str],\n",
    "        relevant_docs: List[List[int]],\n",
    "        top_k: int = 5\n",
    "    ) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        è¯„ä¼°æ£€ç´¢è´¨é‡\n",
    "        \n",
    "        Args:\n",
    "            queries: æŸ¥è¯¢åˆ—è¡¨\n",
    "            documents: æ–‡æ¡£åˆ—è¡¨\n",
    "            relevant_docs: æ¯ä¸ªæŸ¥è¯¢çš„ç›¸å…³æ–‡æ¡£ç´¢å¼•\n",
    "            top_k: æ£€ç´¢top-k\n",
    "        \n",
    "        Returns:\n",
    "            è¯„ä¼°æŒ‡æ ‡\n",
    "        \"\"\"\n",
    "        # ç¼–ç æ‰€æœ‰æ–‡æ¡£\n",
    "        doc_embeddings = [self.model.encode(doc) for doc in documents]\n",
    "        \n",
    "        hit_count = 0\n",
    "        mrr_scores = []\n",
    "        \n",
    "        for query, relevant in zip(queries, relevant_docs):\n",
    "            # ç¼–ç æŸ¥è¯¢\n",
    "            query_emb = self.model.encode(query)\n",
    "            \n",
    "            # è®¡ç®—ç›¸ä¼¼åº¦\n",
    "            similarities = [\n",
    "                cosine_similarity(query_emb, doc_emb)\n",
    "                for doc_emb in doc_embeddings\n",
    "            ]\n",
    "            \n",
    "            # è·å–top-k\n",
    "            top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "            \n",
    "            # Hit Rate\n",
    "            if any(idx in relevant for idx in top_indices):\n",
    "                hit_count += 1\n",
    "            \n",
    "            # MRR\n",
    "            for rank, idx in enumerate(top_indices, 1):\n",
    "                if idx in relevant:\n",
    "                    mrr_scores.append(1.0 / rank)\n",
    "                    break\n",
    "            else:\n",
    "                mrr_scores.append(0.0)\n",
    "        \n",
    "        return {\n",
    "            \"hit_rate\": hit_count / len(queries),\n",
    "            \"mrr\": np.mean(mrr_scores),\n",
    "            \"num_queries\": len(queries)\n",
    "        }\n",
    "\n",
    "# åˆ›å»ºè¯„ä¼°å™¨\n",
    "evaluator = EmbeddingEvaluator(model)\n",
    "\n",
    "# æµ‹è¯•æ•°æ®\n",
    "test_queries = [\n",
    "    \"è‹¹æœå¥½åƒå—\",\n",
    "    \"ç”µè„‘é…ç½®\",\n",
    "]\n",
    "\n",
    "test_docs = [\n",
    "    \"è‹¹æœæ˜¯ä¸€ç§æ°´æœï¼Œå‘³é“ç”œç¾\",\n",
    "    \"ç”µè„‘æ˜¯ä¸€ç§ç”µå­è®¾å¤‡\",\n",
    "    \"é¦™è•‰ä¹Ÿæ˜¯æ°´æœ\",\n",
    "]\n",
    "\n",
    "test_relevant = [\n",
    "    [0],  # ç¬¬ä¸€ä¸ªæŸ¥è¯¢ç›¸å…³æ–‡æ¡£\n",
    "    [1],  # ç¬¬äºŒä¸ªæŸ¥è¯¢ç›¸å…³æ–‡æ¡£\n",
    "]\n",
    "\n",
    "# è¯„ä¼°\n",
    "results = evaluator.evaluate_retrieval(\n",
    "    queries=test_queries,\n",
    "    documents=test_docs,\n",
    "    relevant_docs=test_relevant\n",
    ")\n",
    "\n",
    "print(\"è¯„ä¼°ç»“æœï¼š\")\n",
    "print(f\"-\" * 30)\n",
    "for metric, value in results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{metric}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å®æˆ˜åº”ç”¨\n",
    "\n",
    "### 5.1 æ–‡æ¡£æ£€ç´¢ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentRetriever:\n",
    "    \"\"\"\n",
    "    åŸºäºåµŒå…¥çš„æ–‡æ¡£æ£€ç´¢ç³»ç»Ÿ\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.documents = []\n",
    "        self.embeddings = []\n",
    "    \n",
    "    def add_documents(self, docs: List[str]):\n",
    "        \"\"\"\n",
    "        æ·»åŠ æ–‡æ¡£åˆ°ç´¢å¼•\n",
    "        \"\"\"\n",
    "        self.documents.extend(docs)\n",
    "        for doc in docs:\n",
    "            emb = self.model.encode(doc)\n",
    "            self.embeddings.append(emb)\n",
    "    \n",
    "    def retrieve(self, query: str, top_k: int = 3) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        æ£€ç´¢ç›¸å…³æ–‡æ¡£\n",
    "        \"\"\"\n",
    "        query_emb = self.model.encode(query)\n",
    "        \n",
    "        # è®¡ç®—ç›¸ä¼¼åº¦\n",
    "        similarities = [\n",
    "            cosine_similarity(query_emb, doc_emb)\n",
    "            for doc_emb in self.embeddings\n",
    "        ]\n",
    "        \n",
    "        # æ’åº\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            results.append({\n",
    "                \"document\": self.documents[idx],\n",
    "                \"score\": similarities[idx],\n",
    "                \"index\": idx\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "\n",
    "# åˆ›å»ºæ£€ç´¢ç³»ç»Ÿ\n",
    "retriever = DocumentRetriever(model)\n",
    "\n",
    "# æ·»åŠ æ–‡æ¡£\n",
    "docs = [\n",
    "    \"æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯\",\n",
    "    \"æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œ\",\n",
    "    \"Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€\",\n",
    "    \"è‹¹æœå…¬å¸ç”Ÿäº§iPhone\",\n",
    "]\n",
    "retriever.add_documents(docs)\n",
    "\n",
    "# æµ‹è¯•æ£€ç´¢\n",
    "test_queries = [\n",
    "    \"ä»€ä¹ˆæ˜¯AI\",\n",
    "    \"ç¼–ç¨‹è¯­è¨€\",\n",
    "    \"æ™ºèƒ½æ‰‹æœº\",\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\næŸ¥è¯¢: {query}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    results = retriever.retrieve(query, top_k=2)\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"\\nç»“æœ {i} (ç›¸å…³åº¦: {result['score']:.3f}):\")\n",
    "        print(f\"  {result['document']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ç»ƒä¹ \n",
    "\n",
    "### ç»ƒä¹ 1ï¼šæ¨¡å‹å¯¹æ¯”\n",
    "\n",
    "å°è¯•ä½¿ç”¨ä¸åŒçš„åµŒå…¥æ¨¡å‹ï¼ˆå¦‚æœæœ‰sentence-transformersï¼‰ï¼Œå¯¹æ¯”å®ƒä»¬åœ¨ç›¸åŒæ•°æ®é›†ä¸Šçš„è¡¨ç°ã€‚\n",
    "\n",
    "**æç¤º**ï¼š\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# åŠ è½½ä¸åŒæ¨¡å‹\n",
    "model1 = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model2 = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "# å¯¹æ¯”æ€§èƒ½...\n",
    "```\n",
    "\n",
    "### ç»ƒä¹ 2ï¼šä¼˜åŒ–æ£€ç´¢\n",
    "\n",
    "æ”¹è¿›DocumentRetrieverç±»ï¼Œæ·»åŠ ä»¥ä¸‹åŠŸèƒ½ï¼š\n",
    "- ç¼“å­˜åµŒå…¥å‘é‡\n",
    "- æ‰¹é‡ç¼–ç \n",
    "- ç»“æœè¿‡æ»¤é˜ˆå€¼\n",
    "\n",
    "### ç»ƒä¹ 3ï¼šå¤šè¯­è¨€æ£€ç´¢\n",
    "\n",
    "ä½¿ç”¨å¤šè¯­è¨€åµŒå…¥æ¨¡å‹ï¼ˆå¦‚e5ï¼‰ï¼Œå®ç°è·¨è¯­è¨€æ£€ç´¢åŠŸèƒ½ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. æ€»ç»“\n",
    "\n",
    "### å…³é”®è¦ç‚¹\n",
    "\n",
    "1. **åµŒå…¥æ¨¡å‹åŸç†**ï¼šå°†æ–‡æœ¬æ˜ å°„åˆ°å‘é‡ç©ºé—´\n",
    "2. **ç›¸ä¼¼åº¦è®¡ç®—**ï¼šä½™å¼¦ç›¸ä¼¼åº¦æ˜¯æœ€å¸¸ç”¨çš„æ–¹æ³•\n",
    "3. **æ¨¡å‹é€‰æ‹©**ï¼šæ ¹æ®è¯­è¨€ã€è´¨é‡ã€èµ„æºéœ€æ±‚é€‰æ‹©\n",
    "4. **è´¨é‡è¯„ä¼°**ï¼šHit Rateã€MRRç­‰æŒ‡æ ‡\n",
    "5. **å®æˆ˜åº”ç”¨**ï¼šæ–‡æ¡£æ£€ç´¢ç³»ç»Ÿ\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "\n",
    "- ç¬¬7ç« ï¼šé«˜çº§åˆ†å—ç­–ç•¥\n",
    "- å­¦ä¹ å¦‚ä½•ä¼˜åŒ–æ–‡æ¡£åˆ†å—\n",
    "\n",
    "---\n",
    "\n",
    "**æ­å–œå®Œæˆç¬¬6ç« çš„å­¦ä¹ ï¼** ğŸ‰\n",
    "\n",
    "ä½ å·²ç»æŒæ¡äº†åµŒå…¥æ¨¡å‹çš„æ ¸å¿ƒçŸ¥è¯†ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mernelspec": {
    "display_name": "Python 3",
    "language": "python",
    "name": "python3"
   },
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
