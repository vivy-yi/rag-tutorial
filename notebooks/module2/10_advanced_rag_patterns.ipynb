{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬10ç« ï¼šé«˜çº§RAGæ¨¡å¼\n",
    "\n",
    "> åŸºç¡€RAGä¸å¤Ÿç”¨ï¼Ÿé«˜çº§RAGæ¨¡å¼è®©ç³»ç»Ÿ\"æ€è€ƒ\"ä½•æ—¶æ£€ç´¢ã€æ£€ç´¢ä»€ä¹ˆã€æ£€ç´¢å¤šå°‘ï¼Œæ˜¾è‘—æå‡å¤æ‚é—®é¢˜çš„å¤„ç†èƒ½åŠ›ï¼\n",
    "\n",
    "## ğŸ“š å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "æœ¬Notebookå°†å¸¦ä½ ï¼š\n",
    "- âœ… ç†è§£è¿­ä»£æ£€ç´¢çš„åŸç†å’Œåº”ç”¨åœºæ™¯\n",
    "- âœ… æŒæ¡è‡ªé€‚åº”æ£€ç´¢çš„å®ç°æ–¹æ³•\n",
    "- âœ… åº”ç”¨è·³è·ƒè¯»å–ï¼ˆSkip Readingï¼‰ç­–ç•¥\n",
    "- âœ… ä½¿ç”¨å…ƒæ•°æ®è¿‡æ»¤ä¼˜åŒ–æ£€ç´¢\n",
    "- âœ… å®æˆ˜åº”ç”¨é«˜çº§RAGæ¨¡å¼\n",
    "\n",
    "## é¢„è®¡æ—¶é—´\n",
    "\n",
    "- RAGæ¨¡å¼æ¼”è¿›ï¼š30åˆ†é’Ÿ\n",
    "- è¿­ä»£æ£€ç´¢ï¼š50åˆ†é’Ÿ\n",
    "- è‡ªé€‚åº”æ£€ç´¢ï¼š50åˆ†é’Ÿ\n",
    "- å…¶ä»–é«˜çº§æ¨¡å¼ï¼š40åˆ†é’Ÿ\n",
    "- å®æˆ˜åº”ç”¨ï¼š30åˆ†é’Ÿ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "print(\"æ£€æŸ¥ç¯å¢ƒ...\")\n",
    "print(f\"NumPyç‰ˆæœ¬: {np.__version__}\")\n",
    "print(\"\\nç¯å¢ƒå‡†å¤‡å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RAGæ¨¡å¼æ¼”è¿›\n",
    "\n",
    "### 2.1 ä»Naiveåˆ°Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAGæ¨¡å¼å¯¹æ¯”\n",
    "rag_levels = [\n",
    "    {\n",
    "        \"level\": \"Level 1: Naive RAG\",\n",
    "        \"features\": [\"ä¸€æ¬¡æ£€ç´¢\", \"ä¸€æ¬¡ç”Ÿæˆ\"],\n",
    "        \"use_case\": \"ç®€å•é—®ç­”\",\n",
    "        \"module\": \"æ¨¡å—1\"\n",
    "    },\n",
    "    {\n",
    "        \"level\": \"Level 2: RAG + ä¼˜åŒ–\",\n",
    "        \"features\": [\"æ›´å¥½çš„åµŒå…¥æ¨¡å‹\", \"é«˜çº§åˆ†å—\", \"æŸ¥è¯¢å¢å¼º\", \"æ··åˆæ£€ç´¢+é‡æ’åº\"],\n",
    "        \"use_case\": \"ä¸­ç­‰å¤æ‚åº¦é—®ç­”\",\n",
    "        \"module\": \"æ¨¡å—2\"\n",
    "    },\n",
    "    {\n",
    "        \"level\": \"Level 3: Advanced RAG\",\n",
    "        \"features\": [\"è¿­ä»£æ£€ç´¢\", \"è‡ªé€‚åº”æ£€ç´¢\", \"è·³è·ƒè¯»å–\", \"å…ƒæ•°æ®è¿‡æ»¤\"],\n",
    "        \"use_case\": \"å¤æ‚å¤šè·³é—®ç­”\",\n",
    "        \"module\": \"æœ¬ç« \"\n",
    "    },\n",
    "    {\n",
    "        \"level\": \"Level 4: Agentic RAG\",\n",
    "        \"features\": [\"Agentè‡ªä¸»å†³ç­–\", \"å·¥å…·è°ƒç”¨\", \"å¤šAgentåä½œ\"],\n",
    "        \"use_case\": \"é«˜åº¦å¤æ‚ä»»åŠ¡\",\n",
    "        \"module\": \"æ¨¡å—3\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"RAGæ¨¡å¼æ¼”è¿›è·¯å¾„ï¼š\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for rag in rag_levels:\n",
    "    print(f\"\\n{rag['level']} ({rag['module']}):\")\n",
    "    print(f\"  ç‰¹æ€§: {', '.join(rag['features'])}\")\n",
    "    print(f\"  é€‚ç”¨åœºæ™¯: {rag['use_case']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. è¿­ä»£æ£€ç´¢\n",
    "\n",
    "### 3.1 åŸç†\n",
    "\n",
    "**è¿­ä»£æ£€ç´¢**ï¼šå¤šæ¬¡æ£€ç´¢ï¼Œæ¯æ¬¡åŸºäºå‰ä¸€æ¬¡çš„ç»“æœã€‚\n",
    "\n",
    "```\n",
    "æŸ¥è¯¢: \"é©¬æ–¯å…‹çš„ç«ç®­å…¬å¸æœ€è¿‘ä¸€æ¬¡å‘å°„æ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿ\"\n",
    "\n",
    "ç¬¬1æ¬¡æ£€ç´¢: \"é©¬æ–¯å…‹ç«ç®­å…¬å¸\"\n",
    "  â†’ ç»“æœ: \"SpaceXæ˜¯é©¬æ–¯å…‹çš„å¤ªç©ºæ¢ç´¢å…¬å¸\"\n",
    "\n",
    "ç¬¬2æ¬¡æ£€ç´¢: \"SpaceXæœ€è¿‘ä¸€æ¬¡å‘å°„\"\n",
    "  â†’ ç»“æœ: \"SpaceXäº2024å¹´1æœˆå‘å°„äº†...\"\n",
    "\n",
    "æœ€ç»ˆç­”æ¡ˆ: åŸºäºä¸¤æ¬¡æ£€ç´¢çš„ç»“æœç”Ÿæˆ\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Document:\n",
    "    \"\"\"\n",
    "    æ–‡æ¡£\n",
    "    \"\"\"\n",
    "    content: str\n",
    "    metadata: Dict[str, Any]\n",
    "\n",
    "class IterativeRetriever:\n",
    "    \"\"\"\n",
    "    è¿­ä»£æ£€ç´¢å™¨\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_iterations: int = 3):\n",
    "        self.max_iterations = max_iterations\n",
    "        self.knowledge_base = []\n",
    "    \n",
    "    def add_documents(self, docs: List[Document]):\n",
    "        self.knowledge_base = docs\n",
    "    \n",
    "    def retrieve(self, query: str, top_k: int = 2) -> List[Document]:\n",
    "        \"\"\"\n",
    "        ç®€åŒ–çš„æ£€ç´¢ï¼ˆå…³é”®è¯åŒ¹é…ï¼‰\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        for doc in self.knowledge_base:\n",
    "            # ç®€å•çš„å…³é”®è¯åŒ¹é…\n",
    "            score = sum(1 for word in query_lower.split() if word in doc.content.lower())\n",
    "            if score > 0:\n",
    "                results.append((doc, score))\n",
    "        \n",
    "        # æ’åºå¹¶è¿”å›top-k\n",
    "        results.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [doc for doc, _ in results[:top_k]]\n",
    "\n",
    "class IterativeRAG:\n",
    "    \"\"\"\n",
    "    è¿­ä»£RAGç³»ç»Ÿ\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, retriever: IterativeRetriever):\n",
    "        self.retriever = retriever\n",
    "    \n",
    "    def query(self, initial_query: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        è¿­ä»£æŸ¥è¯¢\n",
    "        \"\"\"\n",
    "        current_query = initial_query\n",
    "        all_retrieved = []\n",
    "        iterations = []\n",
    "        \n",
    "        for i in range(self.retriever.max_iterations):\n",
    "            print(f\"\\nç¬¬{i+1}æ¬¡è¿­ä»£æŸ¥è¯¢: {current_query}\")\n",
    "            \n",
    "            # æ£€ç´¢\n",
    "            docs = self.retriever.retrieve(current_query)\n",
    "            \n",
    "            if not docs:\n",
    "                print(\"æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼Œåœæ­¢è¿­ä»£\")\n",
    "                break\n",
    "            \n",
    "            all_retrieved.extend(docs)\n",
    "            \n",
    "            iteration_info = {\n",
    "                \"iteration\": i + 1,\n",
    "                \"query\": current_query,\n",
    "                \"docs\": [d.content[:50] + \"...\" for d in docs]\n",
    "            }\n",
    "            iterations.append(iteration_info)\n",
    "            \n",
    "            # ç®€åŒ–ï¼šç”Ÿæˆä¸‹ä¸€ä¸ªæŸ¥è¯¢ï¼ˆåŸºäºç¬¬ä¸€ä¸ªæ–‡æ¡£çš„å…³é”®ä¿¡æ¯ï¼‰\n",
    "            if i < self.retriever.max_iterations - 1:\n",
    "                # å®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨LLMç”Ÿæˆä¸‹ä¸€ä¸ªæŸ¥è¯¢\n",
    "                current_query = self._generate_next_query(current_query, docs)\n",
    "                \n",
    "                if current_query is None:\n",
    "                    print(\"å·²è·å¾—è¶³å¤Ÿä¿¡æ¯ï¼Œåœæ­¢è¿­ä»£\")\n",
    "                    break\n",
    "        \n",
    "        return {\n",
    "            \"initial_query\": initial_query,\n",
    "            \"iterations\": iterations,\n",
    "            \"all_documents\": all_retrieved,\n",
    "            \"num_iterations\": len(iterations)\n",
    "        }\n",
    "    \n",
    "    def _generate_next_query(self, current_query: str, docs: List[Document]) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆä¸‹ä¸€ä¸ªæŸ¥è¯¢\n",
    "        \"\"\"\n",
    "        # ç®€åŒ–å®ç°ï¼šåŸºäºè§„åˆ™\n",
    "        # å®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨LLM\n",
    "        \n",
    "        for doc in docs:\n",
    "            content = doc.content.lower()\n",
    "            \n",
    "            # å¦‚æœæ‰¾åˆ°æ›´å…·ä½“çš„å®ä½“ï¼Œç”Ÿæˆæ–°æŸ¥è¯¢\n",
    "            if \"spacex\" in content and \"spacex\" not in current_query.lower():\n",
    "                return \"SpaceXæœ€è¿‘ä¸€æ¬¡å‘å°„\"\n",
    "            \n",
    "            if \"openai\" in content and \"openai\" not in current_query.lower():\n",
    "                return \"OpenAIæœ€æ–°äº§å“\"\n",
    "        \n",
    "        return None\n",
    "\n",
    "# æµ‹è¯•è¿­ä»£æ£€ç´¢\n",
    "# åˆ›å»ºçŸ¥è¯†åº“\n",
    "docs = [\n",
    "    Document(\"SpaceXæ˜¯åŸƒéš†Â·é©¬æ–¯å…‹åˆ›ç«‹çš„å¤ªç©ºæ¢ç´¢æŠ€æœ¯å…¬å¸\", {\"source\": \"doc1\", \"entity\": \"SpaceX\"}),\n",
    "    Document(\"SpaceXäº2024å¹´1æœˆæˆåŠŸå‘å°„äº†æ˜Ÿèˆ°ç³»ç»Ÿ\", {\"source\": \"doc2\", \"entity\": \"SpaceX\"}),\n",
    "    Document(\"OpenAIæ˜¯ä¸€å®¶äººå·¥æ™ºèƒ½ç ”ç©¶å…¬å¸\", {\"source\": \"doc3\", \"entity\": \"OpenAI\"}),\n",
    "    Document(\"OpenAIå‘å¸ƒäº†GPT-4 Turboæ¨¡å‹\", {\"source\": \"doc4\", \"entity\": \"OpenAI\"}),\n",
    "]\n",
    "\n",
    "retriever = IterativeRetriever(max_iterations=3)\n",
    "retriever.add_documents(docs)\n",
    "\n",
    "iterative_rag = IterativeRAG(retriever)\n",
    "\n",
    "# æµ‹è¯•æŸ¥è¯¢\n",
    "query = \"é©¬æ–¯å…‹çš„ç«ç®­å…¬å¸æœ€è¿‘ä¸€æ¬¡å‘å°„æ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿ\"\n",
    "\n",
    "print(\"\\nè¿­ä»£æ£€ç´¢ç¤ºä¾‹ï¼š\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nåˆå§‹æŸ¥è¯¢: {query}\")\n",
    "\n",
    "result = iterative_rag.query(query)\n",
    "\n",
    "print(f\"\\n\\næ£€ç´¢ç»“æœæ±‡æ€»ï¼š\")\n",
    "print(f\"-\" * 60)\n",
    "print(f\"è¿­ä»£æ¬¡æ•°: {result['num_iterations']}\")\n",
    "print(f\"æ£€ç´¢åˆ°çš„æ–‡æ¡£æ•°: {len(result['all_documents'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. è‡ªé€‚åº”æ£€ç´¢\n",
    "\n",
    "### 4.1 åŸç†\n",
    "\n",
    "**è‡ªé€‚åº”æ£€ç´¢**ï¼šæ ¹æ®æŸ¥è¯¢å¤æ‚åº¦åŠ¨æ€è°ƒæ•´æ£€ç´¢ç­–ç•¥ã€‚\n",
    "\n",
    "```\n",
    "ç®€å•æŸ¥è¯¢ â†’ å°‘é‡æ–‡æ¡£ + åŸºç¡€æ£€ç´¢\n",
    "å¤æ‚æŸ¥è¯¢ â†’ å¤§é‡æ–‡æ¡£ + é«˜çº§æ£€ç´¢ + é‡æ’åº\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveRAG:\n",
    "    \"\"\"\n",
    "    è‡ªé€‚åº”RAGç³»ç»Ÿ\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, retriever: IterativeRetriever):\n",
    "        self.retriever = retriever\n",
    "    \n",
    "    def assess_complexity(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        è¯„ä¼°æŸ¥è¯¢å¤æ‚åº¦\n",
    "        \n",
    "        Returns:\n",
    "            'simple', 'medium', æˆ– 'complex'\n",
    "        \"\"\"\n",
    "        # ç®€åŒ–å®ç°ï¼šåŸºäºè§„åˆ™\n",
    "        \n",
    "        # å¤æ‚æŸ¥è¯¢çš„ç‰¹å¾\n",
    "        complex_indicators = [\n",
    "            \"æ¯”è¾ƒ\", \"å¯¹æ¯”\", \"å·®å¼‚\",  # æ¯”è¾ƒç±»\n",
    "            \"ä¸ºä»€ä¹ˆ\", \"åŸå› \", \"å¦‚ä½•\" + \"å’Œ\",  # å¤šè·³\n",
    "            \"æœ€è¿‘\", \"æœ€æ–°\", \"æœ€æ–°ä¸€æ¬¡\",  # æ—¶åº\n",
    "        ]\n",
    "        \n",
    "        complexity_score = sum(1 for indicator in complex_indicators if indicator in query)\n",
    "        \n",
    "        if complexity_score >= 2:\n",
    "            return \"complex\"\n",
    "        elif complexity_score == 1:\n",
    "            return \"medium\"\n",
    "        else:\n",
    "            return \"simple\"\n",
    "    \n",
    "    def query(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        è‡ªé€‚åº”æŸ¥è¯¢\n",
    "        \"\"\"\n",
    "        complexity = self.assess_complexity(query)\n",
    "        \n",
    "        print(f\"\\næŸ¥è¯¢å¤æ‚åº¦è¯„ä¼°: {complexity}\")\n",
    "        \n",
    "        # æ ¹æ®å¤æ‚åº¦é€‰æ‹©ç­–ç•¥\n",
    "        if complexity == \"simple\":\n",
    "            top_k = 2\n",
    "            use_reranking = False\n",
    "        elif complexity == \"medium\":\n",
    "            top_k = 4\n",
    "            use_reranking = True\n",
    "        else:  # complex\n",
    "            top_k = 6\n",
    "            use_reranking = True\n",
    "            # å¯¹äºå¤æ‚æŸ¥è¯¢ï¼Œå¯èƒ½éœ€è¦è¿­ä»£æ£€ç´¢\n",
    "            result = self._complex_query(query)\n",
    "            return result\n",
    "        \n",
    "        # æ‰§è¡Œæ£€ç´¢\n",
    "        docs = self.retriever.retrieve(query, top_k=top_k)\n",
    "        \n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"complexity\": complexity,\n",
    "            \"top_k\": top_k,\n",
    "            \"use_reranking\": use_reranking,\n",
    "            \"retrieved_docs\": [d.content for d in docs],\n",
    "            \"num_docs\": len(docs)\n",
    "        }\n",
    "    \n",
    "    def _complex_query(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        å¤„ç†å¤æ‚æŸ¥è¯¢ï¼ˆä½¿ç”¨è¿­ä»£æ£€ç´¢ï¼‰\n",
    "        \"\"\"\n",
    "        iterative_rag = IterativeRAG(self.retriever)\n",
    "        result = iterative_rag.query(query)\n",
    "        result[\"complexity\"] = \"complex\"\n",
    "        result[\"strategy\"] = \"iterative\"\n",
    "        return result\n",
    "\n",
    "# æµ‹è¯•è‡ªé€‚åº”æ£€ç´¢\n",
    "adaptive_rag = AdaptiveRAG(retriever)\n",
    "\n",
    "# æµ‹è¯•ä¸åŒå¤æ‚åº¦çš„æŸ¥è¯¢\n",
    "test_queries = [\n",
    "    \"ä»€ä¹ˆæ˜¯SpaceX\",  # simple\n",
    "    \"SpaceXæœ€è¿‘ä¸€æ¬¡å‘å°„\",  # medium\n",
    "    \"æ¯”è¾ƒSpaceXå’ŒBlue Originçš„å·®å¼‚\",  # complex\n",
    "]\n",
    "\n",
    "print(\"\\nè‡ªé€‚åº”æ£€ç´¢ç¤ºä¾‹ï¼š\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\næŸ¥è¯¢: {query}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    result = adaptive_rag.query(query)\n",
    "    \n",
    "    if result.get(\"strategy\") == \"iterative\":\n",
    "        print(f\"ç­–ç•¥: è¿­ä»£æ£€ç´¢\")\n",
    "        print(f\"è¿­ä»£æ¬¡æ•°: {result['num_iterations']}\")\n",
    "    else:\n",
    "        print(f\"ç­–ç•¥: å•æ¬¡æ£€ç´¢\")\n",
    "        print(f\"æ£€ç´¢å‚æ•°: top_k={result['top_k']}, reranking={result['use_reranking']}\")\n",
    "        print(f\"æ£€ç´¢æ–‡æ¡£æ•°: {result['num_docs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å…ƒæ•°æ®è¿‡æ»¤\n",
    "\n",
    "### 5.1 åŸç†\n",
    "\n",
    "**å…ƒæ•°æ®è¿‡æ»¤**ï¼šåˆ©ç”¨æ–‡æ¡£çš„å…ƒä¿¡æ¯ï¼ˆæ—¥æœŸã€ç±»åˆ«ã€ä½œè€…ç­‰ï¼‰ä¼˜åŒ–æ£€ç´¢ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetadataFilteredRetriever:\n",
    "    \"\"\"\n",
    "    æ”¯æŒå…ƒæ•°æ®è¿‡æ»¤çš„æ£€ç´¢å™¨\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.documents = []\n",
    "    \n",
    "    def add_documents(self, docs: List[Document]):\n",
    "        self.documents = docs\n",
    "    \n",
    "    def retrieve(\n",
    "        self,\n",
    "        query: str,\n",
    "        top_k: int = 3,\n",
    "        filters: Dict[str, Any] = None\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"\n",
    "        å¸¦å…ƒæ•°æ®è¿‡æ»¤çš„æ£€ç´¢\n",
    "        \n",
    "        Args:\n",
    "            query: æŸ¥è¯¢\n",
    "            top_k: è¿”å›æ•°é‡\n",
    "            filters: å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶\n",
    "        \"\"\"\n",
    "        # é¦–å…ˆåº”ç”¨å…ƒæ•°æ®è¿‡æ»¤\n",
    "        filtered_docs = self.documents\n",
    "        \n",
    "        if filters:\n",
    "            filtered_docs = [\n",
    "                doc for doc in self.documents\n",
    "                if all(\n",
    "                    doc.metadata.get(key) == value\n",
    "                    for key, value in filters.items()\n",
    "                )\n",
    "            ]\n",
    "        \n",
    "        # ç„¶åè¿›è¡Œè¯­ä¹‰æ£€ç´¢\n",
    "        query_lower = query.lower()\n",
    "        results = []\n",
    "        \n",
    "        for doc in filtered_docs:\n",
    "            score = sum(1 for word in query_lower.split() if word in doc.content.lower())\n",
    "            if score > 0:\n",
    "                results.append((doc, score))\n",
    "        \n",
    "        # æ’åº\n",
    "        results.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [doc for doc, _ in results[:top_k]]\n",
    "\n",
    "# æµ‹è¯•å…ƒæ•°æ®è¿‡æ»¤\n",
    "# åˆ›å»ºå¸¦å…ƒæ•°æ®çš„æ–‡æ¡£\n",
    "docs_with_metadata = [\n",
    "    Document(\"Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€\", {\"category\": \"programming\", \"year\": 2023}),\n",
    "    Document(\"Python 3.12å‘å¸ƒäº†æ–°ç‰¹æ€§\", {\"category\": \"programming\", \"year\": 2024}),\n",
    "    Document(\"JavaScriptä¹Ÿæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€\", {\"category\": \"programming\", \"year\": 2023}),\n",
    "    Document(\"AIæŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•\", {\"category\": \"ai\", \"year\": 2024}),\n",
    "]\n",
    "\n",
    "filtered_retriever = MetadataFilteredRetriever()\n",
    "filtered_retriever.add_documents(docs_with_metadata)\n",
    "\n",
    "print(\"\\nå…ƒæ•°æ®è¿‡æ»¤ç¤ºä¾‹ï¼š\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# æµ‹è¯•æŸ¥è¯¢\n",
    "query = \"Python\"\n",
    "\n",
    "# æ— è¿‡æ»¤\n",
    "print(f\"\\næŸ¥è¯¢: {query} (æ— è¿‡æ»¤)\")\n",
    "results = filtered_retriever.retrieve(query, top_k=3)\n",
    "for doc in results:\n",
    "    print(f\"  - {doc.content} (å¹´ä»½: {doc.metadata.get('year']})\")\n",
    "\n",
    "# æœ‰è¿‡æ»¤ï¼šåªè·å–2024å¹´çš„\n",
    "print(f\"\\næŸ¥è¯¢: {query} (å¹´ä»½=2024)\")\n",
    "results = filtered_retriever.retrieve(query, top_k=3, filters={\"year\": 2024})\n",
    "for doc in results:\n",
    "    print(f\"  - {doc.content} (å¹´ä»½: {doc.metadata.get('year']})\")\n",
    "\n",
    "# æœ‰è¿‡æ»¤ï¼šåªè·å–AIç±»åˆ«çš„\n",
    "print(f\"\\næŸ¥è¯¢: {query} (ç±»åˆ«=ai)\")\n",
    "results = filtered_retriever.retrieve(query, top_k=3, filters={\"category\": \"ai\"})\n",
    "for doc in results:\n",
    "    print(f\"  - {doc.content} (ç±»åˆ«: {doc.metadata.get('category'])\")\n",
    "    if not results:\n",
    "        print(\"  (æ— ç»“æœ)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ç»ƒä¹ \n",
    "\n",
    "### ç»ƒä¹ 1ï¼šæ”¹è¿›è¿­ä»£æ£€ç´¢\n",
    "\n",
    "å½“å‰çš„è¿­ä»£æ£€ç´¢ä½¿ç”¨ç®€å•çš„è§„åˆ™ç”Ÿæˆä¸‹ä¸€ä¸ªæŸ¥è¯¢ã€‚å°è¯•æ”¹è¿›å®ƒï¼š\n",
    "- ä½¿ç”¨LLMç”Ÿæˆä¸‹ä¸€ä¸ªæŸ¥è¯¢\n",
    "- æ·»åŠ åœæ­¢æ¡ä»¶ï¼ˆä¾‹å¦‚ï¼šä¿¡æ¯è¶³å¤Ÿï¼‰\n",
    "- è®°å½•æ¨ç†é“¾è·¯\n",
    "\n",
    "### ç»ƒä¹ 2ï¼šæ™ºèƒ½å¤æ‚åº¦è¯„ä¼°\n",
    "\n",
    "æ”¹è¿›æŸ¥è¯¢å¤æ‚åº¦è¯„ä¼°å™¨ï¼š\n",
    "- ä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹\n",
    "- è€ƒè™‘æŸ¥è¯¢é•¿åº¦ã€å…³é”®è¯æ•°é‡\n",
    "- åŠ¨æ€è°ƒæ•´top_k\n",
    "\n",
    "### ç»ƒä¹ 3ï¼šç»„åˆå¤šç§ç­–ç•¥\n",
    "\n",
    "å®ç°ä¸€ä¸ªç»„åˆç³»ç»Ÿï¼Œæ ¹æ®åœºæ™¯é€‰æ‹©ï¼š\n",
    "- è¿­ä»£æ£€ç´¢\n",
    "- è‡ªé€‚åº”æ£€ç´¢\n",
    "- å…ƒæ•°æ®è¿‡æ»¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. æ€»ç»“\n",
    "\n",
    "### å…³é”®è¦ç‚¹\n",
    "\n",
    "1. **RAGæ¨¡å¼æ¼”è¿›**ï¼šä»Naiveåˆ°Advancedåˆ°Agentic\n",
    "2. **è¿­ä»£æ£€ç´¢**ï¼šå¤šæ¬¡æ£€ç´¢ï¼Œé€æ­¥ç»†åŒ–\n",
    "3. **è‡ªé€‚åº”æ£€ç´¢**ï¼šæ ¹æ®å¤æ‚åº¦åŠ¨æ€è°ƒæ•´\n",
    "4. **å…ƒæ•°æ®è¿‡æ»¤**ï¼šåˆ©ç”¨æ–‡æ¡£ç»“æ„åŒ–ä¿¡æ¯\n",
    "5. **ç»„åˆä½¿ç”¨**ï¼šå¤šç§æ¨¡å¼ç»„åˆæ•ˆæœæœ€ä½³\n",
    "\n",
    "### æ¨¡å¼é€‰æ‹©æŒ‡å—\n",
    "\n",
    "| åœºæ™¯ | æ¨èæ¨¡å¼ |\n",
    "|------|----------|\n",
    "| ç®€å•é—®ç­” | Naive RAG |\n",
    "| å•æ–‡æ¡£æŸ¥è¯¢ | å…ƒæ•°æ®è¿‡æ»¤ |\n",
    "| å¤šè·³æ¨ç† | è¿­ä»£æ£€ç´¢ |\n",
    "| ä¸ç¡®å®šå¤æ‚åº¦ | è‡ªé€‚åº”æ£€ç´¢ |\n",
    "| é«˜åº¦å¤æ‚ | Agentic RAG (æ¨¡å—3) |\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "\n",
    "- ç¬¬11ç« ï¼šæ€§èƒ½ä¼˜åŒ–\n",
    "- å­¦ä¹ å¦‚ä½•ä¼˜åŒ–RAGç³»ç»Ÿæ€§èƒ½\n",
    "\n",
    "---\n",
    "\n",
    "**æ­å–œå®Œæˆç¬¬10ç« çš„å­¦ä¹ ï¼** ğŸ‰\n",
    "\n",
    "ä½ å·²ç»æŒæ¡äº†é«˜çº§RAGæ¨¡å¼ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
