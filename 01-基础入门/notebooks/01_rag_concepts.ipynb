{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬1ç« ï¼šRAGæŠ€æœ¯æ¦‚è¿° - äº’åŠ¨å­¦ä¹ \n",
    "\n",
    "**æœ¬ç« ç›®æ ‡**ï¼š\n",
    "- ç†è§£RAGçš„åŸºæœ¬æ¦‚å¿µå’Œä»·å€¼\n",
    "- æŒæ¡RAGçš„5å¤§æ ¸å¿ƒç»„ä»¶\n",
    "- èƒ½å¤Ÿé€‰æ‹©åˆé€‚çš„æŠ€æœ¯æ ˆ\n",
    "- å¿«é€Ÿä½“éªŒä¸€ä¸ªç®€å•çš„RAGç³»ç»Ÿ\n",
    "\n",
    "**é¢„è®¡æ—¶é—´**ï¼š1.5å°æ—¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 ä»€ä¹ˆæ˜¯RAGï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªç®€å•çš„ä¾‹å­ç†è§£RAG\n",
    "\n",
    "# åœºæ™¯ï¼šä½ æ˜¯ä¸€å®¶å…¬å¸çš„å®¢æœ\n",
    "customer_question = \"å…¬å¸çš„å¹´å‡æ”¿ç­–æ˜¯ä»€ä¹ˆï¼Ÿ\"\n",
    "\n",
    "print(f\"å®¢æˆ·é—®é¢˜: {customer_question}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# æ²¡æœ‰RAGçš„æƒ…å†µ\n",
    "print(\"âŒ ä¼ ç»ŸLLMï¼ˆæ²¡æœ‰RAGï¼‰:\")\n",
    "print(\"   LLMå›ç­”: æˆ‘ä¸çŸ¥é“è´µå…¬å¸çš„å…·ä½“æ”¿ç­–...\")\n",
    "print(\"   é—®é¢˜: LLMä¸çŸ¥é“å…¬å¸å†…éƒ¨ä¿¡æ¯\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# æœ‰RAGçš„æƒ…å†µ\n",
    "print(\"âœ… RAGç³»ç»Ÿ:\")\n",
    "# 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£\n",
    "retrieved_docs = [\n",
    "    \"å‘˜å·¥æ‰‹å†Œç¬¬3ç« ï¼šå¹´å‡è§„å®š\",\n",
    "    \"HRæ”¿ç­–æ–‡æ¡£ï¼šå‘˜å·¥å¯äº«å—15å¤©å¹´å‡\"\n",
    "]\n",
    "print(f\"   æ£€ç´¢åˆ°çš„æ–‡æ¡£: {retrieved_docs}\")\n",
    "# 2. åŸºäºæ–‡æ¡£ç”Ÿæˆç­”æ¡ˆ\n",
    "print(\"   RAGå›ç­”: æ ¹æ®å‘˜å·¥æ‰‹å†Œç¬¬3ç« ï¼Œå‘˜å·¥å¯äº«å—15å¤©å¹´å‡...\")\n",
    "print(\"   ä¼˜åŠ¿: åŸºäºçœŸå®æ–‡æ¡£ï¼Œç­”æ¡ˆå‡†ç¡®å¯é \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç»ƒä¹ 1.1ï¼šRAG vs å…¶ä»–æŠ€æœ¯\n",
    "\n",
    "**é¢˜ç›®**ï¼šåˆ¤æ–­ä»¥ä¸‹åœºæ™¯åº”è¯¥ä½¿ç”¨RAGã€Fine-tuningè¿˜æ˜¯Prompt Engineeringï¼Ÿ\n",
    "\n",
    "1. éœ€è¦AIç”¨ç‰¹å®šæ ¼å¼è¾“å‡ºJSON\n",
    "2. å›ç­”å…¬å¸å†…éƒ¨æ–‡æ¡£çš„é—®é¢˜\n",
    "3. æå‡é€šç”¨é—®ç­”èƒ½åŠ›\n",
    "\n",
    "**ç­”æ¡ˆ**ï¼š\n",
    "- åœºæ™¯1 â†’ Prompt Engineeringï¼ˆæ ¼å¼è¦æ±‚ï¼‰\n",
    "- åœºæ™¯2 â†’ RAGï¼ˆå‡†ç¡®æ€§å’Œå®æ—¶æ€§ï¼‰\n",
    "- åœºæ™¯3 â†’ Fine-tuningï¼ˆè¾“å‡ºè´¨é‡ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 RAGçš„5å¤§æ ¸å¿ƒç»„ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAGç³»ç»Ÿçš„5å¤§æ ¸å¿ƒç»„ä»¶\n",
    "\n",
    "class RAGComponents:\n",
    "    \"\"\"RAGæ ¸å¿ƒç»„ä»¶æ¼”ç¤º\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"åˆå§‹åŒ–RAGç³»ç»Ÿçš„5å¤§æ ¸å¿ƒç»„ä»¶...\\n\")\n",
    "    \n",
    "    def component_1_document_loader(self):\n",
    "        \"\"\"ç»„ä»¶1ï¼šæ–‡æ¡£åŠ è½½å™¨\"\"\"\n",
    "        print(\"ğŸ“„ ç»„ä»¶1ï¼šæ–‡æ¡£åŠ è½½å™¨ (Document Loaders)\")\n",
    "        print(\"   ä½œç”¨: ä»å„ç§æ•°æ®æºåŠ è½½æ–‡æ¡£\")\n",
    "        print(\"   æ”¯æŒæ ¼å¼: PDF, TXT, Word, ç½‘é¡µç­‰\")\n",
    "        print(\"   ç¤ºä¾‹: SimpleDirectoryReader, PyPDFLoader\")\n",
    "        print()\n",
    "    \n",
    "    def component_2_text_splitter(self):\n",
    "        \"\"\"ç»„ä»¶2ï¼šæ–‡æœ¬åˆ†å—å™¨\"\"\"\n",
    "        print(\"âœ‚ï¸  ç»„ä»¶2ï¼šæ–‡æœ¬åˆ†å—å™¨ (Text Splitters)\")\n",
    "        print(\"   ä½œç”¨: å°†é•¿æ–‡æ¡£åˆ‡åˆ†æˆå¯ç®¡ç†çš„å—\")\n",
    "        print(\"   å‚æ•°: chunk_size, chunk_overlap\")\n",
    "        print(\"   ç¤ºä¾‹: SentenceSplitter, RecursiveCharacterTextSplitter\")\n",
    "        print()\n",
    "    \n",
    "    def component_3_embedding_model(self):\n",
    "        \"\"\"ç»„ä»¶3ï¼šåµŒå…¥æ¨¡å‹\"\"\"\n",
    "        print(\"ğŸ”¢ ç»„ä»¶3ï¼šåµŒå…¥æ¨¡å‹ (Embedding Models)\")\n",
    "        print(\"   ä½œç”¨: å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡\")\n",
    "        print(\"   ç¤ºä¾‹: OpenAI embeddings, BGE, E5\")\n",
    "        print(\"   è¾“å‡º: 768/1536ç»´å‘é‡\")\n",
    "        print()\n",
    "    \n",
    "    def component_4_vector_store(self):\n",
    "        \"\"\"ç»„ä»¶4ï¼šå‘é‡æ•°æ®åº“\"\"\"\n",
    "        print(\"ğŸ—„ï¸  ç»„ä»¶4ï¼šå‘é‡æ•°æ®åº“ (Vector Stores)\")\n",
    "        print(\"   ä½œç”¨: å­˜å‚¨å’Œæ£€ç´¢å‘é‡\")\n",
    "        print(\"   ç¤ºä¾‹: Chroma, Qdrant, Milvus\")\n",
    "        print(\"   ç®—æ³•: HNSW, IVF\")\n",
    "        print()\n",
    "    \n",
    "    def component_5_llm(self):\n",
    "        \"\"\"ç»„ä»¶5ï¼šå¤§è¯­è¨€æ¨¡å‹\"\"\"\n",
    "        print(\"ğŸ¤– ç»„ä»¶5ï¼šå¤§è¯­è¨€æ¨¡å‹ (LLMs)\")\n",
    "        print(\"   ä½œç”¨: åŸºäºæ£€ç´¢æ–‡æ¡£ç”Ÿæˆç­”æ¡ˆ\")\n",
    "        print(\"   ç¤ºä¾‹: GPT-4, Claude, Qwen\")\n",
    "        print(\"   å‚æ•°: temperature, max_tokens\")\n",
    "        print()\n",
    "\n",
    "# å±•ç¤ºæ‰€æœ‰ç»„ä»¶\n",
    "rag = RAGComponents()\n",
    "rag.component_1_document_loader()\n",
    "rag.component_2_text_splitter()\n",
    "rag.component_3_embedding_model()\n",
    "rag.component_4_vector_store()\n",
    "rag.component_5_llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç»ƒä¹ 1.2ï¼šç»„ä»¶åŒ¹é…\n",
    "\n",
    "**é¢˜ç›®**ï¼šå°†ä»¥ä¸‹åŠŸèƒ½ä¸å¯¹åº”çš„ç»„ä»¶åŒ¹é…\n",
    "\n",
    "åŠŸèƒ½ â†’ ç»„ä»¶\n",
    "1. å°†PDFè½¬æ¢ä¸ºå¯å¤„ç†çš„æ–‡æœ¬ â†’ ?\n",
    "2. è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦ â†’ ?\n",
    "3. ç”Ÿæˆè‡ªç„¶è¯­è¨€ç­”æ¡ˆ â†’ ?\n",
    "4. å°†é•¿æ–‡æ¡£åˆ‡åˆ† â†’ ?\n",
    "5. å­˜å‚¨ç™¾ä¸‡çº§å‘é‡ â†’ ?\n",
    "\n",
    "**ç­”æ¡ˆ**ï¼š\n",
    "1 â†’ æ–‡æ¡£åŠ è½½å™¨\n",
    "2 â†’ åµŒå…¥æ¨¡å‹\n",
    "3 â†’ LLM\n",
    "4 â†’ æ–‡æœ¬åˆ†å—å™¨\n",
    "5 â†’ å‘é‡æ•°æ®åº“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 ç®€å•RAGç³»ç»Ÿæ¼”ç¤º\n",
    "\n",
    "è®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªæœ€ç®€å•çš„RAGç³»ç»Ÿæ¥ç†è§£å·¥ä½œæµç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç®€å•RAGç³»ç»Ÿæ¼”ç¤ºï¼ˆä¸éœ€è¦çœŸå®APIè°ƒç”¨ï¼‰\n",
    "\n",
    "class SimpleRAGDemo:\n",
    "    \"\"\"ç®€åŒ–çš„RAGç³»ç»Ÿæ¼”ç¤º\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # æ¨¡æ‹ŸçŸ¥è¯†åº“\n",
    "        self.knowledge_base = [\n",
    "            \"Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œç”±Guido van Rossumäº1991å¹´åˆ›å»ºã€‚\",\n",
    "            \"Pythonçš„ç‰¹ç‚¹æ˜¯è¯­æ³•ç®€æ´ã€æ˜“å­¦æ˜“ç”¨ã€‚\",\n",
    "            \"Pythonå¹¿æ³›åº”ç”¨äºWebå¼€å‘ã€æ•°æ®åˆ†æã€äººå·¥æ™ºèƒ½ç­‰é¢†åŸŸã€‚\"\n",
    "        ]\n",
    "    \n",
    "    def retrieve(self, query, top_k=2):\n",
    "        \"\"\"æ­¥éª¤1ï¼šæ£€ç´¢ï¼ˆç®€åŒ–ç‰ˆï¼ŒåŸºäºå…³é”®è¯ï¼‰\"\"\"\n",
    "        print(f\"\\nğŸ” æ­¥éª¤1ï¼šæ£€ç´¢ç›¸å…³æ–‡æ¡£\")\n",
    "        print(f\"   æŸ¥è¯¢: {query}\")\n",
    "        \n",
    "        # ç®€åŒ–çš„å…³é”®è¯åŒ¹é…\n",
    "        scores = []\n",
    "        for i, doc in enumerate(self.knowledge_base):\n",
    "            # è®¡ç®—æŸ¥è¯¢è¯åœ¨æ–‡æ¡£ä¸­å‡ºç°çš„æ¬¡æ•°\n",
    "            score = sum(1 for word in query.lower().split() if word in doc.lower())\n",
    "            scores.append((i, doc, score))\n",
    "            print(f\"   æ–‡æ¡£{i+1} ç›¸å…³åº¦: {score}\")\n",
    "        \n",
    "        # æ’åºå¹¶è¿”å›top_k\n",
    "        scores.sort(key=lambda x: x[2], reverse=True)\n",
    "        retrieved = [doc for i, doc, score in scores[:top_k] if score > 0]\n",
    "        \n",
    "        print(f\"\\n   âœ… æ£€ç´¢åˆ° {len(retrieved)} ä¸ªç›¸å…³æ–‡æ¡£\")\n",
    "        return retrieved\n",
    "    \n",
    "    def generate(self, query, retrieved_docs):\n",
    "        \"\"\"æ­¥éª¤2ï¼šç”Ÿæˆç­”æ¡ˆ\"\"\"\n",
    "        print(f\"\\nğŸ¤– æ­¥éª¤2ï¼šç”Ÿæˆç­”æ¡ˆ\")\n",
    "        \n",
    "        if not retrieved_docs:\n",
    "            return \"æŠ±æ­‰ï¼ŒçŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚\"\n",
    "        \n",
    "        # æ„å»ºä¸Šä¸‹æ–‡\n",
    "        context = \"\\n\".join([f\"- {doc}\" for doc in retrieved_docs])\n",
    "        \n",
    "        # ç®€åŒ–çš„ç­”æ¡ˆç”Ÿæˆï¼ˆå®é™…åº”è¯¥è°ƒç”¨LLMï¼‰\n",
    "        answer = f\"\"\"åŸºäºæ£€ç´¢åˆ°çš„ä¿¡æ¯ï¼š\n",
    "\n",
    "{context}\n",
    "\n",
    "ç­”æ¡ˆæ€»ç»“ï¼š{query}çš„ç›¸å…³ä¿¡æ¯å¦‚ä¸Šæ‰€è¿°ã€‚\"\"\"\n",
    "        \n",
    "        print(f\"   âœ… ç­”æ¡ˆç”Ÿæˆå®Œæˆ\")\n",
    "        return answer\n",
    "    \n",
    "    def query(self, question):\n",
    "        \"\"\"å®Œæ•´çš„æŸ¥è¯¢æµç¨‹\"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(f\"â“ ç”¨æˆ·é—®é¢˜: {question}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # æ£€ç´¢\n",
    "        retrieved = self.retrieve(question)\n",
    "        \n",
    "        # ç”Ÿæˆ\n",
    "        answer = self.generate(question, retrieved)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸ“ æœ€ç»ˆç­”æ¡ˆ:\")\n",
    "        print(answer)\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return answer\n",
    "\n",
    "# æµ‹è¯•ç³»ç»Ÿ\n",
    "demo = SimpleRAGDemo()\n",
    "\n",
    "# æµ‹è¯•é—®é¢˜\n",
    "questions = [\n",
    "    \"Pythonæ˜¯ä»€ä¹ˆï¼Ÿ\",\n",
    "    \"Pythonæœ‰å“ªäº›ç‰¹ç‚¹ï¼Ÿ\",\n",
    "    \"Pythonå¯ä»¥ç”¨æ¥åšä»€ä¹ˆï¼Ÿ\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    demo.query(q)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 æŠ€æœ¯æ ˆé€‰æ‹©ç»ƒä¹ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŠ€æœ¯æ ˆé€‰æ‹©å†³ç­–æ ‘\n",
    "\n",
    "def choose_tech_stack():\n",
    "    \"\"\"äº¤äº’å¼æŠ€æœ¯æ ˆé€‰æ‹©å·¥å…·\"\"\"\n",
    "    \n",
    "    print(\"ğŸ¤” RAGæŠ€æœ¯æ ˆé€‰æ‹©åŠ©æ‰‹\\n\")\n",
    "    \n",
    "    # é—®é¢˜1\n",
    "    deployment = input(\"Q1: éƒ¨ç½²æ–¹å¼? (1.äº‘API  2.ç§æœ‰éƒ¨ç½²): \")\n",
    "    \n",
    "    # é—®é¢˜2\n",
    "    budget = input(\"Q2: é¢„ç®—æƒ…å†µ? (1.æœ‰é¢„ç®—  2.é¢„ç®—æœ‰é™): \")\n",
    "    \n",
    "    # é—®é¢˜3\n",
    "    scale = input(\"Q3: æ•°æ®è§„æ¨¡? (1.<10ä¸‡æ–‡æ¡£  2.>10ä¸‡æ–‡æ¡£): \")\n",
    "    \n",
    "    # æ¨èæ–¹æ¡ˆ\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸ’¡ æ¨èæŠ€æœ¯æ ˆ:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # æ¡†æ¶\n",
    "    print(\"\\nğŸ“¦ æ¡†æ¶: LlamaIndex\")\n",
    "    print(\"   ç†ç”±: ä¸“æ³¨RAGï¼Œæ˜“äºä¸Šæ‰‹\")\n",
    "    \n",
    "    # å‘é‡åº“\n",
    "    if scale == \"1\":\n",
    "        print(\"\\nğŸ—„ï¸  å‘é‡åº“: Chroma\")\n",
    "        print(\"   ç†ç”±: è½»é‡ç®€å•ï¼Œé€‚åˆä¸­å°è§„æ¨¡\")\n",
    "    else:\n",
    "        print(\"\\nğŸ—„ï¸  å‘é‡åº“: Milvus\")\n",
    "        print(\"   ç†ç”±: é«˜æ€§èƒ½å¯æ‰©å±•ï¼Œé€‚åˆå¤§è§„æ¨¡\")\n",
    "    \n",
    "    # LLM\n",
    "    if deployment == \"1\" and budget == \"1\":\n",
    "        print(\"\\nğŸ¤– LLM: GPT-4\")\n",
    "        print(\"   ç†ç”±: è´¨é‡æœ€é«˜ï¼Œé€‚åˆç”Ÿäº§\")\n",
    "    elif deployment == \"1\":\n",
    "        print(\"\\nğŸ¤– LLM: GPT-3.5-turbo\")\n",
    "        print(\"   ç†ç”±: æ€§ä»·æ¯”é«˜ï¼Œé€Ÿåº¦å¿«\")\n",
    "    else:\n",
    "        print(\"\\nğŸ¤– LLM: Qwen-72B\")\n",
    "        print(\"   ç†ç”±: å¯ç§æœ‰éƒ¨ç½²ï¼Œä¸­æ–‡ä¼˜åŒ–\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# å–æ¶ˆæ³¨é‡Šä»¥è¿è¡Œäº¤äº’å¼é€‰æ‹©\n",
    "# choose_tech_stack()\n",
    "\n",
    "# é¢„è®¾ç¤ºä¾‹\n",
    "print(\"ç¤ºä¾‹é…ç½®ï¼šå¿«é€Ÿå­¦ä¹ åœºæ™¯\")\n",
    "print(\"- æ¡†æ¶: LlamaIndex\")\n",
    "print(\"- å‘é‡åº“: Chroma\")\n",
    "print(\"- LLM: GPT-3.5-turbo\")\n",
    "print(\"- åµŒå…¥: OpenAI text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 çŸ¥è¯†æ£€æŸ¥\n",
    "\n",
    "### è‡ªæµ‹é¢˜\n",
    "\n",
    "1. **RAGçš„æ ¸å¿ƒä»·å€¼æ˜¯ä»€ä¹ˆï¼Ÿ**\n",
    "   - a) é™ä½æˆæœ¬\n",
    "   - b) å‡å°‘å¹»è§‰ã€çŸ¥è¯†æ›´æ–°ã€å¯è§£é‡Šæ€§  âœ…\n",
    "   - c) æé«˜ç”Ÿæˆé€Ÿåº¦\n",
    "\n",
    "2. **ä»¥ä¸‹å“ªä¸ªä¸æ˜¯RAGçš„ç»„ä»¶ï¼Ÿ**\n",
    "   - a) æ–‡æ¡£åŠ è½½å™¨\n",
    "   - b) æ•°æ®åº“è¿æ¥æ±   âœ…\n",
    "   - c) åµŒå…¥æ¨¡å‹\n",
    "\n",
    "3. **Hit Rateè¡¡é‡ä»€ä¹ˆï¼Ÿ**\n",
    "   - a) æ£€ç´¢é€Ÿåº¦\n",
    "   - b) æ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£çš„æ¯”ä¾‹  âœ…\n",
    "   - c) ç”Ÿæˆè´¨é‡\n",
    "\n",
    "### ç¼–ç ç»ƒä¹ \n",
    "\n",
    "**ä»»åŠ¡**ï¼šå®Œæˆä¸‹é¢çš„RAGæµç¨‹å‡½æ•°\n",
    "\n",
    "```python\n",
    "def rag_pipeline(query, knowledge_base, llm):\n",
    "    \"\"\"\n",
    "    ç®€å•çš„RAGæµç¨‹\n",
    "    \n",
    "    Args:\n",
    "        query: ç”¨æˆ·é—®é¢˜\n",
    "        knowledge_base: æ–‡æ¡£åˆ—è¡¨\n",
    "        llm: è¯­è¨€æ¨¡å‹å‡½æ•°\n",
    "    \n",
    "    Returns:\n",
    "        ç­”æ¡ˆ\n",
    "    \"\"\"\n",
    "    # TODO: å®ç°RAGæµç¨‹\n",
    "    # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£\n",
    "    # 2. æ„å»ºæç¤ºè¯\n",
    "    # 3. ç”Ÿæˆç­”æ¡ˆ\n",
    "    \n",
    "    pass\n",
    "```\n",
    "\n",
    "**ç­”æ¡ˆ**ï¼š\n",
    "\n",
    "```python\n",
    "def rag_pipeline(query, knowledge_base, llm):\n",
    "    # 1. æ£€ç´¢ï¼ˆç®€åŒ–ç‰ˆï¼‰\n",
    "    relevant_docs = [doc for doc in knowledge_base \n",
    "                     if any(word in doc.lower() \n",
    "                         for word in query.lower().split())]\n",
    "    \n",
    "    # 2. æ„å»ºæç¤ºè¯\n",
    "    context = \"\\n\".join(relevant_docs)\n",
    "    prompt = f\"åŸºäºä»¥ä¸‹æ–‡æ¡£å›ç­”é—®é¢˜ï¼š\\n{context}\\né—®é¢˜ï¼š{query}\"\n",
    "    \n",
    "    # 3. ç”Ÿæˆ\n",
    "    answer = llm(prompt)\n",
    "    \n",
    "    return answer\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æœ¬ç« æ€»ç»“\n",
    "\n",
    "âœ… **ä½ å­¦åˆ°äº†**ï¼š\n",
    "- RAGçš„å®šä¹‰å’Œæ ¸å¿ƒä»·å€¼\n",
    "- RAGçš„5å¤§æ ¸å¿ƒç»„ä»¶\n",
    "- RAG vs Fine-tuning vs Prompt Engineeringçš„åŒºåˆ«\n",
    "- å¦‚ä½•é€‰æ‹©åˆé€‚çš„æŠ€æœ¯æ ˆ\n",
    "\n",
    "ğŸ¯ **ä¸‹ä¸€æ­¥**ï¼š\n",
    "- ç¬¬2ç« ï¼šç¯å¢ƒæ­å»ºä¸å·¥å…·å‡†å¤‡\n",
    "- åŠ¨æ‰‹æ­å»ºå¼€å‘ç¯å¢ƒ\n",
    "\n",
    "ğŸ“š **æ‰©å±•é˜…è¯»**ï¼š\n",
    "- [RAGåŸè®ºæ–‡](https://arxiv.org/abs/2005.11401)\n",
    "- [LlamaIndexæ–‡æ¡£](https://docs.llamaindex.ai/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
